(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9731,65],{69606:(e,n,t)=>{"use strict";t.r(n),t.d(n,{assets:()=>h,contentTitle:()=>d,default:()=>g,frontMatter:()=>c,metadata:()=>m,toc:()=>p});var i=t(74848),s=t(28453),o=t(78847),r=t(64428),l=t(76237),a=t.n(l);const c={},d="Friendli",m={id:"integrations/llms/friendli",title:"Friendli",description:"Friendli enhances AI application performance and optimizes cost savings with scalable, efficient deployment options, tailored for high-demand AI workloads.",source:"@site/docs/integrations/llms/friendli.mdx",sourceDirName:"integrations/llms",slug:"/integrations/llms/friendli",permalink:"/docs/integrations/llms/friendli",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/integrations/llms/friendli.mdx",tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"Fireworks",permalink:"/docs/integrations/llms/fireworks"},next:{title:"(Legacy) Google PaLM/VertexAI",permalink:"/docs/integrations/llms/google_palm"}},h={},p=[{value:"Setup",id:"setup",level:2},...o.toc,{value:"Usage",id:"usage",level:2}];function u(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"friendli",children:"Friendli"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"https://friendli.ai/",children:"Friendli"})," enhances AI application performance and optimizes cost savings with scalable, efficient deployment options, tailored for high-demand AI workloads."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["This tutorial guides you through integrating ",(0,i.jsx)(n.code,{children:"Friendli"})," with LangChain."]}),"\n",(0,i.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,i.jsxs)(n.p,{children:["Ensure the ",(0,i.jsx)(n.code,{children:"@langchain/community"})," is installed."]}),"\n","\n",(0,i.jsx)(o.default,{}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/community\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Sign in to ",(0,i.jsx)(n.a,{href:"https://suite.friendli.ai/",children:"Friendli Suite"})," to create a Personal Access Token, and set it as the ",(0,i.jsx)(n.code,{children:"FRIENDLI_TOKEN"})," environment.\nYou can set team id as ",(0,i.jsx)(n.code,{children:"FRIENDLI_TEAM"})," environment."]}),"\n",(0,i.jsxs)(n.p,{children:["You can initialize a Friendli chat model with selecting the model you want to use. The default model is ",(0,i.jsx)(n.code,{children:"mixtral-8x7b-instruct-v0-1"}),". You can check the available models at ",(0,i.jsx)(n.a,{href:"https://docs.friendli.ai/guides/serverless_endpoints/pricing#text-generation-models",children:"docs.friendli.ai"}),"."]}),"\n",(0,i.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n","\n",(0,i.jsx)(r.A,{language:"typescript",children:a()})]})}function g(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},78847:(e,n,t)=>{"use strict";t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var i=t(74848),s=t(28453);const o={},r=void 0,l={id:"mdx_components/integration_install_tooltip",title:"integration_install_tooltip",description:"See this section for general instructions on installing integration packages.",source:"@site/docs/mdx_components/integration_install_tooltip.mdx",sourceDirName:"mdx_components",slug:"/mdx_components/integration_install_tooltip",permalink:"/docs/mdx_components/integration_install_tooltip",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/mdx_components/integration_install_tooltip.mdx",tags:[],version:"current",frontMatter:{}},a={},c=[];function d(e){const n={a:"a",admonition:"admonition",p:"p",...(0,s.R)(),...e.components};return(0,i.jsx)(n.admonition,{type:"tip",children:(0,i.jsxs)(n.p,{children:["See ",(0,i.jsx)(n.a,{href:"/docs/how_to/installation#installing-integration-packages",children:"this section for general instructions on installing integration packages"}),"."]})})}function m(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},76237:e=>{e.exports={content:'import { Friendli } from "@langchain/community/llms/friendli";\n\nconst model = new Friendli({\n  model: "mixtral-8x7b-instruct-v0-1", // Default value\n  friendliToken: process.env.FRIENDLI_TOKEN,\n  friendliTeam: process.env.FRIENDLI_TEAM,\n  maxTokens: 18,\n  temperature: 0.75,\n  topP: 0.25,\n  frequencyPenalty: 0,\n  stop: [],\n});\n\nconst response = await model.invoke(\n  "Check the Grammar: She dont like to eat vegetables, but she loves fruits."\n);\n\nconsole.log(response);\n\n/*\nCorrect: She doesn\'t like to eat vegetables, but she loves fruits\n*/\n\nconst stream = await model.stream(\n  "Check the Grammar: She dont like to eat vegetables, but she loves fruits."\n);\n\nfor await (const chunk of stream) {\n  console.log(chunk);\n}\n\n/*\nCor\nrect\n:\n She\n doesn\n...\nshe\n loves\n fruits\n*/\n',imports:[{local:"Friendli",imported:"Friendli",source:"@langchain/community/llms/friendli"}]}}}]);