"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3375],{24961:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>c,toc:()=>p});var o=t(74848),a=t(28453),s=t(27846),i=t(63142);const r={sidebar_class_name:"hidden",sidebar_position:3,title:"How to add ad-hoc tool calling capability to LLMs and Chat Models"},l=void 0,c={id:"how_to/tools_prompting",title:"How to add ad-hoc tool calling capability to LLMs and Chat Models",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/tools_prompting.mdx",sourceDirName:"how_to",slug:"/how_to/tools_prompting",permalink:"/docs/how_to/tools_prompting",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/tools_prompting.mdx",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_class_name:"hidden",sidebar_position:3,title:"How to add ad-hoc tool calling capability to LLMs and Chat Models"},sidebar:"tutorialSidebar",previous:{title:"How to return structured data from a model",permalink:"/docs/how_to/structured_output"},next:{title:"How to create a custom chat model class",permalink:"/docs/how_to/custom_chat"}},d={},p=[{value:"Setup",id:"setup",level:2},{value:"Set environment variables",id:"set-environment-variables",level:4},{value:"Create a tool",id:"create-a-tool",level:2},{value:"Creating our prompt",id:"creating-our-prompt",level:2},{value:"Adding an output parser",id:"adding-an-output-parser",level:2},{value:"Invoking the tool",id:"invoking-the-tool",level:2},{value:"Choosing from multiple tools",id:"choosing-from-multiple-tools",level:2},{value:"Returning tool inputs",id:"returning-tool-inputs",level:2},{value:"What\u2019s next?",id:"whats-next",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)(n.admonition,{title:"Prerequisites",type:"info",children:[(0,o.jsx)(n.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"../../docs/concepts/#langchain-expression-language",children:"LangChain Expression Language\n(LCEL)"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"../../docs/how_to/sequence/",children:"Chaining runnables"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"../../docs/how_to/tool_calling/",children:"Tool calling"})}),"\n"]})]}),"\n",(0,o.jsxs)(n.p,{children:["In this guide we\u2019ll build a Chain that does not rely on any special\nmodel APIs (like tool calling, which we showed in the\n",(0,o.jsx)(n.a,{href:"../../docs/how_to/tool_calling",children:"Quickstart"}),") and instead just prompts\nthe model directly to invoke tools."]}),"\n",(0,o.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,o.jsx)(n.p,{children:"We\u2019ll need to install the following packages:"}),"\n","\n",(0,o.jsx)(s.A,{children:(0,o.jsx)(n.p,{children:"@langchain/core zod"})}),"\n",(0,o.jsx)(n.h4,{id:"set-environment-variables",children:"Set environment variables"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"# Optional, use LangSmith for best-in-class observability\nLANGSMITH_API_KEY=your-api-key\nLANGCHAIN_TRACING_V2=true\n"})}),"\n",(0,o.jsx)(n.h2,{id:"create-a-tool",children:"Create a tool"}),"\n",(0,o.jsxs)(n.p,{children:["First, we need to create a tool to call. For this example, we will\ncreate a custom tool from a function. For more information on all\ndetails related to creating custom tools, please see ",(0,o.jsx)(n.a,{href:"../../docs/how_to/custom_tools",children:"this\nguide"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'import { StructuredTool } from "@langchain/core/tools";\nimport { z } from "zod";\n\nclass Multiply extends StructuredTool {\n  schema = z.object({\n    first_int: z.number(),\n    second_int: z.number(),\n  });\n\n  name = "multiply";\n\n  description = "Multiply two integers together.";\n\n  async _call(input: z.infer<typeof this.schema>) {\n    return (input.first_int * input.second_int).toString();\n  }\n}\n\nconst multiply = new Multiply();\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"console.log(multiply.name);\nconsole.log(multiply.description);\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"multiply\nMultiply two integers together.\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"await multiply.invoke({ first_int: 4, second_int: 5 });\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"20\n"})}),"\n",(0,o.jsx)(n.h2,{id:"creating-our-prompt",children:"Creating our prompt"}),"\n",(0,o.jsxs)(n.p,{children:["We\u2019ll want to write a prompt that specifies the tools the model has\naccess to, the arguments to those tools, and the desired output format\nof the model. In this case we\u2019ll instruct it to output a JSON blob of\nthe form ",(0,o.jsx)(n.code,{children:'{"name": "...", "arguments": {...}}'}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'import { renderTextDescription } from "langchain/tools/render";\n\nconst renderedTools = renderTextDescription([multiply]);\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'import { ChatPromptTemplate } from "@langchain/core/prompts";\n\nconst systemPrompt = `You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n\n{rendered_tools}\n\nGiven the user input, return the name and input of the tool to use. Return your response as a JSON blob with \'name\' and \'arguments\' keys.`;\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  ["system", systemPrompt],\n  ["user", "{input}"],\n]);\n'})}),"\n",(0,o.jsx)(n.h2,{id:"adding-an-output-parser",children:"Adding an output parser"}),"\n",(0,o.jsxs)(n.p,{children:["We\u2019ll use the ",(0,o.jsx)(n.code,{children:"JsonOutputParser"})," for parsing our models output to JSON."]}),"\n","\n",(0,o.jsx)(i.A,{}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'import { JsonOutputParser } from "@langchain/core/output_parsers";\nconst chain = prompt.pipe(model).pipe(new JsonOutputParser());\nawait chain.invoke({\n  input: "what\'s thirteen times 4",\n  rendered_tools: renderedTools,\n});\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"{ name: 'multiply', arguments: [ 13, 4 ] }\n"})}),"\n",(0,o.jsx)(n.h2,{id:"invoking-the-tool",children:"Invoking the tool"}),"\n",(0,o.jsx)(n.p,{children:"We can invoke the tool as part of the chain by passing along the\nmodel-generated \u201carguments\u201d to it:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'import { RunnableLambda, RunnablePick } from "@langchain/core/runnables";\n\nconst chain = prompt\n  .pipe(model)\n  .pipe(new JsonOutputParser())\n  .pipe(new RunnablePick("arguments"))\n  .pipe(\n    new RunnableLambda({\n      func: (input) =>\n        multiply.invoke({\n          first_int: input[0],\n          second_int: input[1],\n        }),\n    })\n  );\nawait chain.invoke({\n  input: "what\'s thirteen times 4",\n  rendered_tools: renderedTools,\n});\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"52\n"})}),"\n",(0,o.jsx)(n.h2,{id:"choosing-from-multiple-tools",children:"Choosing from multiple tools"}),"\n",(0,o.jsx)(n.p,{children:"Suppose we have multiple tools we want the chain to be able to choose\nfrom:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'class Add extends StructuredTool {\n  schema = z.object({\n    first_int: z.number(),\n    second_int: z.number(),\n  });\n\n  name = "add";\n\n  description = "Add two integers together.";\n\n  async _call(input: z.infer<typeof this.schema>) {\n    return (input.first_int + input.second_int).toString();\n  }\n}\nconst add = new Add();\n\nclass Exponentiate extends StructuredTool {\n  schema = z.object({\n    first_int: z.number(),\n    second_int: z.number(),\n  });\n\n  name = "exponentiate";\n\n  description = "Exponentiate the base to the exponent power.";\n\n  async _call(input: z.infer<typeof this.schema>) {\n    return Math.pow(input.first_int, input.second_int).toString();\n  }\n}\nconst exponentiate = new Exponentiate();\n'})}),"\n",(0,o.jsx)(n.p,{children:"With function calling, we can do this like so:"}),"\n",(0,o.jsx)(n.p,{children:"If we want to run the model selected tool, we can do so using a function\nthat returns the tool based on the model output. Specifically, our\nfunction will action return it\u2019s own subchain that gets the \u201carguments\u201d\npart of the model output and passes it to the chosen tool:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'import { StructuredToolInterface } from "@langchain/core/tools";\n\nconst tools = [add, exponentiate, multiply];\n\nconst toolChain = (modelOutput) => {\n  const toolMap: Record<string, StructuredToolInterface> = Object.fromEntries(\n    tools.map((tool) => [tool.name, tool])\n  );\n  const chosenTool = toolMap[modelOutput.name];\n  return new RunnablePick("arguments").pipe(\n    new RunnableLambda({\n      func: (input) =>\n        chosenTool.invoke({\n          first_int: input[0],\n          second_int: input[1],\n        }),\n    })\n  );\n};\nconst toolChainRunnable = new RunnableLambda({\n  func: toolChain,\n});\n\nconst renderedTools = renderTextDescription(tools);\nconst systemPrompt = `You are an assistant that has access to the following set of tools. Here are the names and descriptions for each tool:\n\n{rendered_tools}\n\nGiven the user input, return the name and input of the tool to use. Return your response as a JSON blob with \'name\' and \'arguments\' keys.`;\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  ["system", systemPrompt],\n  ["user", "{input}"],\n]);\nconst chain = prompt\n  .pipe(model)\n  .pipe(new JsonOutputParser())\n  .pipe(toolChainRunnable);\nawait chain.invoke({\n  input: "what\'s 3 plus 1132",\n  rendered_tools: renderedTools,\n});\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"1135\n"})}),"\n",(0,o.jsx)(n.h2,{id:"returning-tool-inputs",children:"Returning tool inputs"}),"\n",(0,o.jsxs)(n.p,{children:["It can be helpful to return not only tool outputs but also tool inputs.\nWe can easily do this with LCEL by ",(0,o.jsx)(n.code,{children:"RunnablePassthrough.assign"}),"-ing the\ntool output. This will take whatever the input is to the\nRunnablePassrthrough components (assumed to be a dictionary) and add a\nkey to it while still passing through everything that\u2019s currently in the\ninput:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:'import { RunnablePassthrough } from "@langchain/core/runnables";\n\nconst chain = prompt\n  .pipe(model)\n  .pipe(new JsonOutputParser())\n  .pipe(RunnablePassthrough.assign({ output: toolChainRunnable }));\nawait chain.invoke({\n  input: "what\'s 3 plus 1132",\n  rendered_tools: renderedTools,\n});\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"{ name: 'add', arguments: [ 3, 1132 ], output: '1135' }\n"})}),"\n",(0,o.jsx)(n.h2,{id:"whats-next",children:"What\u2019s next?"}),"\n",(0,o.jsx)(n.p,{children:"This how-to guide shows the \u201chappy path\u201d when the model correctly\noutputs all the required tool information."}),"\n",(0,o.jsx)(n.p,{children:"In reality, if you\u2019re using more complex tools, you will start\nencountering errors from the model, especially for models that have not\nbeen fine tuned for tool calling and for less capable models."}),"\n",(0,o.jsx)(n.p,{children:"You will need to be prepared to add strategies to improve the output\nfrom the model; e.g.,"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Provide few shot examples."}),"\n",(0,o.jsx)(n.li,{children:"Add error handling (e.g., catch the exception and feed it back to\nthe LLM to ask it to correct its previous output)."}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},63142:(e,n,t)=>{t.d(n,{A:()=>h});t(96540);var o=t(11470),a=t(19365),s=t(21432),i=t(27846),r=t(27293),l=t(74848);function c(e){let{children:n}=e;return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(r.A,{type:"tip",children:(0,l.jsxs)("p",{children:["See"," ",(0,l.jsx)("a",{href:"/docs/get_started/installation#installing-integration-packages",children:"this section for general instructions on installing integration packages"}),"."]})}),(0,l.jsx)(i.A,{children:n})]})}const d={openaiParams:'{\n  model: "gpt-3.5-turbo",\n  temperature: 0\n}',anthropicParams:'{\n  model: "claude-3-sonnet-20240229",\n  temperature: 0\n}',fireworksParams:'{\n  model: "accounts/fireworks/models/firefunction-v1",\n  temperature: 0\n}',mistralParams:'{\n  model: "mistral-large-latest",\n  temperature: 0\n}',groqParams:'{\n  model: "mixtral-8x7b-32768",\n  temperature: 0\n}',vertexParams:'{\n  model: "gemini-1.5-pro",\n  temperature: 0\n}'},p=["openai","anthropic","mistral","groq","vertex"];function h(e){const{customVarName:n,additionalDependencies:t}=e,i=n??"model",r=e.openaiParams??d.openaiParams,h=e.anthropicParams??d.anthropicParams,u=e.fireworksParams??d.fireworksParams,m=e.mistralParams??d.mistralParams,g=e.groqParams??d.groqParams,x=e.vertexParams??d.vertexParams,f=e.providers??["openai","anthropic","fireworks","mistral","groq","vertex"],j={openai:{value:"openai",label:"OpenAI",default:!0,text:`import { ChatOpenAI } from "@langchain/openai";\n\nconst ${i} = new ChatOpenAI(${r});`,envs:"OPENAI_API_KEY=your-api-key",dependencies:"@langchain/openai"},anthropic:{value:"anthropic",label:"Anthropic",default:!1,text:`import { ChatAnthropic } from "@langchain/anthropic";\n\nconst ${i} = new ChatAnthropic(${h});`,envs:"ANTHROPIC_API_KEY=your-api-key",dependencies:"@langchain/anthropic"},fireworks:{value:"fireworks",label:"FireworksAI",default:!1,text:`import { ChatFireworks } from "@langchain/community/chat_models/fireworks";\n\nconst ${i} = new ChatFireworks(${u});`,envs:"FIREWORKS_API_KEY=your-api-key",dependencies:"@langchain/community"},mistral:{value:"mistral",label:"MistralAI",default:!1,text:`import { ChatMistralAI } from "@langchain/mistralai";\n\nconst ${i} = new ChatMistralAI(${m});`,envs:"MISTRAL_API_KEY=your-api-key",dependencies:"@langchain/mistralai"},groq:{value:"groq",label:"Groq",default:!1,text:`import { ChatGroq } from "@langchain/groq";\n\nconst ${i} = new ChatGroq(${g});`,envs:"GROQ_API_KEY=your-api-key",dependencies:"@langchain/groq"},vertex:{value:"vertex",label:"VertexAI",default:!1,text:`import { ChatVertexAI } from "@langchain/google-vertexai";\n\nconst ${i} = new ChatVertexAI(${x});`,envs:"GOOGLE_APPLICATION_CREDENTIALS=credentials.json",dependencies:"@langchain/google-vertexai"}},w=(e.onlyWso?p:f).map((e=>j[e]));return(0,l.jsxs)("div",{children:[(0,l.jsx)("h3",{children:"\uc0ac\uc6a9\ud560 \ucc44\ud305 \ubaa8\ub378 \uc120\ud0dd:"}),(0,l.jsx)(o.A,{groupId:"modelTabs",children:w.map((e=>(0,l.jsxs)(a.A,{value:e.value,label:e.label,children:[(0,l.jsx)("h4",{children:"\uc758\uc874\uc131 \ucd94\uac00"}),(0,l.jsx)(c,{children:[e.dependencies,t].join(" ")}),(0,l.jsx)("h4",{children:"\ud658\uacbd\ubcc0\uc218 \ucd94\uac00"}),(0,l.jsx)(s.A,{language:"bash",children:e.envs}),(0,l.jsx)("h4",{children:"\ubaa8\ub378 \uc778\uc2a4\ud134\uc2a4\ud654"}),(0,l.jsx)(s.A,{language:"typescript",children:e.text})]},e.value)))})]})}},27846:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);var o=t(11470),a=t(19365),s=t(21432),i=t(74848);function r(e){let{children:n}=e;return(0,i.jsxs)(o.A,{groupId:"npm2yarn",children:[(0,i.jsx)(a.A,{value:"npm",label:"npm",children:(0,i.jsxs)(s.A,{language:"bash",children:["npm i ",n]})}),(0,i.jsx)(a.A,{value:"yarn",label:"yarn",default:!0,children:(0,i.jsxs)(s.A,{language:"bash",children:["yarn add ",n]})}),(0,i.jsx)(a.A,{value:"pnpm",label:"pnpm",children:(0,i.jsxs)(s.A,{language:"bash",children:["pnpm add ",n]})})]})}}}]);