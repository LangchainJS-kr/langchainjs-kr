(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5171],{96209:(n,e,t)=>{"use strict";t.r(e),t.d(e,{assets:()=>m,contentTitle:()=>p,default:()=>f,frontMatter:()=>h,metadata:()=>d,toc:()=>g});var o=t(74848),i=t(28453),a=t(64428),s=t(74359),r=t.n(s),l=t(78847),c=t(71377),u=t.n(c);const h={sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},p="How to route execution within a chain",d={id:"how_to/routing",title:"How to route execution within a chain",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/routing.mdx",sourceDirName:"how_to",slug:"/how_to/routing",permalink:"/docs/how_to/routing",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/routing.mdx",tags:[],version:"current",frontMatter:{sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},sidebar:"tutorialSidebar"},m={},g=[{value:"Using a custom function",id:"using-a-custom-function",level:2},...l.toc,{value:"Using a RunnableBranch",id:"using-a-runnablebranch",level:2},{value:"Next steps",id:"next-steps",level:2}];function w(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"how-to-route-execution-within-a-chain",children:"How to route execution within a chain"}),"\n",(0,o.jsxs)(e.admonition,{title:"Prerequisites",type:"info",children:[(0,o.jsx)(e.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/concepts/#langchain-expression-language",children:"LangChain Expression Language (LCEL)"})}),"\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/how_to/sequence/",children:"Chaining runnables"})}),"\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/how_to/binding",children:"Configuring chain parameters at runtime"})}),"\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/concepts/#prompt-templates",children:"Prompt templates"})}),"\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.a,{href:"/docs/concepts/#message-types",children:"Chat Messages"})}),"\n"]})]}),"\n",(0,o.jsx)(e.p,{children:"This guide covers how to do routing in the LangChain Expression Language."}),"\n",(0,o.jsx)(e.p,{children:"Routing allows you to create non-deterministic chains where the output of a previous step defines the next step. Routing helps provide structure and consistency around interactions with LLMs."}),"\n",(0,o.jsx)(e.p,{children:"There are two ways to perform routing:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:["Conditionally return runnables from a ",(0,o.jsx)(e.a,{href:"/docs/how_to/functions",children:(0,o.jsx)(e.code,{children:"RunnableLambda"})})," (recommended)"]}),"\n",(0,o.jsxs)(e.li,{children:["Using a ",(0,o.jsx)(e.code,{children:"RunnableBranch"})," (legacy)"]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"We'll illustrate both methods using a two step sequence where the first step classifies an input question as being about LangChain, Anthropic, or Other, then routes to a corresponding prompt chain."}),"\n",(0,o.jsx)(e.h2,{id:"using-a-custom-function",children:"Using a custom function"}),"\n",(0,o.jsx)(e.p,{children:"You can use a custom function to route between different outputs. Here's an example:"}),"\n","\n","\n",(0,o.jsx)(l.default,{}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/anthropic\n"})}),"\n","\n",(0,o.jsx)(a.A,{language:"typescript",children:u()}),"\n",(0,o.jsx)(e.h2,{id:"using-a-runnablebranch",children:"Using a RunnableBranch"}),"\n",(0,o.jsxs)(e.p,{children:["A ",(0,o.jsx)(e.code,{children:"RunnableBranch"})," is initialized with a list of (condition, runnable) pairs and a default runnable. It selects which branch by passing each condition the input it's invoked with. It selects the first condition to evaluate to True, and runs the corresponding runnable to that condition with the input."]}),"\n",(0,o.jsx)(e.p,{children:"If no provided conditions match, it runs the default runnable."}),"\n",(0,o.jsx)(e.p,{children:"Here's an example of what it looks like in action:"}),"\n",(0,o.jsx)(a.A,{language:"typescript",children:r()}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,o.jsx)(e.p,{children:"You've now learned how to add routing to your composed LCEL chains."}),"\n",(0,o.jsxs)(e.p,{children:["Next, check out the other ",(0,o.jsx)(e.a,{href:"/docs/how_to/#langchain-expression-language-lcel",children:"how-to guides on runnables"})," in this section."]})]})}function f(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(w,{...n})}):w(n)}},71377:n=>{n.exports={content:"import { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { StringOutputParser } from \"@langchain/core/output_parsers\";\nimport { RunnableSequence } from \"@langchain/core/runnables\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst promptTemplate =\n  ChatPromptTemplate.fromTemplate(`Given the user question below, classify it as either being about \\`LangChain\\`, \\`Anthropic\\`, or \\`Other\\`.\n                                     \nDo not respond with more than one word.\n\n<question>\n{question}\n</question>\n\nClassification:`);\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-sonnet-20240229\",\n});\n\nconst classificationChain = RunnableSequence.from([\n  promptTemplate,\n  model,\n  new StringOutputParser(),\n]);\n\nconst classificationChainResult = await classificationChain.invoke({\n  question: \"how do I call Anthropic?\",\n});\nconsole.log(classificationChainResult);\n\n/*\n  Anthropic\n*/\n\nconst langChainChain = ChatPromptTemplate.fromTemplate(\n  `You are an expert in langchain.\nAlways answer questions starting with \"As Harrison Chase told me\".\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst anthropicChain = ChatPromptTemplate.fromTemplate(\n  `You are an expert in anthropic. \\\nAlways answer questions starting with \"As Dario Amodei told me\". \\\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst generalChain = ChatPromptTemplate.fromTemplate(\n  `Respond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst route = ({ topic }: { input: string; topic: string }) => {\n  if (topic.toLowerCase().includes(\"anthropic\")) {\n    return anthropicChain;\n  } else if (topic.toLowerCase().includes(\"langchain\")) {\n    return langChainChain;\n  } else {\n    return generalChain;\n  }\n};\n\nconst fullChain = RunnableSequence.from([\n  {\n    topic: classificationChain,\n    question: (input: { question: string }) => input.question,\n  },\n  route,\n]);\n\nconst result1 = await fullChain.invoke({\n  question: \"how do I use Anthropic?\",\n});\n\nconsole.log(result1);\n\n/*\n  AIMessage {\n    content: ' As Dario Amodei told me, here are some tips for how to use Anthropic:\\n' +\n      '\\n' +\n      \"First, sign up for an account on Anthropic's website. This will give you access to their conversational AI assistant named Claude. \\n\" +\n      '\\n' +\n      \"Once you've created an account, you can have conversations with Claude through their web interface. Talk to Claude like you would talk to a person, asking questions, giving instructions, etc. Claude is trained to have natural conversations and be helpful.\\n\" +\n      '\\n' +\n      \"You can also integrate Claude into your own applications using Anthropic's API. This allows you to build Claude's conversational abilities into chatbots, virtual assistants, and other AI systems you develop.\\n\" +\n      '\\n' +\n      'Anthropic is constantly working on improving Claude, so its capabilities are always expanding. Make sure to check their blog and documentation to stay up to date on the latest features.\\n' +\n      '\\n' +\n      'The key is to interact with Claude regularly so it can learn from you. The more you chat with it, the better it will become at understanding you and having personalized conversations. Over time, Claude will feel more human-like as it accumulates more conversational experience.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result2 = await fullChain.invoke({\n  question: \"how do I use LangChain?\",\n});\n\nconsole.log(result2);\n\n/*\n  AIMessage {\n    content: ' As Harrison Chase told me, here is how you use LangChain:\\n' +\n      '\\n' +\n      'First, think carefully about what you want to ask or have the AI do. Frame your request clearly and specifically. Avoid vague or overly broad prompts that could lead to unhelpful or concerning responses. \\n' +\n      '\\n' +\n      'Next, type your question or request into the chat window and send it. Be patient as the AI processes your input and generates a response. The AI will do its best to provide a helpful answer or follow your instructions, but its capabilities are limited.\\n' +\n      '\\n' +\n      'Keep your requests simple at first. Ask basic questions or have the AI summarize content or generate basic text. As you get more comfortable, you can try having the AI perform more complex tasks like answering tricky questions, generating stories, or having a conversation.\\n' +\n      '\\n' +\n      \"Pay attention to the AI's responses. If they seem off topic, nonsensical, or concerning, rephrase your prompt to steer the AI in a better direction. You may need to provide additional clarification or context to get useful results.\\n\" +\n      '\\n' +\n      'Be polite and respectful towards the AI system. Remember, it is a tool designed to be helpful, harmless, and honest. Do not try to trick, confuse, or exploit it. \\n' +\n      '\\n' +\n      'I hope these tips help you have a safe, fun and productive experience using LangChain! Let me know if you have any other questions.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result3 = await fullChain.invoke({\n  question: \"what is 2 + 2?\",\n});\n\nconsole.log(result3);\n\n/*\n  AIMessage {\n    content: ' 4',\n    additional_kwargs: {}\n  }\n*/\n",imports:[{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"},{local:"StringOutputParser",imported:"StringOutputParser",source:"@langchain/core/output_parsers"},{local:"RunnableSequence",imported:"RunnableSequence",source:"@langchain/core/runnables"},{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"}]}},74359:n=>{n.exports={content:"import { ChatPromptTemplate } from \"@langchain/core/prompts\";\nimport { StringOutputParser } from \"@langchain/core/output_parsers\";\nimport { RunnableBranch, RunnableSequence } from \"@langchain/core/runnables\";\nimport { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst promptTemplate =\n  ChatPromptTemplate.fromTemplate(`Given the user question below, classify it as either being about \\`LangChain\\`, \\`Anthropic\\`, or \\`Other\\`.\n                                     \nDo not respond with more than one word.\n\n<question>\n{question}\n</question>\n\nClassification:`);\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-sonnet-20240229\",\n});\n\nconst classificationChain = RunnableSequence.from([\n  promptTemplate,\n  model,\n  new StringOutputParser(),\n]);\n\nconst classificationChainResult = await classificationChain.invoke({\n  question: \"how do I call Anthropic?\",\n});\nconsole.log(classificationChainResult);\n\n/*\n  Anthropic\n*/\n\nconst langChainChain = ChatPromptTemplate.fromTemplate(\n  `You are an expert in langchain.\nAlways answer questions starting with \"As Harrison Chase told me\".\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst anthropicChain = ChatPromptTemplate.fromTemplate(\n  `You are an expert in anthropic. \\\nAlways answer questions starting with \"As Dario Amodei told me\". \\\nRespond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst generalChain = ChatPromptTemplate.fromTemplate(\n  `Respond to the following question:\n\nQuestion: {question}\nAnswer:`\n).pipe(model);\n\nconst branch = RunnableBranch.from([\n  [\n    (x: { topic: string; question: string }) =>\n      x.topic.toLowerCase().includes(\"anthropic\"),\n    anthropicChain,\n  ],\n  [\n    (x: { topic: string; question: string }) =>\n      x.topic.toLowerCase().includes(\"langchain\"),\n    langChainChain,\n  ],\n  generalChain,\n]);\n\nconst fullChain = RunnableSequence.from([\n  {\n    topic: classificationChain,\n    question: (input: { question: string }) => input.question,\n  },\n  branch,\n]);\n\nconst result1 = await fullChain.invoke({\n  question: \"how do I use Anthropic?\",\n});\n\nconsole.log(result1);\n\n/*\n  AIMessage {\n    content: ' As Dario Amodei told me, here are some tips for how to use Anthropic:\\n' +\n      '\\n' +\n      \"First, sign up for an account on Anthropic's website. This will give you access to their conversational AI assistant named Claude. \\n\" +\n      '\\n' +\n      \"Once you've created an account, you can have conversations with Claude through their web interface. Talk to Claude like you would talk to a person, asking questions, giving instructions, etc. Claude is trained to have natural conversations and be helpful.\\n\" +\n      '\\n' +\n      \"You can also integrate Claude into your own applications using Anthropic's API. This allows you to build Claude's conversational abilities into chatbots, virtual assistants, and other AI systems you develop.\\n\" +\n      '\\n' +\n      'Anthropic is constantly working on improving Claude, so its capabilities are always expanding. Make sure to check their blog and documentation to stay up to date on the latest features.\\n' +\n      '\\n' +\n      'The key is to interact with Claude regularly so it can learn from you. The more you chat with it, the better it will become at understanding you and having personalized conversations. Over time, Claude will feel more human-like as it accumulates more conversational experience.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result2 = await fullChain.invoke({\n  question: \"how do I use LangChain?\",\n});\n\nconsole.log(result2);\n\n/*\n  AIMessage {\n    content: ' As Harrison Chase told me, here is how you use LangChain:\\n' +\n      '\\n' +\n      'First, think carefully about what you want to ask or have the AI do. Frame your request clearly and specifically. Avoid vague or overly broad prompts that could lead to unhelpful or concerning responses. \\n' +\n      '\\n' +\n      'Next, type your question or request into the chat window and send it. Be patient as the AI processes your input and generates a response. The AI will do its best to provide a helpful answer or follow your instructions, but its capabilities are limited.\\n' +\n      '\\n' +\n      'Keep your requests simple at first. Ask basic questions or have the AI summarize content or generate basic text. As you get more comfortable, you can try having the AI perform more complex tasks like answering tricky questions, generating stories, or having a conversation.\\n' +\n      '\\n' +\n      \"Pay attention to the AI's responses. If they seem off topic, nonsensical, or concerning, rephrase your prompt to steer the AI in a better direction. You may need to provide additional clarification or context to get useful results.\\n\" +\n      '\\n' +\n      'Be polite and respectful towards the AI system. Remember, it is a tool designed to be helpful, harmless, and honest. Do not try to trick, confuse, or exploit it. \\n' +\n      '\\n' +\n      'I hope these tips help you have a safe, fun and productive experience using LangChain! Let me know if you have any other questions.',\n    additional_kwargs: {}\n  }\n*/\n\nconst result3 = await fullChain.invoke({\n  question: \"what is 2 + 2?\",\n});\n\nconsole.log(result3);\n\n/*\n  AIMessage {\n    content: ' 4',\n    additional_kwargs: {}\n  }\n*/\n",imports:[{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"},{local:"StringOutputParser",imported:"StringOutputParser",source:"@langchain/core/output_parsers"},{local:"RunnableBranch",imported:"RunnableBranch",source:"@langchain/core/runnables"},{local:"RunnableSequence",imported:"RunnableSequence",source:"@langchain/core/runnables"},{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"}]}}}]);