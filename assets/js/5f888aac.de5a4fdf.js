(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7839,7817,65],{96997:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>x,contentTitle:()=>g,default:()=>j,frontMatter:()=>u,metadata:()=>f,toc:()=>_});var o=n(74848),a=n(28453),s=n(64428),i=n(78847),r=n(2280),l=n(7504),c=n.n(l),d=n(38212),m=n.n(d),p=n(15357),h=n.n(p);const u={sidebar_label:"TogetherAI"},g="ChatTogetherAI",f={id:"integrations/chat/togetherai",title:"ChatTogetherAI",description:"Setup",source:"@site/docs/integrations/chat/togetherai.mdx",sourceDirName:"integrations/chat",slug:"/integrations/chat/togetherai",permalink:"/docs/integrations/chat/togetherai",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/integrations/chat/togetherai.mdx",tags:[],version:"current",frontMatter:{sidebar_label:"TogetherAI"},sidebar:"integrations",previous:{title:"PromptLayer OpenAI",permalink:"/docs/integrations/chat/prompt_layer_openai"},next:{title:"WebLLM",permalink:"/docs/integrations/chat/web_llm"}},x={},_=[{value:"Setup",id:"setup",level:2},...i.toc,...r.toc,{value:"Tool calling &amp; JSON mode",id:"tool-calling--json-mode",level:2},{value:"Tool calling",id:"tool-calling",level:3},{value:"JSON mode",id:"json-mode",level:3}];function T(e){const t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"chattogetherai",children:"ChatTogetherAI"}),"\n",(0,o.jsx)(t.h2,{id:"setup",children:"Setup"}),"\n",(0,o.jsxs)(t.ol,{children:["\n",(0,o.jsxs)(t.li,{children:["Create a TogetherAI account and get your API key ",(0,o.jsx)(t.a,{href:"https://api.together.xyz/",children:"here"}),"."]}),"\n",(0,o.jsxs)(t.li,{children:["Export or set your API key inline. The ChatTogetherAI class defaults to ",(0,o.jsx)(t.code,{children:"process.env.TOGETHER_AI_API_KEY"}),"."]}),"\n"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"export TOGETHER_AI_API_KEY=your-api-key\n"})}),"\n",(0,o.jsx)(t.p,{children:"You can use models provided by TogetherAI as follows:"}),"\n","\n",(0,o.jsx)(i.default,{}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/community\n"})}),"\n","\n",(0,o.jsx)(r.default,{}),"\n","\n",(0,o.jsx)(s.A,{language:"typescript",children:c()}),"\n",(0,o.jsx)(t.h2,{id:"tool-calling--json-mode",children:"Tool calling & JSON mode"}),"\n",(0,o.jsx)(t.p,{children:"The TogetherAI chat supports JSON mode and calling tools."}),"\n",(0,o.jsx)(t.h3,{id:"tool-calling",children:"Tool calling"}),"\n","\n",(0,o.jsx)(s.A,{language:"typescript",children:m()}),"\n",(0,o.jsx)(t.admonition,{type:"tip",children:(0,o.jsxs)(t.p,{children:["See a LangSmith trace of the above example ",(0,o.jsx)(t.a,{href:"https://smith.langchain.com/public/5082ea20-c2de-410f-80e2-dbdfbf4d8adb/r",children:"here"}),"."]})}),"\n",(0,o.jsx)(t.h3,{id:"json-mode",children:"JSON mode"}),"\n",(0,o.jsxs)(t.p,{children:['To use JSON mode you must include the string "JSON" inside the prompt.\nTypical conventions include telling the model to use JSON, eg: ',(0,o.jsx)(t.code,{children:"Respond to the user in JSON format"}),"."]}),"\n","\n",(0,o.jsx)(s.A,{language:"typescript",children:h()}),"\n",(0,o.jsx)(t.admonition,{type:"tip",children:(0,o.jsxs)(t.p,{children:["See a LangSmith trace of the above example ",(0,o.jsx)(t.a,{href:"https://smith.langchain.com/public/3864aebb-5096-4b5f-b096-e54ddd1ec3d2/r",children:"here"}),"."]})}),"\n",(0,o.jsx)(t.p,{children:"Behind the scenes, TogetherAI uses the OpenAI SDK and OpenAI compatible API, with some caveats:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:["Certain properties are not supported by the TogetherAI API, see ",(0,o.jsx)(t.a,{href:"https://docs.together.ai/reference/chat-completions",children:"here"}),"."]}),"\n"]})]})}function j(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(T,{...e})}):T(e)}},78847:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var o=n(74848),a=n(28453);const s={},i=void 0,r={id:"mdx_components/integration_install_tooltip",title:"integration_install_tooltip",description:"See this section for general instructions on installing integration packages.",source:"@site/docs/mdx_components/integration_install_tooltip.mdx",sourceDirName:"mdx_components",slug:"/mdx_components/integration_install_tooltip",permalink:"/docs/mdx_components/integration_install_tooltip",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/mdx_components/integration_install_tooltip.mdx",tags:[],version:"current",frontMatter:{}},l={},c=[];function d(e){const t={a:"a",admonition:"admonition",p:"p",...(0,a.R)(),...e.components};return(0,o.jsx)(t.admonition,{type:"tip",children:(0,o.jsxs)(t.p,{children:["See ",(0,o.jsx)(t.a,{href:"/docs/how_to/installation#installing-integration-packages",children:"this section for general instructions on installing integration packages"}),"."]})})}function m(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},2280:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var o=n(74848),a=n(28453);const s={},i=void 0,r={id:"mdx_components/unified_model_params_tooltip",title:"unified_model_params_tooltip",description:"We're unifying model params across all packages. We now suggest using model instead of modelName, and apiKey for API keys.",source:"@site/docs/mdx_components/unified_model_params_tooltip.mdx",sourceDirName:"mdx_components",slug:"/mdx_components/unified_model_params_tooltip",permalink:"/docs/mdx_components/unified_model_params_tooltip",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/mdx_components/unified_model_params_tooltip.mdx",tags:[],version:"current",frontMatter:{}},l={},c=[];function d(e){const t={admonition:"admonition",code:"code",p:"p",...(0,a.R)(),...e.components};return(0,o.jsx)(t.admonition,{type:"tip",children:(0,o.jsxs)(t.p,{children:["We're unifying model params across all packages. We now suggest using ",(0,o.jsx)(t.code,{children:"model"})," instead of ",(0,o.jsx)(t.code,{children:"modelName"}),", and ",(0,o.jsx)(t.code,{children:"apiKey"})," for API keys."]})})}function m(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},7504:e=>{e.exports={content:'import { ChatTogetherAI } from "@langchain/community/chat_models/togetherai";\nimport { HumanMessage } from "@langchain/core/messages";\n\nconst model = new ChatTogetherAI({\n  temperature: 0.9,\n  // In Node.js defaults to process.env.TOGETHER_AI_API_KEY\n  apiKey: "YOUR-API-KEY",\n});\n\nconsole.log(await model.invoke([new HumanMessage("Hello there!")]));\n',imports:[{local:"ChatTogetherAI",imported:"ChatTogetherAI",source:"@langchain/community/chat_models/togetherai"},{local:"HumanMessage",imported:"HumanMessage",source:"@langchain/core/messages"}]}},15357:e=>{e.exports={content:'import { ChatTogetherAI } from "@langchain/community/chat_models/togetherai";\nimport { ChatPromptTemplate } from "@langchain/core/prompts";\n\n// Define a JSON schema for the response\nconst responseSchema = {\n  type: "object",\n  properties: {\n    orderedArray: {\n      type: "array",\n      items: {\n        type: "number",\n      },\n    },\n  },\n  required: ["orderedArray"],\n};\nconst modelWithJsonSchema = new ChatTogetherAI({\n  temperature: 0,\n  apiKey: process.env.TOGETHER_AI_API_KEY,\n  model: "mistralai/Mixtral-8x7B-Instruct-v0.1",\n}).bind({\n  response_format: {\n    type: "json_object", // Define the response format as a JSON object\n    schema: responseSchema, // Pass in the schema for the model\'s response\n  },\n});\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  ["system", "You are a helpful assistant who responds in JSON."],\n  ["human", "Please list this output in order of DESC {unorderedList}."],\n]);\n\n// Use LCEL to chain the prompt to the model.\nconst response = await prompt.pipe(modelWithJsonSchema).invoke({\n  unorderedList: "[1, 4, 2, 8]",\n});\n\nconsole.log(JSON.parse(response.content as string));\n/**\n{ orderedArray: [ 8, 4, 2, 1 ] }\n */\n',imports:[{local:"ChatTogetherAI",imported:"ChatTogetherAI",source:"@langchain/community/chat_models/togetherai"},{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"}]}},38212:e=>{e.exports={content:'import { ChatTogetherAI } from "@langchain/community/chat_models/togetherai";\nimport { ChatPromptTemplate } from "@langchain/core/prompts";\nimport { convertToOpenAITool } from "@langchain/core/utils/function_calling";\nimport { Calculator } from "@langchain/community/tools/calculator";\n\n// Use a pre-built tool\nconst calculatorTool = convertToOpenAITool(new Calculator());\n\nconst modelWithCalculator = new ChatTogetherAI({\n  temperature: 0,\n  // This is the default env variable name it will look for if none is passed.\n  apiKey: process.env.TOGETHER_AI_API_KEY,\n  // Together JSON mode/tool calling only supports a select number of models\n  model: "mistralai/Mixtral-8x7B-Instruct-v0.1",\n}).bind({\n  // Bind the tool to the model.\n  tools: [calculatorTool],\n  tool_choice: calculatorTool, // Specify what tool the model should use\n});\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  ["system", "You are a super not-so-smart mathmatician."],\n  ["human", "Help me out, how can I add {math}?"],\n]);\n\n// Use LCEL to chain the prompt to the model.\nconst response = await prompt.pipe(modelWithCalculator).invoke({\n  math: "2 plus 3",\n});\n\nconsole.log(JSON.stringify(response.additional_kwargs.tool_calls));\n/**\n[\n  {\n    "id": "call_f4lzeeuho939vs4dilwd7267",\n    "type":"function",\n    "function": {\n      "name":"calculator",\n      "arguments": "{\\"input\\":\\"2 + 3\\"}"\n    }\n  }\n]\n */\n',imports:[{local:"ChatTogetherAI",imported:"ChatTogetherAI",source:"@langchain/community/chat_models/togetherai"},{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"},{local:"convertToOpenAITool",imported:"convertToOpenAITool",source:"@langchain/core/utils/function_calling"},{local:"Calculator",imported:"Calculator",source:"@langchain/community/tools/calculator"}]}}}]);