(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6571,65],{97896:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>l,default:()=>u,frontMatter:()=>d,metadata:()=>m,toc:()=>h});var r=n(74848),o=n(28453),i=n(64428),s=n(98553),a=n.n(s),c=n(78847);const d={hide_table_of_contents:!0},l="HyDE Retriever",m={id:"integrations/retrievers/hyde",title:"HyDE Retriever",description:"This example shows how to use the HyDE Retriever, which implements Hypothetical Document Embeddings (HyDE) as described in this paper.",source:"@site/docs/integrations/retrievers/hyde.mdx",sourceDirName:"integrations/retrievers",slug:"/integrations/retrievers/hyde",permalink:"/docs/integrations/retrievers/hyde",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/integrations/retrievers/hyde.mdx",tags:[],version:"current",frontMatter:{hide_table_of_contents:!0},sidebar:"integrations",previous:{title:"Exa Search",permalink:"/docs/integrations/retrievers/exa"},next:{title:"Amazon Kendra Retriever",permalink:"/docs/integrations/retrievers/kendra-retriever"}},p={},h=[{value:"Usage",id:"usage",level:2},...c.toc];function g(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.h1,{id:"hyde-retriever",children:"HyDE Retriever"}),"\n",(0,r.jsxs)(t.p,{children:["This example shows how to use the HyDE Retriever, which implements Hypothetical Document Embeddings (HyDE) as described in ",(0,r.jsx)(t.a,{href:"https://arxiv.org/abs/2212.10496",children:"this paper"}),"."]}),"\n",(0,r.jsx)(t.p,{children:"At a high level, HyDE is an embedding technique that takes queries, generates a hypothetical answer, and then embeds that generated document and uses that as the final example."}),"\n",(0,r.jsxs)(t.p,{children:["In order to use HyDE, we therefore need to provide a base embedding model, as well as an LLM that can be used to generate those documents. By default, the HyDE class comes with some default prompts to use (see the paper for more details on them), but we can also create our own, which should have a single input variable ",(0,r.jsx)(t.code,{children:"{question}"}),"."]}),"\n",(0,r.jsx)(t.h2,{id:"usage",children:"Usage"}),"\n","\n","\n",(0,r.jsx)(c.default,{}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/openai\n"})}),"\n",(0,r.jsx)(i.A,{language:"typescript",children:a()})]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(g,{...e})}):g(e)}},78847:(e,t,n)=>{"use strict";n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>s,default:()=>m,frontMatter:()=>i,metadata:()=>a,toc:()=>d});var r=n(74848),o=n(28453);const i={},s=void 0,a={id:"mdx_components/integration_install_tooltip",title:"integration_install_tooltip",description:"See this section for general instructions on installing integration packages.",source:"@site/docs/mdx_components/integration_install_tooltip.mdx",sourceDirName:"mdx_components",slug:"/mdx_components/integration_install_tooltip",permalink:"/docs/mdx_components/integration_install_tooltip",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/mdx_components/integration_install_tooltip.mdx",tags:[],version:"current",frontMatter:{}},c={},d=[];function l(e){const t={a:"a",admonition:"admonition",p:"p",...(0,o.R)(),...e.components};return(0,r.jsx)(t.admonition,{type:"tip",children:(0,r.jsxs)(t.p,{children:["See ",(0,r.jsx)(t.a,{href:"/docs/how_to/installation#installing-integration-packages",children:"this section for general instructions on installing integration packages"}),"."]})})}function m(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},98553:e=>{e.exports={content:'import { OpenAI, OpenAIEmbeddings } from "@langchain/openai";\nimport { MemoryVectorStore } from "langchain/vectorstores/memory";\nimport { HydeRetriever } from "langchain/retrievers/hyde";\nimport { Document } from "@langchain/core/documents";\n\nconst embeddings = new OpenAIEmbeddings();\nconst vectorStore = new MemoryVectorStore(embeddings);\nconst llm = new OpenAI();\nconst retriever = new HydeRetriever({\n  vectorStore,\n  llm,\n  k: 1,\n});\n\nawait vectorStore.addDocuments(\n  [\n    "My name is John.",\n    "My name is Bob.",\n    "My favourite food is pizza.",\n    "My favourite food is pasta.",\n  ].map((pageContent) => new Document({ pageContent }))\n);\n\nconst results = await retriever.invoke("What is my favourite food?");\n\nconsole.log(results);\n/*\n[\n  Document { pageContent: \'My favourite food is pasta.\', metadata: {} }\n]\n*/\n',imports:[{local:"OpenAI",imported:"OpenAI",source:"@langchain/openai"},{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"MemoryVectorStore",imported:"MemoryVectorStore",source:"langchain/vectorstores/memory"},{local:"HydeRetriever",imported:"HydeRetriever",source:"langchain/retrievers/hyde"},{local:"Document",imported:"Document",source:"@langchain/core/documents"}]}}}]);