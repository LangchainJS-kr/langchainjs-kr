"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[6877],{82614:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"\uc18c\uac1c","href":"/docs/introduction","docId":"introduction","unlisted":false},{"type":"category","label":"\ud29c\ud1a0\ub9ac\uc5bc","collapsed":false,"collapsible":false,"items":[{"type":"link","label":"\uadf8\ub798\ud504 \ub370\uc774\ud130\ubca0\uc774\uc2a4\ub97c \ud1b5\ud55c \uc9c8\ubb38/\ub2f5\ubcc0 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/graph","className":"hidden","docId":"tutorials/graph","unlisted":false},{"type":"link","label":"\ud29c\ud1a0\ub9ac\uc5bc","href":"/docs/tutorials/","className":"hidden","docId":"tutorials/index","unlisted":false},{"type":"link","label":"\uac04\ub2e8\ud55c LLM \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/llm_chain","className":"hidden","docId":"tutorials/llm_chain","unlisted":false},{"type":"link","label":"Build a Query Analysis System","href":"/docs/tutorials/query_analysis","className":"hidden","docId":"tutorials/query_analysis","unlisted":false},{"type":"link","label":"\ucc57\ubd07 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/chatbot","className":"hidden","docId":"tutorials/chatbot","unlisted":false},{"type":"link","label":"\uc5d0\uc774\uc804\ud2b8 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/agents","className":"hidden","docId":"tutorials/agents","unlisted":false},{"type":"link","label":"\ucd94\ucd9c \uccb4\uc778 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/extraction","className":"hidden","docId":"tutorials/extraction","unlisted":false},{"type":"link","label":"\ud14d\uc2a4\ud2b8 \uc694\uc57d\ud558\uae30","href":"/docs/tutorials/summarization","className":"hidden","docId":"tutorials/summarization","unlisted":false},{"type":"link","label":"Tagging","href":"/docs/tutorials/classification","className":"hidden","docId":"tutorials/classification","unlisted":false},{"type":"link","label":"\ub85c\uceec RAG \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/local_rag","className":"hidden","docId":"tutorials/local_rag","unlisted":false},{"type":"link","label":"\ub300\ud654\ud615 RAG \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/qa_chat_history","className":"hidden","docId":"tutorials/qa_chat_history","unlisted":false},{"type":"link","label":"\uac80\uc0c9-\uc99d\uac15 \uc0dd\uc131 (RAG) \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","href":"/docs/tutorials/rag","className":"hidden","docId":"tutorials/rag","unlisted":false},{"type":"link","label":"SQL \ub370\uc774\ud130\ub97c \ud1b5\ud55c \uc9c8\ubb38/\ub2f5\ubcc0 \uc2dc\uc2a4\ud15c \ub9cc\ub4e4\uae30","href":"/docs/tutorials/sql_qa","className":"hidden","docId":"tutorials/sql_qa","unlisted":false}],"href":"/docs/tutorials/"},{"type":"category","label":"\uc0ac\uc6a9 \uac00\uc774\ub4dc","collapsible":false,"collapsed":false,"items":[{"type":"link","label":"\uc0ac\uc6a9 \uac00\uc774\ub4dc","href":"/docs/how_to/","className":"hidden","docId":"how_to/index","unlisted":false},{"type":"link","label":"How to use example selectors","href":"/docs/how_to/example_selectors","className":"hidden","docId":"how_to/example_selectors","unlisted":false},{"type":"link","label":"Installation","href":"/docs/how_to/installation","className":"hidden","docId":"how_to/installation","unlisted":false},{"type":"link","label":"How to stream responses from an LLM","href":"/docs/how_to/streaming_llm","className":"hidden","docId":"how_to/streaming_llm","unlisted":false},{"type":"link","label":"How to stream chat model responses","href":"/docs/how_to/chat_streaming","className":"hidden","docId":"how_to/chat_streaming","unlisted":false},{"type":"link","label":"How to embed text data","href":"/docs/how_to/embed_text","className":"hidden","docId":"how_to/embed_text","unlisted":false},{"type":"link","label":"How to use few shot examples in chat models","href":"/docs/how_to/few_shot_examples_chat","className":"hidden","docId":"how_to/few_shot_examples_chat","unlisted":false},{"type":"link","label":"How to cache model responses","href":"/docs/how_to/llm_caching","className":"hidden","docId":"how_to/llm_caching","unlisted":false},{"type":"link","label":"How to cache chat model responses","href":"/docs/how_to/chat_model_caching","className":"hidden","docId":"how_to/chat_model_caching","unlisted":false},{"type":"link","label":"How to create a custom LLM class","href":"/docs/how_to/custom_llm","className":"hidden","docId":"how_to/custom_llm","unlisted":false},{"type":"link","label":"How to use few shot examples","href":"/docs/how_to/few_shot_examples","className":"hidden","docId":"how_to/few_shot_examples","unlisted":false},{"type":"link","label":"How to use output parsers to parse an LLM response into structured format","href":"/docs/how_to/output_parser_structured","className":"hidden","docId":"how_to/output_parser_structured","unlisted":false},{"type":"link","label":"How to return structured data from a model","href":"/docs/how_to/structured_output","className":"hidden","docId":"how_to/structured_output","unlisted":false},{"type":"link","label":"How to add ad-hoc tool calling capability to LLMs and Chat Models","href":"/docs/how_to/tools_prompting","className":"hidden","docId":"how_to/tools_prompting","unlisted":false},{"type":"link","label":"How to create a custom chat model class","href":"/docs/how_to/custom_chat","className":"hidden","docId":"how_to/custom_chat","unlisted":false},{"type":"link","label":"How to do per-user retrieval","href":"/docs/how_to/qa_per_user","className":"hidden","docId":"how_to/qa_per_user","unlisted":false},{"type":"link","label":"How to track token usage","href":"/docs/how_to/chat_token_usage_tracking","className":"hidden","docId":"how_to/chat_token_usage_tracking","unlisted":false},{"type":"link","label":"How to track token usage","href":"/docs/how_to/llm_token_usage_tracking","className":"hidden","docId":"how_to/llm_token_usage_tracking","unlisted":false},{"type":"link","label":"How to pass through arguments from one step to the next","href":"/docs/how_to/passthrough","className":"hidden","docId":"how_to/passthrough","unlisted":false},{"type":"link","label":"How to compose prompts together","href":"/docs/how_to/prompts_composition","className":"hidden","docId":"how_to/prompts_composition","unlisted":false},{"type":"link","label":"How to use legacy LangChain Agents (AgentExecutor)","href":"/docs/how_to/agent_executor","className":"hidden","docId":"how_to/agent_executor","unlisted":false},{"type":"link","label":"How to add values to a chain\'s state","href":"/docs/how_to/assign","className":"hidden","docId":"how_to/assign","unlisted":false},{"type":"link","label":"How to attach runtime arguments to a Runnable","href":"/docs/how_to/binding","className":"hidden","docId":"how_to/binding","unlisted":false},{"type":"link","label":"How to cache embedding results","href":"/docs/how_to/caching_embeddings","className":"hidden","docId":"how_to/caching_embeddings","unlisted":false},{"type":"link","label":"How to attach callbacks to a module","href":"/docs/how_to/callbacks_attach","className":"hidden","docId":"how_to/callbacks_attach","unlisted":false},{"type":"link","label":"How to make callbacks run in the background","href":"/docs/how_to/callbacks_backgrounding","className":"hidden","docId":"how_to/callbacks_backgrounding","unlisted":false},{"type":"link","label":"How to pass callbacks into a module constructor","href":"/docs/how_to/callbacks_constructor","className":"hidden","docId":"how_to/callbacks_constructor","unlisted":false},{"type":"link","label":"How to pass callbacks in at runtime","href":"/docs/how_to/callbacks_runtime","className":"hidden","docId":"how_to/callbacks_runtime","unlisted":false},{"type":"link","label":"How to split by character","href":"/docs/how_to/character_text_splitter","className":"hidden","docId":"how_to/character_text_splitter","unlisted":false},{"type":"link","label":"How to manage memory","href":"/docs/how_to/chatbots_memory","className":"hidden","docId":"how_to/chatbots_memory","unlisted":false},{"type":"link","label":"How to do retrieval","href":"/docs/how_to/chatbots_retrieval","className":"hidden","docId":"how_to/chatbots_retrieval","unlisted":false},{"type":"link","label":"How to use tools","href":"/docs/how_to/chatbots_tools","className":"hidden","docId":"how_to/chatbots_tools","unlisted":false},{"type":"link","label":"How to split code","href":"/docs/how_to/code_splitter","className":"hidden","docId":"how_to/code_splitter","unlisted":false},{"type":"link","label":"How to do retrieval with contextual compression","href":"/docs/how_to/contextual_compression","className":"hidden","docId":"how_to/contextual_compression","unlisted":false},{"type":"link","label":"How to create custom callback handlers","href":"/docs/how_to/custom_callbacks","className":"hidden","docId":"how_to/custom_callbacks","unlisted":false},{"type":"link","label":"How to write a custom retriever class","href":"/docs/how_to/custom_retriever","className":"hidden","docId":"how_to/custom_retriever","unlisted":false},{"type":"link","label":"How to create custom Tools","href":"/docs/how_to/custom_tools","className":"hidden","docId":"how_to/custom_tools","unlisted":false},{"type":"link","label":"How to debug your LLM apps","href":"/docs/how_to/debugging","className":"hidden","docId":"how_to/debugging","unlisted":false},{"type":"link","label":"How to load CSV data","href":"/docs/how_to/document_loader_csv","className":"hidden","docId":"how_to/document_loader_csv","unlisted":false},{"type":"link","label":"How to write a custom document loader","href":"/docs/how_to/document_loader_custom","className":"hidden","docId":"how_to/document_loader_custom","unlisted":false},{"type":"link","label":"How to load data from a directory","href":"/docs/how_to/document_loader_directory","className":"hidden","docId":"how_to/document_loader_directory","unlisted":false},{"type":"link","label":"How to load HTML","href":"/docs/how_to/document_loader_html","className":"hidden","docId":"how_to/document_loader_html","unlisted":false},{"type":"link","label":"How to load Markdown","href":"/docs/how_to/document_loader_markdown","className":"hidden","docId":"how_to/document_loader_markdown","unlisted":false},{"type":"link","label":"How to load PDF files","href":"/docs/how_to/document_loader_pdf","className":"hidden","docId":"how_to/document_loader_pdf","unlisted":false},{"type":"link","label":"How to load JSON data","href":"/docs/how_to/document_loaders_json","className":"hidden","docId":"how_to/document_loaders_json","unlisted":false},{"type":"link","label":"How to select examples by length","href":"/docs/how_to/example_selectors_length_based","className":"hidden","docId":"how_to/example_selectors_length_based","unlisted":false},{"type":"link","label":"How to select examples by similarity","href":"/docs/how_to/example_selectors_similarity","className":"hidden","docId":"how_to/example_selectors_similarity","unlisted":false},{"type":"link","label":"How to use reference examples","href":"/docs/how_to/extraction_examples","className":"hidden","docId":"how_to/extraction_examples","unlisted":false},{"type":"link","label":"How to handle long text","href":"/docs/how_to/extraction_long_text","className":"hidden","docId":"how_to/extraction_long_text","unlisted":false},{"type":"link","label":"How to do extraction without using function calling","href":"/docs/how_to/extraction_parse","className":"hidden","docId":"how_to/extraction_parse","unlisted":false},{"type":"link","label":"Fallbacks","href":"/docs/how_to/fallbacks","className":"hidden","docId":"how_to/fallbacks","unlisted":false},{"type":"link","label":"Few Shot Prompt Templates","href":"/docs/how_to/few_shot","className":"hidden","docId":"how_to/few_shot","unlisted":false},{"type":"link","label":"How to run custom functions","href":"/docs/how_to/functions","className":"hidden","docId":"how_to/functions","unlisted":false},{"type":"link","label":"How to construct knowledge graphs","href":"/docs/how_to/graph_constructing","className":"hidden","docId":"how_to/graph_constructing","unlisted":false},{"type":"link","label":"How to map values to a database","href":"/docs/how_to/graph_mapping","className":"hidden","docId":"how_to/graph_mapping","unlisted":false},{"type":"link","label":"How to improve results with prompting","href":"/docs/how_to/graph_prompting","className":"hidden","docId":"how_to/graph_prompting","unlisted":false},{"type":"link","label":"How to add a semantic layer over the database","href":"/docs/how_to/graph_semantic","className":"hidden","docId":"how_to/graph_semantic","unlisted":false},{"type":"link","label":"How to reindex data to keep your vectorstore in-sync with the underlying data source","href":"/docs/how_to/indexing","className":"hidden","docId":"how_to/indexing","unlisted":false},{"type":"link","label":"LangChain Expression Language Cheatsheet","href":"/docs/how_to/lcel_cheatsheet","className":"hidden","docId":"how_to/lcel_cheatsheet","unlisted":false},{"type":"link","label":"How to get log probabilities","href":"/docs/how_to/logprobs","className":"hidden","docId":"how_to/logprobs","unlisted":false},{"type":"link","label":"How to add message history","href":"/docs/how_to/message_history","className":"hidden","docId":"how_to/message_history","unlisted":false},{"type":"link","label":"How to generate multiple embeddings per document","href":"/docs/how_to/multi_vector","className":"hidden","docId":"how_to/multi_vector","unlisted":false},{"type":"link","label":"How to generate multiple queries to retrieve data for","href":"/docs/how_to/multiple_queries","className":"hidden","docId":"how_to/multiple_queries","unlisted":false},{"type":"link","label":"How to try to fix errors in output parsing","href":"/docs/how_to/output_parser_fixing","className":"hidden","docId":"how_to/output_parser_fixing","unlisted":false},{"type":"link","label":"How to parse JSON output","href":"/docs/how_to/output_parser_json","className":"hidden","docId":"how_to/output_parser_json","unlisted":false},{"type":"link","label":"How to parse XML output","href":"/docs/how_to/output_parser_xml","className":"hidden","docId":"how_to/output_parser_xml","unlisted":false},{"type":"link","label":"How to invoke runnables in parallel","href":"/docs/how_to/parallel","className":"hidden","docId":"how_to/parallel","unlisted":false},{"type":"link","label":"How to retrieve the whole document for a chunk","href":"/docs/how_to/parent_document_retriever","className":"hidden","docId":"how_to/parent_document_retriever","unlisted":false},{"type":"link","label":"How to partially format prompt templates","href":"/docs/how_to/prompts_partial","className":"hidden","docId":"how_to/prompts_partial","unlisted":false},{"type":"link","label":"How to add chat history to a question-answering chain","href":"/docs/how_to/qa_chat_history_how_to","className":"hidden","docId":"how_to/qa_chat_history_how_to","unlisted":false},{"type":"link","label":"How to return citations","href":"/docs/how_to/qa_citations","className":"hidden","docId":"how_to/qa_citations","unlisted":false},{"type":"link","label":"How to return sources","href":"/docs/how_to/qa_sources","className":"hidden","docId":"how_to/qa_sources","unlisted":false},{"type":"link","label":"How to stream from a question-answering chain","href":"/docs/how_to/qa_streaming","className":"hidden","docId":"how_to/qa_streaming","unlisted":false},{"type":"link","label":"How to construct filters","href":"/docs/how_to/query_constructing_filters","className":"hidden","docId":"how_to/query_constructing_filters","unlisted":false},{"type":"link","label":"How to add examples to the prompt","href":"/docs/how_to/query_few_shot","className":"hidden","docId":"how_to/query_few_shot","unlisted":false},{"type":"link","label":"How to deal with high cardinality categorical variables","href":"/docs/how_to/query_high_cardinality","className":"hidden","docId":"how_to/query_high_cardinality","unlisted":false},{"type":"link","label":"How to handle multiple queries","href":"/docs/how_to/query_multiple_queries","className":"hidden","docId":"how_to/query_multiple_queries","unlisted":false},{"type":"link","label":"How to handle multiple retrievers","href":"/docs/how_to/query_multiple_retrievers","className":"hidden","docId":"how_to/query_multiple_retrievers","unlisted":false},{"type":"link","label":"How to handle cases where no queries are generated","href":"/docs/how_to/query_no_queries","className":"hidden","docId":"how_to/query_no_queries","unlisted":false},{"type":"link","label":"How to recursively split text by characters","href":"/docs/how_to/recursive_text_splitter","className":"hidden","docId":"how_to/recursive_text_splitter","unlisted":false},{"type":"link","label":"How to reduce retrieval latency","href":"/docs/how_to/reduce_retrieval_latency","className":"hidden","docId":"how_to/reduce_retrieval_latency","unlisted":false},{"type":"link","label":"How to route execution within a chain","href":"/docs/how_to/routing","className":"hidden","docId":"how_to/routing","unlisted":false},{"type":"link","label":"How to do \\"self-querying\\" retrieval","href":"/docs/how_to/self_query","className":"hidden","docId":"how_to/self_query","unlisted":false},{"type":"link","label":"How to chain runnables","href":"/docs/how_to/sequence","className":"hidden","docId":"how_to/sequence","unlisted":false},{"type":"link","label":"How to split text by tokens","href":"/docs/how_to/split_by_token","className":"hidden","docId":"how_to/split_by_token","unlisted":false},{"type":"link","label":"How to deal with large databases","href":"/docs/how_to/sql_large_db","className":"hidden","docId":"how_to/sql_large_db","unlisted":false},{"type":"link","label":"How to use prompting to improve results","href":"/docs/how_to/sql_prompting","className":"hidden","docId":"how_to/sql_prompting","unlisted":false},{"type":"link","label":"How to do query validation","href":"/docs/how_to/sql_query_checking","className":"hidden","docId":"how_to/sql_query_checking","unlisted":false},{"type":"link","label":"How to stream","href":"/docs/how_to/streaming","className":"hidden","docId":"how_to/streaming","unlisted":false},{"type":"link","label":"How to create a time-weighted retriever","href":"/docs/how_to/time_weighted_vectorstore","className":"hidden","docId":"how_to/time_weighted_vectorstore","unlisted":false},{"type":"link","label":"How to use a chat model to call tools","href":"/docs/how_to/tool_calling","className":"hidden","docId":"how_to/tool_calling","unlisted":false},{"type":"link","label":"How to call tools with multi-modal data","href":"/docs/how_to/tool_calls_multi_modal","className":"hidden","docId":"how_to/tool_calls_multi_modal","unlisted":false},{"type":"link","label":"How to use LangChain tools","href":"/docs/how_to/tools_builtin","className":"hidden","docId":"how_to/tools_builtin","unlisted":false},{"type":"link","label":"How use a vector store to retrieve data","href":"/docs/how_to/vectorstore_retriever","className":"hidden","docId":"how_to/vectorstore_retriever","unlisted":false},{"type":"link","label":"How to create and query vector stores","href":"/docs/how_to/vectorstores","className":"hidden","docId":"how_to/vectorstores","unlisted":false}],"href":"/docs/how_to/"},{"type":"link","label":"\uac1c\ub150 \uac00\uc774\ub4dc","href":"/docs/concepts","className":"concepts","docId":"concepts","unlisted":false},{"type":"category","label":"\uc0dd\ud0dc\uacc4","collapsed":false,"collapsible":false,"items":[{"type":"link","href":"https://docs.smith.langchain.com/","label":"\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith"},{"type":"link","href":"https://langchain-ai.github.io/langgraphjs/","label":"\ud83e\udd9c\ud83d\udd78\ufe0f LangGraph.js"}]},{"type":"category","label":"\ubc84\uc804","collapsed":false,"collapsible":false,"items":[{"type":"link","label":"\uac1c\uc694","href":"/docs/versions/overview","docId":"versions/overview","unlisted":false},{"type":"link","label":"v0.2","href":"/docs/versions/v0_2","docId":"versions/v0_2","unlisted":false},{"type":"link","label":"\ub9b4\ub9ac\uc988 \uc815\ucc45","href":"/docs/versions/release_policy","docId":"versions/release_policy","unlisted":false},{"type":"link","label":"\ud328\ud0a4\uc9c0","href":"/docs/versions/packages","docId":"versions/packages","unlisted":false}]},{"type":"link","label":"\ubcf4\uc548","href":"/docs/security","className":"security","docId":"security","unlisted":false}],"integrations":[{"type":"category","label":"Providers","collapsible":false,"items":[{"type":"link","label":"Providers","href":"/docs/integrations/platforms/","className":"hidden","docId":"integrations/platforms/index","unlisted":false},{"type":"link","label":"Anthropic","href":"/docs/integrations/platforms/anthropic","docId":"integrations/platforms/anthropic","unlisted":false},{"type":"link","label":"AWS","href":"/docs/integrations/platforms/aws","docId":"integrations/platforms/aws","unlisted":false},{"type":"link","label":"Google","href":"/docs/integrations/platforms/google","docId":"integrations/platforms/google","unlisted":false},{"type":"link","label":"Microsoft","href":"/docs/integrations/platforms/microsoft","docId":"integrations/platforms/microsoft","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/platforms/openai","docId":"integrations/platforms/openai","unlisted":false}],"collapsed":false,"href":"/docs/integrations/platforms/"},{"type":"category","label":"Components","collapsible":false,"items":[{"type":"category","label":"Chat models","collapsed":true,"items":[{"type":"link","label":"Chat models","href":"/docs/integrations/chat/","className":"hidden","docId":"integrations/chat/index","unlisted":false},{"type":"link","label":"Alibaba Tongyi","href":"/docs/integrations/chat/alibaba_tongyi","docId":"integrations/chat/alibaba_tongyi","unlisted":false},{"type":"link","label":"Anthropic","href":"/docs/integrations/chat/anthropic","docId":"integrations/chat/anthropic","unlisted":false},{"type":"link","label":"Anthropic Tools","href":"/docs/integrations/chat/anthropic_tools","className":"hidden","docId":"integrations/chat/anthropic_tools","unlisted":false},{"type":"link","label":"Azure OpenAI","href":"/docs/integrations/chat/azure","docId":"integrations/chat/azure","unlisted":false},{"type":"link","label":"Baidu Wenxin","href":"/docs/integrations/chat/baidu_wenxin","docId":"integrations/chat/baidu_wenxin","unlisted":false},{"type":"link","label":"Bedrock","href":"/docs/integrations/chat/bedrock","docId":"integrations/chat/bedrock","unlisted":false},{"type":"link","label":"Cloudflare Workers AI","href":"/docs/integrations/chat/cloudflare_workersai","docId":"integrations/chat/cloudflare_workersai","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/integrations/chat/cohere","className":"beta","docId":"integrations/chat/cohere","unlisted":false},{"type":"link","label":"Fake LLM","href":"/docs/integrations/chat/fake","docId":"integrations/chat/fake","unlisted":false},{"type":"link","label":"Fireworks","href":"/docs/integrations/chat/fireworks","docId":"integrations/chat/fireworks","unlisted":false},{"type":"link","label":"Friendli","href":"/docs/integrations/chat/friendli","docId":"integrations/chat/friendli","unlisted":false},{"type":"link","label":"Google GenAI","href":"/docs/integrations/chat/google_generativeai","docId":"integrations/chat/google_generativeai","unlisted":false},{"type":"link","label":"(Legacy) Google PaLM/VertexAI","href":"/docs/integrations/chat/google_palm","className":"hidden","docId":"integrations/chat/google_palm","unlisted":false},{"type":"link","label":"Google Vertex AI","href":"/docs/integrations/chat/google_vertex_ai","docId":"integrations/chat/google_vertex_ai","unlisted":false},{"type":"link","label":"Groq","href":"/docs/integrations/chat/groq","docId":"integrations/chat/groq","unlisted":false},{"type":"link","label":"Llama CPP","href":"/docs/integrations/chat/llama_cpp","className":"node-only","docId":"integrations/chat/llama_cpp","unlisted":false},{"type":"link","label":"Minimax","href":"/docs/integrations/chat/minimax","docId":"integrations/chat/minimax","unlisted":false},{"type":"link","label":"Mistral AI","href":"/docs/integrations/chat/mistral","docId":"integrations/chat/mistral","unlisted":false},{"type":"link","label":"NIBittensorChatModel","href":"/docs/integrations/chat/ni_bittensor","className":"hidden","docId":"integrations/chat/ni_bittensor","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/integrations/chat/ollama","docId":"integrations/chat/ollama","unlisted":false},{"type":"link","label":"Ollama Functions","href":"/docs/integrations/chat/ollama_functions","docId":"integrations/chat/ollama_functions","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/chat/openai","docId":"integrations/chat/openai","unlisted":false},{"type":"link","label":"PremAI","href":"/docs/integrations/chat/premai","docId":"integrations/chat/premai","unlisted":false},{"type":"link","label":"PromptLayer OpenAI","href":"/docs/integrations/chat/prompt_layer_openai","docId":"integrations/chat/prompt_layer_openai","unlisted":false},{"type":"link","label":"TogetherAI","href":"/docs/integrations/chat/togetherai","docId":"integrations/chat/togetherai","unlisted":false},{"type":"link","label":"WebLLM","href":"/docs/integrations/chat/web_llm","className":"web-only","docId":"integrations/chat/web_llm","unlisted":false},{"type":"link","label":"YandexGPT","href":"/docs/integrations/chat/yandex","docId":"integrations/chat/yandex","unlisted":false},{"type":"link","label":"ZhipuAI","href":"/docs/integrations/chat/zhipuai","docId":"integrations/chat/zhipuai","unlisted":false}],"collapsible":true,"href":"/docs/integrations/chat/"},{"type":"category","label":"LLMs","collapsed":true,"items":[{"type":"link","label":"LLMs","href":"/docs/integrations/llms/","className":"hidden","docId":"integrations/llms/index","unlisted":false},{"type":"link","label":"AI21","href":"/docs/integrations/llms/ai21","docId":"integrations/llms/ai21","unlisted":false},{"type":"link","label":"AlephAlpha","href":"/docs/integrations/llms/aleph_alpha","docId":"integrations/llms/aleph_alpha","unlisted":false},{"type":"link","label":"AWS SageMakerEndpoint","href":"/docs/integrations/llms/aws_sagemaker","docId":"integrations/llms/aws_sagemaker","unlisted":false},{"type":"link","label":"Azure OpenAI","href":"/docs/integrations/llms/azure","docId":"integrations/llms/azure","unlisted":false},{"type":"link","label":"Bedrock","href":"/docs/integrations/llms/bedrock","docId":"integrations/llms/bedrock","unlisted":false},{"type":"link","label":"Cloudflare Workers AI","href":"/docs/integrations/llms/cloudflare_workersai","docId":"integrations/llms/cloudflare_workersai","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/integrations/llms/cohere","docId":"integrations/llms/cohere","unlisted":false},{"type":"link","label":"Fireworks","href":"/docs/integrations/llms/fireworks","docId":"integrations/llms/fireworks","unlisted":false},{"type":"link","label":"Friendli","href":"/docs/integrations/llms/friendli","docId":"integrations/llms/friendli","unlisted":false},{"type":"link","label":"(Legacy) Google PaLM/VertexAI","href":"/docs/integrations/llms/google_palm","className":"hidden","docId":"integrations/llms/google_palm","unlisted":false},{"type":"link","label":"Google Vertex AI","href":"/docs/integrations/llms/google_vertex_ai","docId":"integrations/llms/google_vertex_ai","unlisted":false},{"type":"link","label":"Gradient AI","href":"/docs/integrations/llms/gradient_ai","className":"node-only","docId":"integrations/llms/gradient_ai","unlisted":false},{"type":"link","label":"HuggingFaceInference","href":"/docs/integrations/llms/huggingface_inference","docId":"integrations/llms/huggingface_inference","unlisted":false},{"type":"link","label":"Layerup Security","href":"/docs/integrations/llms/layerup_security","docId":"integrations/llms/layerup_security","unlisted":false},{"type":"link","label":"Llama CPP","href":"/docs/integrations/llms/llama_cpp","className":"node-only","docId":"integrations/llms/llama_cpp","unlisted":false},{"type":"link","label":"NIBittensor","href":"/docs/integrations/llms/ni_bittensor","className":"hidden","docId":"integrations/llms/ni_bittensor","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/integrations/llms/ollama","docId":"integrations/llms/ollama","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/llms/openai","docId":"integrations/llms/openai","unlisted":false},{"type":"link","label":"PromptLayer OpenAI","href":"/docs/integrations/llms/prompt_layer_openai","className":"hidden","docId":"integrations/llms/prompt_layer_openai","unlisted":false},{"type":"link","label":"RaycastAI","href":"/docs/integrations/llms/raycast","docId":"integrations/llms/raycast","unlisted":false},{"type":"link","label":"Replicate","href":"/docs/integrations/llms/replicate","docId":"integrations/llms/replicate","unlisted":false},{"type":"link","label":"Together AI","href":"/docs/integrations/llms/togetherai","docId":"integrations/llms/togetherai","unlisted":false},{"type":"link","label":"WatsonX AI","href":"/docs/integrations/llms/watsonx_ai","docId":"integrations/llms/watsonx_ai","unlisted":false},{"type":"link","label":"Writer","href":"/docs/integrations/llms/writer","docId":"integrations/llms/writer","unlisted":false},{"type":"link","label":"YandexGPT","href":"/docs/integrations/llms/yandex","docId":"integrations/llms/yandex","unlisted":false}],"collapsible":true,"href":"/docs/integrations/llms/"},{"type":"category","label":"Embedding models","collapsed":true,"items":[{"type":"link","label":"Alibaba Tongyi","href":"/docs/integrations/text_embedding/alibaba_tongyi","className":"node-only","docId":"integrations/text_embedding/alibaba_tongyi","unlisted":false},{"type":"link","label":"Azure OpenAI","href":"/docs/integrations/text_embedding/azure_openai","docId":"integrations/text_embedding/azure_openai","unlisted":false},{"type":"link","label":"Baidu Qianfan","href":"/docs/integrations/text_embedding/baidu_qianfan","className":"node-only","docId":"integrations/text_embedding/baidu_qianfan","unlisted":false},{"type":"link","label":"Bedrock","href":"/docs/integrations/text_embedding/bedrock","docId":"integrations/text_embedding/bedrock","unlisted":false},{"type":"link","label":"Cloudflare Workers AI","href":"/docs/integrations/text_embedding/cloudflare_ai","docId":"integrations/text_embedding/cloudflare_ai","unlisted":false},{"type":"link","label":"Cohere","href":"/docs/integrations/text_embedding/cohere","docId":"integrations/text_embedding/cohere","unlisted":false},{"type":"link","label":"Fireworks","href":"/docs/integrations/text_embedding/fireworks","docId":"integrations/text_embedding/fireworks","unlisted":false},{"type":"link","label":"Google AI","href":"/docs/integrations/text_embedding/google_generativeai","docId":"integrations/text_embedding/google_generativeai","unlisted":false},{"type":"link","label":"Google PaLM","href":"/docs/integrations/text_embedding/google_palm","docId":"integrations/text_embedding/google_palm","unlisted":false},{"type":"link","label":"Google Vertex AI","href":"/docs/integrations/text_embedding/google_vertex_ai","docId":"integrations/text_embedding/google_vertex_ai","unlisted":false},{"type":"link","label":"Gradient AI","href":"/docs/integrations/text_embedding/gradient_ai","className":"node-only","docId":"integrations/text_embedding/gradient_ai","unlisted":false},{"type":"link","label":"HuggingFace Inference","href":"/docs/integrations/text_embedding/hugging_face_inference","docId":"integrations/text_embedding/hugging_face_inference","unlisted":false},{"type":"link","label":"Llama CPP","href":"/docs/integrations/text_embedding/llama_cpp","className":"node-only","docId":"integrations/text_embedding/llama_cpp","unlisted":false},{"type":"link","label":"Minimax","href":"/docs/integrations/text_embedding/minimax","docId":"integrations/text_embedding/minimax","unlisted":false},{"type":"link","label":"Mistral AI","href":"/docs/integrations/text_embedding/mistralai","docId":"integrations/text_embedding/mistralai","unlisted":false},{"type":"link","label":"Nomic","href":"/docs/integrations/text_embedding/nomic","docId":"integrations/text_embedding/nomic","unlisted":false},{"type":"link","label":"Ollama","href":"/docs/integrations/text_embedding/ollama","docId":"integrations/text_embedding/ollama","unlisted":false},{"type":"link","label":"OpenAI","href":"/docs/integrations/text_embedding/openai","docId":"integrations/text_embedding/openai","unlisted":false},{"type":"link","label":"Prem AI","href":"/docs/integrations/text_embedding/premai","docId":"integrations/text_embedding/premai","unlisted":false},{"type":"link","label":"TensorFlow","href":"/docs/integrations/text_embedding/tensorflow","docId":"integrations/text_embedding/tensorflow","unlisted":false},{"type":"link","label":"Together AI","href":"/docs/integrations/text_embedding/togetherai","docId":"integrations/text_embedding/togetherai","unlisted":false},{"type":"link","label":"HuggingFace Transformers","href":"/docs/integrations/text_embedding/transformers","docId":"integrations/text_embedding/transformers","unlisted":false},{"type":"link","label":"Voyage AI","href":"/docs/integrations/text_embedding/voyageai","docId":"integrations/text_embedding/voyageai","unlisted":false},{"type":"link","label":"ZhipuAI","href":"/docs/integrations/text_embedding/zhipuai","className":"node-only","docId":"integrations/text_embedding/zhipuai","unlisted":false}],"collapsible":true,"href":"/docs/integrations/text_embedding"},{"type":"category","label":"Document loaders","collapsed":true,"items":[{"type":"category","label":"File Loaders","collapsible":true,"collapsed":true,"className":"node-only-category","items":[{"type":"link","label":"Folders with multiple files","href":"/docs/integrations/document_loaders/file_loaders/directory","docId":"integrations/document_loaders/file_loaders/directory","unlisted":false},{"type":"link","label":"ChatGPT files","href":"/docs/integrations/document_loaders/file_loaders/chatgpt","docId":"integrations/document_loaders/file_loaders/chatgpt","unlisted":false},{"type":"link","label":"CSV files","href":"/docs/integrations/document_loaders/file_loaders/csv","docId":"integrations/document_loaders/file_loaders/csv","unlisted":false},{"type":"link","label":"Docx files","href":"/docs/integrations/document_loaders/file_loaders/docx","docId":"integrations/document_loaders/file_loaders/docx","unlisted":false},{"type":"link","label":"EPUB files","href":"/docs/integrations/document_loaders/file_loaders/epub","docId":"integrations/document_loaders/file_loaders/epub","unlisted":false},{"type":"link","label":"JSON files","href":"/docs/integrations/document_loaders/file_loaders/json","docId":"integrations/document_loaders/file_loaders/json","unlisted":false},{"type":"link","label":"JSONLines files","href":"/docs/integrations/document_loaders/file_loaders/jsonlines","docId":"integrations/document_loaders/file_loaders/jsonlines","unlisted":false},{"type":"link","label":"Notion markdown export","href":"/docs/integrations/document_loaders/file_loaders/notion_markdown","docId":"integrations/document_loaders/file_loaders/notion_markdown","unlisted":false},{"type":"link","label":"Open AI Whisper Audio","href":"/docs/integrations/document_loaders/file_loaders/openai_whisper_audio","docId":"integrations/document_loaders/file_loaders/openai_whisper_audio","unlisted":false},{"type":"link","label":"PDF files","href":"/docs/integrations/document_loaders/file_loaders/pdf","docId":"integrations/document_loaders/file_loaders/pdf","unlisted":false},{"type":"link","label":"PPTX files","href":"/docs/integrations/document_loaders/file_loaders/pptx","docId":"integrations/document_loaders/file_loaders/pptx","unlisted":false},{"type":"link","label":"Subtitles","href":"/docs/integrations/document_loaders/file_loaders/subtitles","docId":"integrations/document_loaders/file_loaders/subtitles","unlisted":false},{"type":"link","label":"Text files","href":"/docs/integrations/document_loaders/file_loaders/text","docId":"integrations/document_loaders/file_loaders/text","unlisted":false},{"type":"link","label":"Unstructured","href":"/docs/integrations/document_loaders/file_loaders/unstructured","docId":"integrations/document_loaders/file_loaders/unstructured","unlisted":false}],"href":"/docs/integrations/document_loaders/file_loaders/"},{"type":"category","label":"Web Loaders","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Cheerio","href":"/docs/integrations/document_loaders/web_loaders/web_cheerio","docId":"integrations/document_loaders/web_loaders/web_cheerio","unlisted":false},{"type":"link","label":"Puppeteer","href":"/docs/integrations/document_loaders/web_loaders/web_puppeteer","className":"node-only","docId":"integrations/document_loaders/web_loaders/web_puppeteer","unlisted":false},{"type":"link","label":"Playwright","href":"/docs/integrations/document_loaders/web_loaders/web_playwright","className":"node-only","docId":"integrations/document_loaders/web_loaders/web_playwright","unlisted":false},{"type":"link","label":"Apify Dataset","href":"/docs/integrations/document_loaders/web_loaders/apify_dataset","className":"node-only","docId":"integrations/document_loaders/web_loaders/apify_dataset","unlisted":false},{"type":"link","label":"AssemblyAI Audio Transcript","href":"/docs/integrations/document_loaders/web_loaders/assemblyai_audio_transcription","docId":"integrations/document_loaders/web_loaders/assemblyai_audio_transcription","unlisted":false},{"type":"link","label":"Azure Blob Storage Container","href":"/docs/integrations/document_loaders/web_loaders/azure_blob_storage_container","className":"node-only","docId":"integrations/document_loaders/web_loaders/azure_blob_storage_container","unlisted":false},{"type":"link","label":"Azure Blob Storage File","href":"/docs/integrations/document_loaders/web_loaders/azure_blob_storage_file","className":"node-only","docId":"integrations/document_loaders/web_loaders/azure_blob_storage_file","unlisted":false},{"type":"link","label":"Browserbase Loader","href":"/docs/integrations/document_loaders/web_loaders/browserbase","docId":"integrations/document_loaders/web_loaders/browserbase","unlisted":false},{"type":"link","label":"College Confidential","href":"/docs/integrations/document_loaders/web_loaders/college_confidential","docId":"integrations/document_loaders/web_loaders/college_confidential","unlisted":false},{"type":"link","label":"Confluence","href":"/docs/integrations/document_loaders/web_loaders/confluence","className":"node-only","docId":"integrations/document_loaders/web_loaders/confluence","unlisted":false},{"type":"link","label":"Couchbase","href":"/docs/integrations/document_loaders/web_loaders/couchbase","className":"node-only","docId":"integrations/document_loaders/web_loaders/couchbase","unlisted":false},{"type":"link","label":"Figma","href":"/docs/integrations/document_loaders/web_loaders/figma","docId":"integrations/document_loaders/web_loaders/figma","unlisted":false},{"type":"link","label":"Firecrawl","href":"/docs/integrations/document_loaders/web_loaders/firecrawl","docId":"integrations/document_loaders/web_loaders/firecrawl","unlisted":false},{"type":"link","label":"GitBook","href":"/docs/integrations/document_loaders/web_loaders/gitbook","docId":"integrations/document_loaders/web_loaders/gitbook","unlisted":false},{"type":"link","label":"GitHub","href":"/docs/integrations/document_loaders/web_loaders/github","className":"node-only","docId":"integrations/document_loaders/web_loaders/github","unlisted":false},{"type":"link","label":"Hacker News","href":"/docs/integrations/document_loaders/web_loaders/hn","docId":"integrations/document_loaders/web_loaders/hn","unlisted":false},{"type":"link","label":"IMSDB","href":"/docs/integrations/document_loaders/web_loaders/imsdb","docId":"integrations/document_loaders/web_loaders/imsdb","unlisted":false},{"type":"link","label":"Notion API","href":"/docs/integrations/document_loaders/web_loaders/notionapi","className":"node-only","docId":"integrations/document_loaders/web_loaders/notionapi","unlisted":false},{"type":"link","label":"PDF files","href":"/docs/integrations/document_loaders/web_loaders/pdf","docId":"integrations/document_loaders/web_loaders/pdf","unlisted":false},{"type":"link","label":"Recursive URL Loader","href":"/docs/integrations/document_loaders/web_loaders/recursive_url_loader","className":"node-only","docId":"integrations/document_loaders/web_loaders/recursive_url_loader","unlisted":false},{"type":"link","label":"S3 File","href":"/docs/integrations/document_loaders/web_loaders/s3","className":"node-only","docId":"integrations/document_loaders/web_loaders/s3","unlisted":false},{"type":"link","label":"SearchApi Loader","href":"/docs/integrations/document_loaders/web_loaders/searchapi","docId":"integrations/document_loaders/web_loaders/searchapi","unlisted":false},{"type":"link","label":"SerpAPI Loader","href":"/docs/integrations/document_loaders/web_loaders/serpapi","docId":"integrations/document_loaders/web_loaders/serpapi","unlisted":false},{"type":"link","label":"Sitemap Loader","href":"/docs/integrations/document_loaders/web_loaders/sitemap","docId":"integrations/document_loaders/web_loaders/sitemap","unlisted":false},{"type":"link","label":"Sonix Audio","href":"/docs/integrations/document_loaders/web_loaders/sonix_audio_transcription","className":"node-only","docId":"integrations/document_loaders/web_loaders/sonix_audio_transcription","unlisted":false},{"type":"link","label":"Blockchain Data","href":"/docs/integrations/document_loaders/web_loaders/sort_xyz_blockchain","docId":"integrations/document_loaders/web_loaders/sort_xyz_blockchain","unlisted":false},{"type":"link","label":"Spider","href":"/docs/integrations/document_loaders/web_loaders/spider","docId":"integrations/document_loaders/web_loaders/spider","unlisted":false},{"type":"link","label":"YouTube transcripts","href":"/docs/integrations/document_loaders/web_loaders/youtube","docId":"integrations/document_loaders/web_loaders/youtube","unlisted":false}],"href":"/docs/integrations/document_loaders/web_loaders/"}],"collapsible":true,"href":"/docs/integrations/document_loaders"},{"type":"category","label":"Document transformers","collapsed":true,"items":[{"type":"link","label":"html-to-text","href":"/docs/integrations/document_transformers/html-to-text","docId":"integrations/document_transformers/html-to-text","unlisted":false},{"type":"link","label":"@mozilla/readability","href":"/docs/integrations/document_transformers/mozilla_readability","docId":"integrations/document_transformers/mozilla_readability","unlisted":false},{"type":"link","label":"OpenAI functions metadata tagger","href":"/docs/integrations/document_transformers/openai_metadata_tagger","docId":"integrations/document_transformers/openai_metadata_tagger","unlisted":false}],"collapsible":true,"href":"/docs/integrations/document_transformers"},{"type":"category","label":"Vector stores","collapsed":true,"items":[{"type":"link","label":"Memory","href":"/docs/integrations/vectorstores/memory","docId":"integrations/vectorstores/memory","unlisted":false},{"type":"link","label":"AnalyticDB","href":"/docs/integrations/vectorstores/analyticdb","className":"node-only","docId":"integrations/vectorstores/analyticdb","unlisted":false},{"type":"link","label":"Astra DB","href":"/docs/integrations/vectorstores/astradb","className":"node-only","docId":"integrations/vectorstores/astradb","unlisted":false},{"type":"link","label":"Azure AI Search","href":"/docs/integrations/vectorstores/azure_aisearch","docId":"integrations/vectorstores/azure_aisearch","unlisted":false},{"type":"link","label":"Azure Cosmos DB","href":"/docs/integrations/vectorstores/azure_cosmosdb","docId":"integrations/vectorstores/azure_cosmosdb","unlisted":false},{"type":"link","label":"Cassandra","href":"/docs/integrations/vectorstores/cassandra","className":"node-only","docId":"integrations/vectorstores/cassandra","unlisted":false},{"type":"link","label":"Chroma","href":"/docs/integrations/vectorstores/chroma","docId":"integrations/vectorstores/chroma","unlisted":false},{"type":"link","label":"ClickHouse","href":"/docs/integrations/vectorstores/clickhouse","className":"node-only","docId":"integrations/vectorstores/clickhouse","unlisted":false},{"type":"link","label":"CloseVector","href":"/docs/integrations/vectorstores/closevector","docId":"integrations/vectorstores/closevector","unlisted":false},{"type":"link","label":"Cloudflare Vectorize","href":"/docs/integrations/vectorstores/cloudflare_vectorize","docId":"integrations/vectorstores/cloudflare_vectorize","unlisted":false},{"type":"link","label":"Convex","href":"/docs/integrations/vectorstores/convex","className":"node-only","docId":"integrations/vectorstores/convex","unlisted":false},{"type":"link","label":"Couchbase","href":"/docs/integrations/vectorstores/couchbase","className":"node-only","docId":"integrations/vectorstores/couchbase","unlisted":false},{"type":"link","label":"Elasticsearch","href":"/docs/integrations/vectorstores/elasticsearch","className":"node-only","docId":"integrations/vectorstores/elasticsearch","unlisted":false},{"type":"link","label":"Faiss","href":"/docs/integrations/vectorstores/faiss","className":"node-only","docId":"integrations/vectorstores/faiss","unlisted":false},{"type":"link","label":"Google Vertex AI Matching Engine","href":"/docs/integrations/vectorstores/googlevertexai","className":"node-only","docId":"integrations/vectorstores/googlevertexai","unlisted":false},{"type":"link","label":"SAP HANA Cloud Vector Engine","href":"/docs/integrations/vectorstores/hanavector","docId":"integrations/vectorstores/hanavector","unlisted":false},{"type":"link","label":"HNSWLib","href":"/docs/integrations/vectorstores/hnswlib","className":"node-only","docId":"integrations/vectorstores/hnswlib","unlisted":false},{"type":"link","label":"LanceDB","href":"/docs/integrations/vectorstores/lancedb","className":"node-only","docId":"integrations/vectorstores/lancedb","unlisted":false},{"type":"link","label":"Milvus","href":"/docs/integrations/vectorstores/milvus","className":"node-only","docId":"integrations/vectorstores/milvus","unlisted":false},{"type":"link","label":"Momento Vector Index (MVI)","href":"/docs/integrations/vectorstores/momento_vector_index","docId":"integrations/vectorstores/momento_vector_index","unlisted":false},{"type":"link","label":"MyScale","href":"/docs/integrations/vectorstores/myscale","className":"node-only","docId":"integrations/vectorstores/myscale","unlisted":false},{"type":"link","label":"Neo4j Vector Index","href":"/docs/integrations/vectorstores/neo4jvector","docId":"integrations/vectorstores/neo4jvector","unlisted":false},{"type":"link","label":"Neon Postgres","href":"/docs/integrations/vectorstores/neon","docId":"integrations/vectorstores/neon","unlisted":false},{"type":"link","label":"OpenSearch","href":"/docs/integrations/vectorstores/opensearch","className":"node-only","docId":"integrations/vectorstores/opensearch","unlisted":false},{"type":"link","label":"PGVector","href":"/docs/integrations/vectorstores/pgvector","docId":"integrations/vectorstores/pgvector","unlisted":false},{"type":"link","label":"Pinecone","href":"/docs/integrations/vectorstores/pinecone","docId":"integrations/vectorstores/pinecone","unlisted":false},{"type":"link","label":"Prisma","href":"/docs/integrations/vectorstores/prisma","className":"node-only","docId":"integrations/vectorstores/prisma","unlisted":false},{"type":"link","label":"Qdrant","href":"/docs/integrations/vectorstores/qdrant","className":"node-only","docId":"integrations/vectorstores/qdrant","unlisted":false},{"type":"link","label":"Redis","href":"/docs/integrations/vectorstores/redis","className":"node-only","docId":"integrations/vectorstores/redis","unlisted":false},{"type":"link","label":"Rockset","href":"/docs/integrations/vectorstores/rockset","className":"node-only","docId":"integrations/vectorstores/rockset","unlisted":false},{"type":"link","label":"SingleStore","href":"/docs/integrations/vectorstores/singlestore","className":"node-only","docId":"integrations/vectorstores/singlestore","unlisted":false},{"type":"link","label":"Supabase","href":"/docs/integrations/vectorstores/supabase","docId":"integrations/vectorstores/supabase","unlisted":false},{"type":"link","label":"tigris","href":"/docs/integrations/vectorstores/tigris","className":"node-only","docId":"integrations/vectorstores/tigris","unlisted":false},{"type":"link","label":"Turbopuffer","href":"/docs/integrations/vectorstores/turbopuffer","docId":"integrations/vectorstores/turbopuffer","unlisted":false},{"type":"link","label":"TypeORM","href":"/docs/integrations/vectorstores/typeorm","docId":"integrations/vectorstores/typeorm","unlisted":false},{"type":"link","label":"Typesense","href":"/docs/integrations/vectorstores/typesense","docId":"integrations/vectorstores/typesense","unlisted":false},{"type":"link","label":"Upstash Vector","href":"/docs/integrations/vectorstores/upstash","docId":"integrations/vectorstores/upstash","unlisted":false},{"type":"link","label":"USearch","href":"/docs/integrations/vectorstores/usearch","className":"node-only","docId":"integrations/vectorstores/usearch","unlisted":false},{"type":"link","label":"Vectara","href":"/docs/integrations/vectorstores/vectara","className":"node-only","docId":"integrations/vectorstores/vectara","unlisted":false},{"type":"link","label":"Vercel Postgres","href":"/docs/integrations/vectorstores/vercel_postgres","docId":"integrations/vectorstores/vercel_postgres","unlisted":false},{"type":"link","label":"Voy","href":"/docs/integrations/vectorstores/voy","docId":"integrations/vectorstores/voy","unlisted":false},{"type":"link","label":"Weaviate","href":"/docs/integrations/vectorstores/weaviate","docId":"integrations/vectorstores/weaviate","unlisted":false},{"type":"link","label":"Xata","href":"/docs/integrations/vectorstores/xata","docId":"integrations/vectorstores/xata","unlisted":false},{"type":"link","label":"Zep","href":"/docs/integrations/vectorstores/zep","docId":"integrations/vectorstores/zep","unlisted":false}],"collapsible":true,"href":"/docs/integrations/vectorstores"},{"type":"category","label":"Retrievers","collapsed":true,"items":[{"type":"link","label":"Knowledge Bases for Amazon Bedrock","href":"/docs/integrations/retrievers/bedrock-knowledge-bases","docId":"integrations/retrievers/bedrock-knowledge-bases","unlisted":false},{"type":"link","label":"Chaindesk Retriever","href":"/docs/integrations/retrievers/chaindesk-retriever","docId":"integrations/retrievers/chaindesk-retriever","unlisted":false},{"type":"link","label":"ChatGPT Plugin Retriever","href":"/docs/integrations/retrievers/chatgpt-retriever-plugin","docId":"integrations/retrievers/chatgpt-retriever-plugin","unlisted":false},{"type":"link","label":"Dria Retriever","href":"/docs/integrations/retrievers/dria","docId":"integrations/retrievers/dria","unlisted":false},{"type":"link","label":"Exa Search","href":"/docs/integrations/retrievers/exa","docId":"integrations/retrievers/exa","unlisted":false},{"type":"link","label":"HyDE Retriever","href":"/docs/integrations/retrievers/hyde","docId":"integrations/retrievers/hyde","unlisted":false},{"type":"link","label":"Amazon Kendra Retriever","href":"/docs/integrations/retrievers/kendra-retriever","docId":"integrations/retrievers/kendra-retriever","unlisted":false},{"type":"link","label":"Metal Retriever","href":"/docs/integrations/retrievers/metal-retriever","docId":"integrations/retrievers/metal-retriever","unlisted":false},{"type":"category","label":"Self-querying retrievers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Chroma Self Query Retriever","href":"/docs/integrations/retrievers/self_query/chroma","docId":"integrations/retrievers/self_query/chroma","unlisted":false},{"type":"link","label":"HNSWLib Self Query Retriever","href":"/docs/integrations/retrievers/self_query/hnswlib","docId":"integrations/retrievers/self_query/hnswlib","unlisted":false},{"type":"link","label":"Memory Vector Store Self Query Retriever","href":"/docs/integrations/retrievers/self_query/memory","docId":"integrations/retrievers/self_query/memory","unlisted":false},{"type":"link","label":"Pinecone Self Query Retriever","href":"/docs/integrations/retrievers/self_query/pinecone","docId":"integrations/retrievers/self_query/pinecone","unlisted":false},{"type":"link","label":"Qdrant Self Query Retriever","href":"/docs/integrations/retrievers/self_query/qdrant","docId":"integrations/retrievers/self_query/qdrant","unlisted":false},{"type":"link","label":"Supabase Self Query Retriever","href":"/docs/integrations/retrievers/self_query/supabase","docId":"integrations/retrievers/self_query/supabase","unlisted":false},{"type":"link","label":"Vectara Self Query Retriever","href":"/docs/integrations/retrievers/self_query/vectara","docId":"integrations/retrievers/self_query/vectara","unlisted":false},{"type":"link","label":"Weaviate Self Query Retriever","href":"/docs/integrations/retrievers/self_query/weaviate","docId":"integrations/retrievers/self_query/weaviate","unlisted":false}],"href":"/docs/integrations/retrievers/self_query/"},{"type":"link","label":"Supabase Hybrid Search","href":"/docs/integrations/retrievers/supabase-hybrid","docId":"integrations/retrievers/supabase-hybrid","unlisted":false},{"type":"link","label":"Tavily Search API","href":"/docs/integrations/retrievers/tavily","docId":"integrations/retrievers/tavily","unlisted":false},{"type":"link","label":"Time-Weighted Retriever","href":"/docs/integrations/retrievers/time-weighted-retriever","docId":"integrations/retrievers/time-weighted-retriever","unlisted":false},{"type":"link","label":"Vector Store","href":"/docs/integrations/retrievers/vectorstore","docId":"integrations/retrievers/vectorstore","unlisted":false},{"type":"link","label":"Vespa Retriever","href":"/docs/integrations/retrievers/vespa-retriever","docId":"integrations/retrievers/vespa-retriever","unlisted":false},{"type":"link","label":"Zep Retriever","href":"/docs/integrations/retrievers/zep-retriever","docId":"integrations/retrievers/zep-retriever","unlisted":false}],"collapsible":true,"href":"/docs/integrations/retrievers"},{"type":"category","label":"Tools","collapsed":true,"items":[{"type":"link","label":"ChatGPT Plugins","href":"/docs/integrations/tools/aiplugin-tool","docId":"integrations/tools/aiplugin-tool","unlisted":false},{"type":"link","label":"Connery Action Tool","href":"/docs/integrations/tools/connery","docId":"integrations/tools/connery","unlisted":false},{"type":"link","label":"Dall-E Tool","href":"/docs/integrations/tools/dalle","docId":"integrations/tools/dalle","unlisted":false},{"type":"link","label":"Discord Tool","href":"/docs/integrations/tools/discord","docId":"integrations/tools/discord","unlisted":false},{"type":"link","label":"DuckDuckGoSearch","href":"/docs/integrations/tools/duckduckgo_search","docId":"integrations/tools/duckduckgo_search","unlisted":false},{"type":"link","label":"Exa Search","href":"/docs/integrations/tools/exa_search","docId":"integrations/tools/exa_search","unlisted":false},{"type":"link","label":"Gmail Tool","href":"/docs/integrations/tools/gmail","docId":"integrations/tools/gmail","unlisted":false},{"type":"link","label":"Google Calendar Tool","href":"/docs/integrations/tools/google_calendar","docId":"integrations/tools/google_calendar","unlisted":false},{"type":"link","label":"Google Places Tool","href":"/docs/integrations/tools/google_places","docId":"integrations/tools/google_places","unlisted":false},{"type":"link","label":"Google Routes Tool","href":"/docs/integrations/tools/google_routes","docId":"integrations/tools/google_routes","unlisted":false},{"type":"link","label":"Agent with AWS Lambda","href":"/docs/integrations/tools/lambda_agent","docId":"integrations/tools/lambda_agent","unlisted":false},{"type":"link","label":"Python interpreter tool","href":"/docs/integrations/tools/pyinterpreter","docId":"integrations/tools/pyinterpreter","unlisted":false},{"type":"link","label":"SearchApi tool","href":"/docs/integrations/tools/searchapi","docId":"integrations/tools/searchapi","unlisted":false},{"type":"link","label":"Searxng Search tool","href":"/docs/integrations/tools/searxng","docId":"integrations/tools/searxng","unlisted":false},{"type":"link","label":"StackExchange Tool","href":"/docs/integrations/tools/stackexchange","docId":"integrations/tools/stackexchange","unlisted":false},{"type":"link","label":"Tavily Search","href":"/docs/integrations/tools/tavily_search","docId":"integrations/tools/tavily_search","unlisted":false},{"type":"link","label":"Web Browser Tool","href":"/docs/integrations/tools/webbrowser","docId":"integrations/tools/webbrowser","unlisted":false},{"type":"link","label":"Wikipedia tool","href":"/docs/integrations/tools/wikipedia","docId":"integrations/tools/wikipedia","unlisted":false},{"type":"link","label":"WolframAlpha Tool","href":"/docs/integrations/tools/wolframalpha","docId":"integrations/tools/wolframalpha","unlisted":false},{"type":"link","label":"Agent with Zapier NLA Integration","href":"/docs/integrations/tools/zapier_agent","className":"hidden","docId":"integrations/tools/zapier_agent","unlisted":false}],"collapsible":true,"href":"/docs/integrations/tools"},{"type":"category","label":"Toolkits","collapsed":true,"items":[{"type":"link","label":"Connery Toolkit","href":"/docs/integrations/toolkits/connery","docId":"integrations/toolkits/connery","unlisted":false},{"type":"link","label":"JSON Agent Toolkit","href":"/docs/integrations/toolkits/json","docId":"integrations/toolkits/json","unlisted":false},{"type":"link","label":"OpenAPI Agent Toolkit","href":"/docs/integrations/toolkits/openapi","docId":"integrations/toolkits/openapi","unlisted":false},{"type":"link","label":"AWS Step Functions Toolkit","href":"/docs/integrations/toolkits/sfn_agent","docId":"integrations/toolkits/sfn_agent","unlisted":false},{"type":"link","label":"SQL Agent Toolkit","href":"/docs/integrations/toolkits/sql","docId":"integrations/toolkits/sql","unlisted":false},{"type":"link","label":"VectorStore Agent Toolkit","href":"/docs/integrations/toolkits/vectorstore","docId":"integrations/toolkits/vectorstore","unlisted":false}],"collapsible":true,"href":"/docs/integrations/toolkits"},{"type":"category","label":"Stores","collapsed":true,"items":[{"type":"link","label":"Cassandra KV","href":"/docs/integrations/stores/cassandra_storage","className":"node-only","docId":"integrations/stores/cassandra_storage","unlisted":false},{"type":"link","label":"File System Store","href":"/docs/integrations/stores/file_system","className":"node-only","docId":"integrations/stores/file_system","unlisted":false},{"type":"link","label":"In Memory Store","href":"/docs/integrations/stores/in_memory","docId":"integrations/stores/in_memory","unlisted":false},{"type":"link","label":"Stores","href":"/docs/integrations/stores/","className":"hidden","docId":"integrations/stores/index","unlisted":false},{"type":"link","label":"IORedis","href":"/docs/integrations/stores/ioredis_storage","docId":"integrations/stores/ioredis_storage","unlisted":false},{"type":"link","label":"Upstash Redis","href":"/docs/integrations/stores/upstash_redis_storage","docId":"integrations/stores/upstash_redis_storage","unlisted":false},{"type":"link","label":"Vercel KV","href":"/docs/integrations/stores/vercel_kv_storage","docId":"integrations/stores/vercel_kv_storage","unlisted":false}],"collapsible":true,"href":"/docs/integrations/stores/"}],"collapsed":false,"href":"/docs/integrations/components"}]},"docs":{"concepts":{"id":"concepts","title":"\uac1c\ub150 \uac00\uc774\ub4dc","description":"\uc774 \uc139\uc158\uc5d0\ub294 LangChain\uc758 \uc8fc\uc694 \ud30c\ud2b8\uc5d0 \ub300\ud55c \uc18c\uac1c\ub97c \ub2f4\uace0 \uc788\uc2b5\ub2c8\ub2e4.","sidebar":"tutorialSidebar"},"contributing/code":{"id":"contributing/code","title":"Contribute Code","description":"To contribute to this project, please follow the \\"fork and pull request\\" workflow."},"contributing/documentation/style_guide":{"id":"contributing/documentation/style_guide","title":"LangChain Documentation Style Guide","description":"Introduction"},"contributing/faq":{"id":"contributing/faq","title":"Frequently Asked Questions","description":"Pull Requests (PRs)"},"contributing/index":{"id":"contributing/index","title":"Welcome Contributors","description":"Hi there! Thank you for even being interested in contributing to LangChain."},"contributing/integrations":{"id":"contributing/integrations","title":"Contribute Integrations","description":"To begin, make sure you have all the dependencies outlined in guide on Contributing Code."},"contributing/repo_structure":{"id":"contributing/repo_structure","title":"Repository Structure","description":"If you plan on contributing to LangChain code or documentation, it can be useful"},"contributing/testing":{"id":"contributing/testing","title":"Testing","description":"In general, tests should be added within a tests/ folder alongside the modules they"},"how_to/agent_executor":{"id":"how_to/agent_executor","title":"How to use legacy LangChain Agents (AgentExecutor)","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/assign":{"id":"how_to/assign","title":"How to add values to a chain\'s state","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/binding":{"id":"how_to/binding","title":"How to attach runtime arguments to a Runnable","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/caching_embeddings":{"id":"how_to/caching_embeddings","title":"How to cache embedding results","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/callbacks_attach":{"id":"how_to/callbacks_attach","title":"How to attach callbacks to a module","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/callbacks_backgrounding":{"id":"how_to/callbacks_backgrounding","title":"How to make callbacks run in the background","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/callbacks_constructor":{"id":"how_to/callbacks_constructor","title":"How to pass callbacks into a module constructor","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/callbacks_runtime":{"id":"how_to/callbacks_runtime","title":"How to pass callbacks in at runtime","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/character_text_splitter":{"id":"how_to/character_text_splitter","title":"How to split by character","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/chat_model_caching":{"id":"how_to/chat_model_caching","title":"How to cache chat model responses","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/chat_streaming":{"id":"how_to/chat_streaming","title":"How to stream chat model responses","description":"All [chat","sidebar":"tutorialSidebar"},"how_to/chat_token_usage_tracking":{"id":"how_to/chat_token_usage_tracking","title":"How to track token usage","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/chatbots_memory":{"id":"how_to/chatbots_memory","title":"How to manage memory","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/chatbots_retrieval":{"id":"how_to/chatbots_retrieval","title":"How to do retrieval","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/chatbots_tools":{"id":"how_to/chatbots_tools","title":"How to use tools","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/code_splitter":{"id":"how_to/code_splitter","title":"How to split code","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/contextual_compression":{"id":"how_to/contextual_compression","title":"How to do retrieval with contextual compression","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/custom_callbacks":{"id":"how_to/custom_callbacks","title":"How to create custom callback handlers","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/custom_chat":{"id":"how_to/custom_chat","title":"How to create a custom chat model class","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/custom_llm":{"id":"how_to/custom_llm","title":"How to create a custom LLM class","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/custom_retriever":{"id":"how_to/custom_retriever","title":"How to write a custom retriever class","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/custom_tools":{"id":"how_to/custom_tools","title":"How to create custom Tools","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/debugging":{"id":"how_to/debugging","title":"How to debug your LLM apps","description":"Like building any type of software, at some point you\'ll need to debug when building with LLMs.","sidebar":"tutorialSidebar"},"how_to/document_loader_csv":{"id":"how_to/document_loader_csv","title":"How to load CSV data","description":"A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas.","sidebar":"tutorialSidebar"},"how_to/document_loader_custom":{"id":"how_to/document_loader_custom","title":"How to write a custom document loader","description":"If you want to implement your own Document Loader, you have a few options.","sidebar":"tutorialSidebar"},"how_to/document_loader_directory":{"id":"how_to/document_loader_directory","title":"How to load data from a directory","description":"This covers how to load all documents in a directory.","sidebar":"tutorialSidebar"},"how_to/document_loader_html":{"id":"how_to/document_loader_html","title":"How to load HTML","description":"The HyperText Markup Language or","sidebar":"tutorialSidebar"},"how_to/document_loader_markdown":{"id":"how_to/document_loader_markdown","title":"How to load Markdown","description":"Markdown is a lightweight","sidebar":"tutorialSidebar"},"how_to/document_loader_pdf":{"id":"how_to/document_loader_pdf","title":"How to load PDF files","description":"Portable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.","sidebar":"tutorialSidebar"},"how_to/document_loaders_json":{"id":"how_to/document_loaders_json","title":"How to load JSON data","description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute\u2013value pairs and arrays (or other serializable values).","sidebar":"tutorialSidebar"},"how_to/embed_text":{"id":"how_to/embed_text","title":"How to embed text data","description":"Head to Integrations for documentation on built-in integrations with text embedding providers.","sidebar":"tutorialSidebar"},"how_to/example_selectors":{"id":"how_to/example_selectors","title":"How to use example selectors","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/example_selectors_length_based":{"id":"how_to/example_selectors_length_based","title":"How to select examples by length","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/example_selectors_similarity":{"id":"how_to/example_selectors_similarity","title":"How to select examples by similarity","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/extraction_examples":{"id":"how_to/extraction_examples","title":"How to use reference examples","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/extraction_long_text":{"id":"how_to/extraction_long_text","title":"How to handle long text","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/extraction_parse":{"id":"how_to/extraction_parse","title":"How to do extraction without using function calling","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/fallbacks":{"id":"how_to/fallbacks","title":"Fallbacks","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/few_shot":{"id":"how_to/few_shot","title":"Few Shot Prompt Templates","description":"Few shot prompting is a prompting technique which provides the Large Language Model (LLM) with a list of examples, and then asks the LLM to generate some text following the lead of the examples provided.","sidebar":"tutorialSidebar"},"how_to/few_shot_examples":{"id":"how_to/few_shot_examples","title":"How to use few shot examples","description":"In this guide, we\u2019ll learn how to create a simple prompt template that","sidebar":"tutorialSidebar"},"how_to/few_shot_examples_chat":{"id":"how_to/few_shot_examples_chat","title":"How to use few shot examples in chat models","description":"This guide covers how to prompt a chat model with example inputs and","sidebar":"tutorialSidebar"},"how_to/functions":{"id":"how_to/functions","title":"How to run custom functions","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/graph_constructing":{"id":"how_to/graph_constructing","title":"How to construct knowledge graphs","description":"In this guide we\u2019ll go over the basic ways of constructing a knowledge","sidebar":"tutorialSidebar"},"how_to/graph_mapping":{"id":"how_to/graph_mapping","title":"How to map values to a database","description":"In this guide we\u2019ll go over strategies to improve graph database query","sidebar":"tutorialSidebar"},"how_to/graph_prompting":{"id":"how_to/graph_prompting","title":"How to improve results with prompting","description":"In this guide we\u2019ll go over prompting strategies to improve graph","sidebar":"tutorialSidebar"},"how_to/graph_semantic":{"id":"how_to/graph_semantic","title":"How to add a semantic layer over the database","description":"You can use database queries to retrieve information from a graph","sidebar":"tutorialSidebar"},"how_to/index":{"id":"how_to/index","title":"\uc0ac\uc6a9 \uac00\uc774\ub4dc","description":"\uc5ec\uae30\uc5d0\ub294 \\"~\ub97c \uc5b4\ub5bb\uac8c \ud558\uc9c0?\\" \uc720\ud615\uc758 \uc9c8\ubb38\uc5d0 \ub300\ud55c \ub2f5\ubcc0\uc774 \ub098\uc640 \uc788\uc2b5\ub2c8\ub2e4.","sidebar":"tutorialSidebar"},"how_to/indexing":{"id":"how_to/indexing","title":"How to reindex data to keep your vectorstore in-sync with the underlying data source","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/installation":{"id":"how_to/installation","title":"Installation","description":"Supported Environments","sidebar":"tutorialSidebar"},"how_to/lcel_cheatsheet":{"id":"how_to/lcel_cheatsheet","title":"LangChain Expression Language Cheatsheet","description":"This is a quick reference for all the most important LCEL primitives.","sidebar":"tutorialSidebar"},"how_to/llm_caching":{"id":"how_to/llm_caching","title":"How to cache model responses","description":"LangChain provides an optional caching layer for LLMs. This is useful for two reasons:","sidebar":"tutorialSidebar"},"how_to/llm_token_usage_tracking":{"id":"how_to/llm_token_usage_tracking","title":"How to track token usage","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/logprobs":{"id":"how_to/logprobs","title":"How to get log probabilities","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/message_history":{"id":"how_to/message_history","title":"How to add message history","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/multi_vector":{"id":"how_to/multi_vector","title":"How to generate multiple embeddings per document","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/multiple_queries":{"id":"how_to/multiple_queries","title":"How to generate multiple queries to retrieve data for","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/output_parser_fixing":{"id":"how_to/output_parser_fixing","title":"How to try to fix errors in output parsing","description":"This guide assumes familiarity with the following concepts: - [Chat","sidebar":"tutorialSidebar"},"how_to/output_parser_json":{"id":"how_to/output_parser_json","title":"How to parse JSON output","description":"While some model providers support [built-in ways to return structured","sidebar":"tutorialSidebar"},"how_to/output_parser_structured":{"id":"how_to/output_parser_structured","title":"How to use output parsers to parse an LLM response into structured format","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/output_parser_xml":{"id":"how_to/output_parser_xml","title":"How to parse XML output","description":"This guide assumes familiarity with the following concepts: - [Chat","sidebar":"tutorialSidebar"},"how_to/parallel":{"id":"how_to/parallel","title":"How to invoke runnables in parallel","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/parent_document_retriever":{"id":"how_to/parent_document_retriever","title":"How to retrieve the whole document for a chunk","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/passthrough":{"id":"how_to/passthrough","title":"How to pass through arguments from one step to the next","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/prompts_composition":{"id":"how_to/prompts_composition","title":"How to compose prompts together","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/prompts_partial":{"id":"how_to/prompts_partial","title":"How to partially format prompt templates","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/qa_chat_history_how_to":{"id":"how_to/qa_chat_history_how_to","title":"How to add chat history to a question-answering chain","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/qa_citations":{"id":"how_to/qa_citations","title":"How to return citations","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/qa_per_user":{"id":"how_to/qa_per_user","title":"How to do per-user retrieval","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/qa_sources":{"id":"how_to/qa_sources","title":"How to return sources","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/qa_streaming":{"id":"how_to/qa_streaming","title":"How to stream from a question-answering chain","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/query_constructing_filters":{"id":"how_to/query_constructing_filters","title":"How to construct filters","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/query_few_shot":{"id":"how_to/query_few_shot","title":"How to add examples to the prompt","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/query_high_cardinality":{"id":"how_to/query_high_cardinality","title":"How to deal with high cardinality categorical variables","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/query_multiple_queries":{"id":"how_to/query_multiple_queries","title":"How to handle multiple queries","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/query_multiple_retrievers":{"id":"how_to/query_multiple_retrievers","title":"How to handle multiple retrievers","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/query_no_queries":{"id":"how_to/query_no_queries","title":"How to handle cases where no queries are generated","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/recursive_text_splitter":{"id":"how_to/recursive_text_splitter","title":"How to recursively split text by characters","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/reduce_retrieval_latency":{"id":"how_to/reduce_retrieval_latency","title":"How to reduce retrieval latency","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/routing":{"id":"how_to/routing","title":"How to route execution within a chain","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/self_query":{"id":"how_to/self_query","title":"How to do \\"self-querying\\" retrieval","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/sequence":{"id":"how_to/sequence","title":"How to chain runnables","description":"One point about [LangChain Expression","sidebar":"tutorialSidebar"},"how_to/split_by_token":{"id":"how_to/split_by_token","title":"How to split text by tokens","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/sql_large_db":{"id":"how_to/sql_large_db","title":"How to deal with large databases","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/sql_prompting":{"id":"how_to/sql_prompting","title":"How to use prompting to improve results","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/sql_query_checking":{"id":"how_to/sql_query_checking","title":"How to do query validation","description":"This guide assumes familiarity with the following:","sidebar":"tutorialSidebar"},"how_to/streaming":{"id":"how_to/streaming","title":"How to stream","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/streaming_llm":{"id":"how_to/streaming_llm","title":"How to stream responses from an LLM","description":"All LLMs implement the Runnable interface, which comes with default implementations of standard runnable methods (i.e. ainvoke, batch, abatch, stream, astream, astream_events).","sidebar":"tutorialSidebar"},"how_to/structured_output":{"id":"how_to/structured_output","title":"How to return structured data from a model","description":"It is often useful to have a model return output that matches some","sidebar":"tutorialSidebar"},"how_to/time_weighted_vectorstore":{"id":"how_to/time_weighted_vectorstore","title":"How to create a time-weighted retriever","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/tool_calling":{"id":"how_to/tool_calling","title":"How to use a chat model to call tools","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/tool_calls_multi_modal":{"id":"how_to/tool_calls_multi_modal","title":"How to call tools with multi-modal data","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/tools_builtin":{"id":"how_to/tools_builtin","title":"How to use LangChain tools","description":"Tools are interfaces that an agent, chain, or LLM can use to interact","sidebar":"tutorialSidebar"},"how_to/tools_prompting":{"id":"how_to/tools_prompting","title":"How to add ad-hoc tool calling capability to LLMs and Chat Models","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/vectorstore_retriever":{"id":"how_to/vectorstore_retriever","title":"How use a vector store to retrieve data","description":"This guide assumes familiarity with the following concepts:","sidebar":"tutorialSidebar"},"how_to/vectorstores":{"id":"how_to/vectorstores","title":"How to create and query vector stores","description":"Head to Integrations for documentation on built-in integrations with vectorstore providers.","sidebar":"tutorialSidebar"},"integrations/chat_memory/astradb":{"id":"integrations/chat_memory/astradb","title":"Astra DB Chat Memory","description":"For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory that backs chat memory classes like BufferMemory for Astra DB."},"integrations/chat_memory/cassandra":{"id":"integrations/chat_memory/cassandra","title":"Cassandra Chat Memory","description":"For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory that backs chat memory classes like BufferMemory for a Cassandra cluster."},"integrations/chat_memory/cloudflare_d1":{"id":"integrations/chat_memory/cloudflare_d1","title":"Cloudflare D1-Backed Chat Memory","description":"This integration is only supported in Cloudflare Workers."},"integrations/chat_memory/convex":{"id":"integrations/chat_memory/convex","title":"Convex Chat Memory","description":"For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory that backs chat memory classes like BufferMemory for Convex."},"integrations/chat_memory/dynamodb":{"id":"integrations/chat_memory/dynamodb","title":"DynamoDB-Backed Chat Memory","description":"For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory that backs chat memory classes like BufferMemory for a DynamoDB instance."},"integrations/chat_memory/firestore":{"id":"integrations/chat_memory/firestore","title":"Firestore Chat Memory","description":"For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory that backs chat memory classes like BufferMemory for a firestore."},"integrations/chat_memory/ipfs_datastore":{"id":"integrations/chat_memory/ipfs_datastore","title":"IPFS Datastore Chat Memory","description":"For a storage backend you can use the IPFS Datastore Chat Memory to wrap an IPFS Datastore allowing you to use any IPFS compatible datastore."},"integrations/chat_memory/momento":{"id":"integrations/chat_memory/momento","title":"Momento-Backed Chat Memory","description":"For distributed, serverless persistence across chat sessions, you can swap in a Momento-backed chat message history."},"integrations/chat_memory/mongodb":{"id":"integrations/chat_memory/mongodb","title":"MongoDB Chat Memory","description":"Only available on Node.js."},"integrations/chat_memory/motorhead_memory":{"id":"integrations/chat_memory/motorhead_memory","title":"Mot\xf6rhead Memory","description":"Mot\xf6rhead is a memory server implemented in Rust. It automatically handles incremental summarization in the background and allows for stateless applications."},"integrations/chat_memory/planetscale":{"id":"integrations/chat_memory/planetscale","title":"PlanetScale Chat Memory","description":"Because PlanetScale works via a REST API, you can use this with Vercel Edge, Cloudflare Workers and other Serverless environments."},"integrations/chat_memory/postgres":{"id":"integrations/chat_memory/postgres","title":"Postgres Chat Memory","description":"For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory for a Postgres Database."},"integrations/chat_memory/redis":{"id":"integrations/chat_memory/redis","title":"Redis-Backed Chat Memory","description":"For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory that backs chat memory classes like BufferMemory for a Redis instance."},"integrations/chat_memory/upstash_redis":{"id":"integrations/chat_memory/upstash_redis","title":"Upstash Redis-Backed Chat Memory","description":"Because Upstash Redis works via a REST API, you can use this with Vercel Edge, Cloudflare Workers and other Serverless environments."},"integrations/chat_memory/xata":{"id":"integrations/chat_memory/xata","title":"Xata Chat Memory","description":"Xata is a serverless data platform, based on PostgreSQL. It provides a type-safe TypeScript/JavaScript SDK for interacting with your database, and a"},"integrations/chat_memory/zep_memory":{"id":"integrations/chat_memory/zep_memory","title":"Zep Memory","description":"Recall, understand, and extract data from chat histories. Power personalized AI experiences."},"integrations/chat/alibaba_tongyi":{"id":"integrations/chat/alibaba_tongyi","title":"ChatAlibabaTongyi","description":"LangChain.js supports the Alibaba qwen family of models.","sidebar":"integrations"},"integrations/chat/anthropic":{"id":"integrations/chat/anthropic","title":"ChatAnthropic","description":"LangChain supports Anthropic\'s Claude family of chat models.","sidebar":"integrations"},"integrations/chat/anthropic_tools":{"id":"integrations/chat/anthropic_tools","title":"anthropic_tools","description":"This API is deprecated as Anthropic now officially supports tools. Click here to read the documentation.","sidebar":"integrations"},"integrations/chat/azure":{"id":"integrations/chat/azure","title":"Azure OpenAI","description":"Azure OpenAI is a cloud service to help you quickly develop generative AI experiences with a diverse set of prebuilt and curated models from OpenAI, Meta and beyond.","sidebar":"integrations"},"integrations/chat/baidu_wenxin":{"id":"integrations/chat/baidu_wenxin","title":"ChatBaiduWenxin","description":"LangChain.js supports Baidu\'s ERNIE-bot family of models. Here\'s an example:","sidebar":"integrations"},"integrations/chat/bedrock":{"id":"integrations/chat/bedrock","title":"BedrockChat","description":"Amazon Bedrock is a fully managed service that makes Foundation Models (FMs)","sidebar":"integrations"},"integrations/chat/cloudflare_workersai":{"id":"integrations/chat/cloudflare_workersai","title":"ChatCloudflareWorkersAI","description":"Workers AI allows you to run machine learning models, on the Cloudflare network, from your own code.","sidebar":"integrations"},"integrations/chat/cohere":{"id":"integrations/chat/cohere","title":"ChatCohere","description":"The Cohere Chat API is still in beta. This means Cohere may make breaking changes at any time.","sidebar":"integrations"},"integrations/chat/fake":{"id":"integrations/chat/fake","title":"Fake LLM","description":"LangChain provides a fake LLM chat model for testing purposes. This allows you to mock out calls to the LLM and and simulate what would happen if the LLM responded in a certain way.","sidebar":"integrations"},"integrations/chat/fireworks":{"id":"integrations/chat/fireworks","title":"ChatFireworks","description":"You can use models provided by Fireworks AI as follows:","sidebar":"integrations"},"integrations/chat/friendli":{"id":"integrations/chat/friendli","title":"Friendli","description":"Friendli enhances AI application performance and optimizes cost savings with scalable, efficient deployment options, tailored for high-demand AI workloads.","sidebar":"integrations"},"integrations/chat/google_generativeai":{"id":"integrations/chat/google_generativeai","title":"ChatGoogleGenerativeAI","description":"You can access Google\'s gemini and gemini-vision models, as well as other","sidebar":"integrations"},"integrations/chat/google_palm":{"id":"integrations/chat/google_palm","title":"ChatGooglePaLM","description":"This integration does not support gemini-* models. Check Google GenAI or VertexAI.","sidebar":"integrations"},"integrations/chat/google_vertex_ai":{"id":"integrations/chat/google_vertex_ai","title":"ChatVertexAI","description":"LangChain.js supports Google Vertex AI chat models as an integration.","sidebar":"integrations"},"integrations/chat/groq":{"id":"integrations/chat/groq","title":"ChatGroq","description":"Setup","sidebar":"integrations"},"integrations/chat/index":{"id":"integrations/chat/index","title":"Chat models","description":"Features (natively supported)","sidebar":"integrations"},"integrations/chat/llama_cpp":{"id":"integrations/chat/llama_cpp","title":"Llama CPP","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/chat/minimax":{"id":"integrations/chat/minimax","title":"Minimax","description":"Minimax is a Chinese startup that provides natural language processing models for companies and individuals.","sidebar":"integrations"},"integrations/chat/mistral":{"id":"integrations/chat/mistral","title":"ChatMistralAI","description":"Mistral AI is a research organization and hosting platform for LLMs.","sidebar":"integrations"},"integrations/chat/ni_bittensor":{"id":"integrations/chat/ni_bittensor","title":"NIBittensorChatModel","description":"This module has been deprecated and is no longer supported. The documentation below will not work in versions 0.2.0 or later.","sidebar":"integrations"},"integrations/chat/ollama":{"id":"integrations/chat/ollama","title":"ChatOllama","description":"Ollama allows you to run open-source large language models, such as Llama 2, locally.","sidebar":"integrations"},"integrations/chat/ollama_functions":{"id":"integrations/chat/ollama_functions","title":"Ollama Functions","description":"LangChain offers an experimental wrapper around open source models run locally via Ollama","sidebar":"integrations"},"integrations/chat/openai":{"id":"integrations/chat/openai","title":"ChatOpenAI","description":"You can use OpenAI\'s chat models as follows:","sidebar":"integrations"},"integrations/chat/premai":{"id":"integrations/chat/premai","title":"ChatPrem","description":"Setup","sidebar":"integrations"},"integrations/chat/prompt_layer_openai":{"id":"integrations/chat/prompt_layer_openai","title":"PromptLayerChatOpenAI","description":"You can pass in the optional returnPromptLayerId boolean to get a promptLayerRequestId like below. Here is an example of getting the PromptLayerChatOpenAI requestID:","sidebar":"integrations"},"integrations/chat/togetherai":{"id":"integrations/chat/togetherai","title":"ChatTogetherAI","description":"Setup","sidebar":"integrations"},"integrations/chat/web_llm":{"id":"integrations/chat/web_llm","title":"WebLLM","description":"Only available in web environments.","sidebar":"integrations"},"integrations/chat/yandex":{"id":"integrations/chat/yandex","title":"ChatYandexGPT","description":"LangChain.js supports calling YandexGPT chat models.","sidebar":"integrations"},"integrations/chat/zhipuai":{"id":"integrations/chat/zhipuai","title":"ChatZhipuAI","description":"LangChain.js supports the Zhipu AI family of models.","sidebar":"integrations"},"integrations/document_compressors/cohere_rerank":{"id":"integrations/document_compressors/cohere_rerank","title":"Cohere Rerank","description":"Reranking documents can greatly improve any RAG application and document retrieval system."},"integrations/document_loaders/file_loaders/chatgpt":{"id":"integrations/document_loaders/file_loaders/chatgpt","title":"ChatGPT files","description":"This example goes over how to load conversations.json from your ChatGPT data export folder. You can get your data export by email by going to: ChatGPT -> (Profile) - Settings -> Export data -> Confirm export -> Check email.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/csv":{"id":"integrations/document_loaders/file_loaders/csv","title":"CSV files","description":"This example goes over how to load data from CSV files. The second argument is the column name to extract from the CSV file. One document will be created for each row in the CSV file. When column is not specified, each row is converted into a key/value pair with each key/value pair outputted to a new line in the document\'s pageContent. When column is specified, one document is created for each row, and the value of the specified column is used as the document\'s pageContent.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/directory":{"id":"integrations/document_loaders/file_loaders/directory","title":"Folders with multiple files","description":"This example goes over how to load data from folders with multiple files. The second argument is a map of file extensions to loader factories. Each file will be passed to the matching loader, and the resulting documents will be concatenated together.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/docx":{"id":"integrations/document_loaders/file_loaders/docx","title":"Docx files","description":"This example goes over how to load data from docx files.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/epub":{"id":"integrations/document_loaders/file_loaders/epub","title":"EPUB files","description":"This example goes over how to load data from EPUB files. By default, one document will be created for each chapter in the EPUB file, you can change this behavior by setting the splitChapters option to false.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/index":{"id":"integrations/document_loaders/file_loaders/index","title":"File Loaders","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/json":{"id":"integrations/document_loaders/file_loaders/json","title":"JSON files","description":"The JSON loader use JSON pointer to target keys in your JSON files you want to target.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/jsonlines":{"id":"integrations/document_loaders/file_loaders/jsonlines","title":"JSONLines files","description":"This example goes over how to load data from JSONLines or JSONL files. The second argument is a JSONPointer to the property to extract from each JSON object in the file. One document will be created for each JSON object in the file.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/notion_markdown":{"id":"integrations/document_loaders/file_loaders/notion_markdown","title":"Notion markdown export","description":"This example goes over how to load data from your Notion pages exported from the notion dashboard.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/openai_whisper_audio":{"id":"integrations/document_loaders/file_loaders/openai_whisper_audio","title":"Open AI Whisper Audio","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/pdf":{"id":"integrations/document_loaders/file_loaders/pdf","title":"PDF files","description":"This example goes over how to load data from PDF files. By default, one document will be created for each page in the PDF file, you can change this behavior by setting the splitPages option to false.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/pptx":{"id":"integrations/document_loaders/file_loaders/pptx","title":"PPTX files","description":"This example goes over how to load data from PPTX files. By default, one document will be created for all pages in the PPTX file.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/subtitles":{"id":"integrations/document_loaders/file_loaders/subtitles","title":"Subtitles","description":"This example goes over how to load data from subtitle files. One document will be created for each subtitles file.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/text":{"id":"integrations/document_loaders/file_loaders/text","title":"Text files","description":"This example goes over how to load data from text files.","sidebar":"integrations"},"integrations/document_loaders/file_loaders/unstructured":{"id":"integrations/document_loaders/file_loaders/unstructured","title":"Unstructured","description":"This example covers how to use Unstructured to load files of many types. Unstructured currently supports loading of text files, powerpoints, html, pdfs, images, and more.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/apify_dataset":{"id":"integrations/document_loaders/web_loaders/apify_dataset","title":"Apify Dataset","description":"This guide shows how to use Apify with LangChain to load documents from an Apify Dataset.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/assemblyai_audio_transcription":{"id":"integrations/document_loaders/web_loaders/assemblyai_audio_transcription","title":"AssemblyAI Audio Transcript","description":"This covers how to load audio (and video) transcripts as document objects from a file using the AssemblyAI API.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/azure_blob_storage_container":{"id":"integrations/document_loaders/web_loaders/azure_blob_storage_container","title":"Azure Blob Storage Container","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/azure_blob_storage_file":{"id":"integrations/document_loaders/web_loaders/azure_blob_storage_file","title":"Azure Blob Storage File","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/browserbase":{"id":"integrations/document_loaders/web_loaders/browserbase","title":"Browserbase Loader","description":"Description","sidebar":"integrations"},"integrations/document_loaders/web_loaders/college_confidential":{"id":"integrations/document_loaders/web_loaders/college_confidential","title":"College Confidential","description":"This example goes over how to load data from the college confidential website, using Cheerio. One document will be created for each page.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/confluence":{"id":"integrations/document_loaders/web_loaders/confluence","title":"Confluence","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/couchbase":{"id":"integrations/document_loaders/web_loaders/couchbase","title":"Couchbase","description":"Couchbase is an award-winning distributed NoSQL cloud database that delivers unmatched versatility, performance, scalability, and financial value for all of your cloud, mobile, AI, and edge computing applications.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/figma":{"id":"integrations/document_loaders/web_loaders/figma","title":"Figma","description":"This example goes over how to load data from a Figma file.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/firecrawl":{"id":"integrations/document_loaders/web_loaders/firecrawl","title":"Firecrawl","description":"This guide shows how to use Firecrawl with LangChain to load web data into an LLM-ready format using Firecrawl.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/gitbook":{"id":"integrations/document_loaders/web_loaders/gitbook","title":"GitBook","description":"This example goes over how to load data from any GitBook, using Cheerio. One document will be created for each page.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/github":{"id":"integrations/document_loaders/web_loaders/github","title":"GitHub","description":"This example goes over how to load data from a GitHub repository.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/hn":{"id":"integrations/document_loaders/web_loaders/hn","title":"Hacker News","description":"This example goes over how to load data from the hacker news website, using Cheerio. One document will be created for each page.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/imsdb":{"id":"integrations/document_loaders/web_loaders/imsdb","title":"IMSDB","description":"This example goes over how to load data from the internet movie script database website, using Cheerio. One document will be created for each page.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/index":{"id":"integrations/document_loaders/web_loaders/index","title":"Web Loaders","description":"These loaders are used to load web resources.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/notionapi":{"id":"integrations/document_loaders/web_loaders/notionapi","title":"Notion API","description":"This guide will take you through the steps required to load documents from Notion pages and databases using the Notion API.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/pdf":{"id":"integrations/document_loaders/web_loaders/pdf","title":"PDF files","description":"You can use this version of the popular PDFLoader in web environments.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/recursive_url_loader":{"id":"integrations/document_loaders/web_loaders/recursive_url_loader","title":"Recursive URL Loader","description":"When loading content from a website, we may want to process load all URLs on a page.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/s3":{"id":"integrations/document_loaders/web_loaders/s3","title":"S3 File","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/searchapi":{"id":"integrations/document_loaders/web_loaders/searchapi","title":"SearchApi Loader","description":"This guide shows how to use SearchApi with LangChain to load web search results.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/serpapi":{"id":"integrations/document_loaders/web_loaders/serpapi","title":"SerpAPI Loader","description":"This guide shows how to use SerpAPI with LangChain to load web search results.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/sitemap":{"id":"integrations/document_loaders/web_loaders/sitemap","title":"Sitemap Loader","description":"This notebook goes over how to use the SitemapLoader class to load sitemaps into Documents.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/sonix_audio_transcription":{"id":"integrations/document_loaders/web_loaders/sonix_audio_transcription","title":"Sonix Audio","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/sort_xyz_blockchain":{"id":"integrations/document_loaders/web_loaders/sort_xyz_blockchain","title":"Blockchain Data","description":"This example shows how to load blockchain data, including NFT metadata and transactions for a contract address, via the sort.xyz SQL API.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/spider":{"id":"integrations/document_loaders/web_loaders/spider","title":"Spider","description":"Spider is the fastest crawler. It converts any website into pure HTML, markdown, metadata or text while enabling you to crawl with custom actions using AI.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/web_cheerio":{"id":"integrations/document_loaders/web_loaders/web_cheerio","title":"Webpages, with Cheerio","description":"This example goes over how to load data from webpages using Cheerio. One document will be created for each webpage.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/web_playwright":{"id":"integrations/document_loaders/web_loaders/web_playwright","title":"Webpages, with Playwright","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/web_puppeteer":{"id":"integrations/document_loaders/web_loaders/web_puppeteer","title":"Webpages, with Puppeteer","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/document_loaders/web_loaders/youtube":{"id":"integrations/document_loaders/web_loaders/youtube","title":"YouTube transcripts","description":"This covers how to load youtube transcript into LangChain documents.","sidebar":"integrations"},"integrations/document_transformers/html-to-text":{"id":"integrations/document_transformers/html-to-text","title":"html-to-text","description":"When ingesting HTML documents for later retrieval, we are often interested only in the actual content of the webpage rather than semantics.","sidebar":"integrations"},"integrations/document_transformers/mozilla_readability":{"id":"integrations/document_transformers/mozilla_readability","title":"@mozilla/readability","description":"When ingesting HTML documents for later retrieval, we are often interested only in the actual content of the webpage rather than semantics.","sidebar":"integrations"},"integrations/document_transformers/openai_metadata_tagger":{"id":"integrations/document_transformers/openai_metadata_tagger","title":"OpenAI functions metadata tagger","description":"It can often be useful to tag ingested documents with structured metadata, such as the title, tone, or length of a document, to allow for more targeted similarity search later. However, for large numbers of documents, performing this labelling process manually can be tedious.","sidebar":"integrations"},"integrations/llms/ai21":{"id":"integrations/llms/ai21","title":"AI21","description":"You can get started with AI21Labs\' Jurassic family of models, as well as see a full list of available foundational models, by signing up for an API key on their website.","sidebar":"integrations"},"integrations/llms/aleph_alpha":{"id":"integrations/llms/aleph_alpha","title":"AlephAlpha","description":"LangChain.js supports AlephAlpha\'s Luminous family of models. You\'ll need to sign up for an API key on their website.","sidebar":"integrations"},"integrations/llms/aws_sagemaker":{"id":"integrations/llms/aws_sagemaker","title":"AWS SageMakerEndpoint","description":"LangChain.js supports integration with AWS SageMaker-hosted endpoints. Check Amazon SageMaker JumpStart for a list of available models, and how to deploy your own.","sidebar":"integrations"},"integrations/llms/azure":{"id":"integrations/llms/azure","title":"Azure OpenAI","description":"Azure OpenAI is a cloud service to help you quickly develop generative AI experiences with a diverse set of prebuilt and curated models from OpenAI, Meta and beyond.","sidebar":"integrations"},"integrations/llms/bedrock":{"id":"integrations/llms/bedrock","title":"Bedrock","description":"Amazon Bedrock is a fully managed service that makes Foundation Models (FMs)","sidebar":"integrations"},"integrations/llms/cloudflare_workersai":{"id":"integrations/llms/cloudflare_workersai","title":"Cloudflare Workers AI","description":"Workers AI is currently in Open Beta and is not recommended for production data and traffic, and limits + access are subject to change","sidebar":"integrations"},"integrations/llms/cohere":{"id":"integrations/llms/cohere","title":"Cohere","description":"LangChain.js supports Cohere LLMs. Here\'s an example:","sidebar":"integrations"},"integrations/llms/fireworks":{"id":"integrations/llms/fireworks","title":"Fireworks","description":"You can use models provided by Fireworks AI as follows:","sidebar":"integrations"},"integrations/llms/friendli":{"id":"integrations/llms/friendli","title":"Friendli","description":"Friendli enhances AI application performance and optimizes cost savings with scalable, efficient deployment options, tailored for high-demand AI workloads.","sidebar":"integrations"},"integrations/llms/google_palm":{"id":"integrations/llms/google_palm","title":"Google PaLM","description":"This integration does not support gemini-* models. Check Google AI or VertexAI.","sidebar":"integrations"},"integrations/llms/google_vertex_ai":{"id":"integrations/llms/google_vertex_ai","title":"Google Vertex AI","description":"Langchain.js supports two different authentication methods based on whether","sidebar":"integrations"},"integrations/llms/gradient_ai":{"id":"integrations/llms/gradient_ai","title":"Gradient AI","description":"LangChain.js supports integration with Gradient AI. Check out Gradient AI for a list of available models.","sidebar":"integrations"},"integrations/llms/huggingface_inference":{"id":"integrations/llms/huggingface_inference","title":"HuggingFaceInference","description":"Here\'s an example of calling a HugggingFaceInference model as an LLM:","sidebar":"integrations"},"integrations/llms/index":{"id":"integrations/llms/index","title":"LLMs","description":"Features (natively supported)","sidebar":"integrations"},"integrations/llms/layerup_security":{"id":"integrations/llms/layerup_security","title":"Layerup Security","description":"The Layerup Security integration allows you to secure your calls to any LangChain LLM, LLM chain or LLM agent. The LLM object wraps around any existing LLM object, allowing for a secure layer between your users and your LLMs.","sidebar":"integrations"},"integrations/llms/llama_cpp":{"id":"integrations/llms/llama_cpp","title":"Llama CPP","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/llms/ni_bittensor":{"id":"integrations/llms/ni_bittensor","title":"NIBittensor","description":"This module has been deprecated and is no longer supported. The documentation below will not work in versions 0.2.0 or later.","sidebar":"integrations"},"integrations/llms/ollama":{"id":"integrations/llms/ollama","title":"Ollama","description":"Ollama allows you to run open-source large language models, such as Llama 2, locally.","sidebar":"integrations"},"integrations/llms/openai":{"id":"integrations/llms/openai","title":"OpenAI","description":"Here\'s how you can initialize an OpenAI LLM instance:","sidebar":"integrations"},"integrations/llms/prompt_layer_openai":{"id":"integrations/llms/prompt_layer_openai","title":"PromptLayer OpenAI","description":"This module has been deprecated and is no longer supported. The documentation below will not work in versions 0.2.0 or later.","sidebar":"integrations"},"integrations/llms/raycast":{"id":"integrations/llms/raycast","title":"RaycastAI","description":"Note: This is a community-built integration and is not officially supported by Raycast.","sidebar":"integrations"},"integrations/llms/replicate":{"id":"integrations/llms/replicate","title":"Replicate","description":"Here\'s an example of calling a Replicate model as an LLM:","sidebar":"integrations"},"integrations/llms/togetherai":{"id":"integrations/llms/togetherai","title":"Together AI","description":"Here\'s an example of calling a Together AI model as an LLM:","sidebar":"integrations"},"integrations/llms/watsonx_ai":{"id":"integrations/llms/watsonx_ai","title":"WatsonX AI","description":"LangChain.js supports integration with IBM WatsonX AI. Checkout WatsonX AI for a list of available models.","sidebar":"integrations"},"integrations/llms/writer":{"id":"integrations/llms/writer","title":"Writer","description":"LangChain.js supports calling Writer LLMs.","sidebar":"integrations"},"integrations/llms/yandex":{"id":"integrations/llms/yandex","title":"YandexGPT","description":"LangChain.js supports calling YandexGPT LLMs.","sidebar":"integrations"},"integrations/platforms/anthropic":{"id":"integrations/platforms/anthropic","title":"Anthropic","description":"All functionality related to Anthropic models.","sidebar":"integrations"},"integrations/platforms/aws":{"id":"integrations/platforms/aws","title":"AWS","description":"All functionality related to Amazon AWS platform","sidebar":"integrations"},"integrations/platforms/google":{"id":"integrations/platforms/google","title":"Google","description":"Functionality related to Google Cloud Platform","sidebar":"integrations"},"integrations/platforms/index":{"id":"integrations/platforms/index","title":"Providers","description":"LangChain integrates with many providers.","sidebar":"integrations"},"integrations/platforms/microsoft":{"id":"integrations/platforms/microsoft","title":"Microsoft","description":"All functionality related to Microsoft Azure and other Microsoft products.","sidebar":"integrations"},"integrations/platforms/openai":{"id":"integrations/platforms/openai","title":"OpenAI","description":"All functionality related to OpenAI","sidebar":"integrations"},"integrations/retrievers/bedrock-knowledge-bases":{"id":"integrations/retrievers/bedrock-knowledge-bases","title":"Knowledge Bases for Amazon Bedrock","description":"Knowledge Bases for Amazon Bedrock is a fully managed support for end-to-end RAG workflow provided by Amazon Web Services (AWS). It provides an entire ingestion workflow of converting your documents into embeddings (vector) and storing the embeddings in a specialized vector database. Knowledge Bases for Amazon Bedrock supports popular databases for vector storage, including vector engine for Amazon OpenSearch Serverless, Pinecone, Redis Enterprise Cloud, Amazon Aurora (coming soon), and MongoDB (coming soon).","sidebar":"integrations"},"integrations/retrievers/chaindesk-retriever":{"id":"integrations/retrievers/chaindesk-retriever","title":"Chaindesk Retriever","description":"This example shows how to use the Chaindesk Retriever in a retrieval chain to retrieve documents from a Chaindesk.ai datastore.","sidebar":"integrations"},"integrations/retrievers/chatgpt-retriever-plugin":{"id":"integrations/retrievers/chatgpt-retriever-plugin","title":"ChatGPT Plugin Retriever","description":"This module has been deprecated and is no longer supported. The documentation below will not work in versions 0.2.0 or later.","sidebar":"integrations"},"integrations/retrievers/dria":{"id":"integrations/retrievers/dria","title":"Dria Retriever","description":"The Dria retriever allows an agent to perform a text-based search across a comprehensive knowledge hub.","sidebar":"integrations"},"integrations/retrievers/exa":{"id":"integrations/retrievers/exa","title":"Exa Search","description":"The Exa Search API provides a new search experience designed for LLMs.","sidebar":"integrations"},"integrations/retrievers/hyde":{"id":"integrations/retrievers/hyde","title":"HyDE Retriever","description":"This example shows how to use the HyDE Retriever, which implements Hypothetical Document Embeddings (HyDE) as described in this paper.","sidebar":"integrations"},"integrations/retrievers/kendra-retriever":{"id":"integrations/retrievers/kendra-retriever","title":"Amazon Kendra Retriever","description":"Amazon Kendra is an intelligent search service provided by Amazon Web Services (AWS). It utilizes advanced natural language processing (NLP) and machine learning algorithms to enable powerful search capabilities across various data sources within an organization. Kendra is designed to help users find the information they need quickly and accurately, improving productivity and decision-making.","sidebar":"integrations"},"integrations/retrievers/metal-retriever":{"id":"integrations/retrievers/metal-retriever","title":"Metal Retriever","description":"This example shows how to use the Metal Retriever in a retrieval chain to retrieve documents from a Metal index.","sidebar":"integrations"},"integrations/retrievers/self_query/chroma":{"id":"integrations/retrievers/self_query/chroma","title":"Chroma Self Query Retriever","description":"This example shows how to use a self query retriever with a Chroma vector store.","sidebar":"integrations"},"integrations/retrievers/self_query/hnswlib":{"id":"integrations/retrievers/self_query/hnswlib","title":"HNSWLib Self Query Retriever","description":"This example shows how to use a self query retriever with an HNSWLib vector store.","sidebar":"integrations"},"integrations/retrievers/self_query/index":{"id":"integrations/retrievers/self_query/index","title":"Self-querying retrievers","description":"Learn about how self-querying retrievers work here.","sidebar":"integrations"},"integrations/retrievers/self_query/memory":{"id":"integrations/retrievers/self_query/memory","title":"Memory Vector Store Self Query Retriever","description":"This example shows how to use a self query retriever with a basic, in-memory vector store.","sidebar":"integrations"},"integrations/retrievers/self_query/pinecone":{"id":"integrations/retrievers/self_query/pinecone","title":"Pinecone Self Query Retriever","description":"This example shows how to use a self query retriever with a Pinecone vector store.","sidebar":"integrations"},"integrations/retrievers/self_query/qdrant":{"id":"integrations/retrievers/self_query/qdrant","title":"Qdrant Self Query Retriever","description":"This example shows how to use a self query retriever with a Qdrant vector store.","sidebar":"integrations"},"integrations/retrievers/self_query/supabase":{"id":"integrations/retrievers/self_query/supabase","title":"Supabase Self Query Retriever","description":"This example shows how to use a self query retriever with a Supabase vector store.","sidebar":"integrations"},"integrations/retrievers/self_query/vectara":{"id":"integrations/retrievers/self_query/vectara","title":"Vectara Self Query Retriever","description":"This example shows how to use a self query retriever with a Vectara vector store.","sidebar":"integrations"},"integrations/retrievers/self_query/weaviate":{"id":"integrations/retrievers/self_query/weaviate","title":"Weaviate Self Query Retriever","description":"This example shows how to use a self query retriever with a Weaviate vector store.","sidebar":"integrations"},"integrations/retrievers/supabase-hybrid":{"id":"integrations/retrievers/supabase-hybrid","title":"Supabase Hybrid Search","description":"Langchain supports hybrid search with a Supabase Postgres database. The hybrid search combines the postgres pgvector extension (similarity search) and Full-Text Search (keyword search) to retrieve documents. You can add documents via SupabaseVectorStore addDocuments function. SupabaseHybridKeyWordSearch accepts embedding, supabase client, number of results for similarity search, and number of results for keyword search as parameters. The getRelevantDocuments function produces a list of documents that has duplicates removed and is sorted by relevance score.","sidebar":"integrations"},"integrations/retrievers/tavily":{"id":"integrations/retrievers/tavily","title":"Tavily Search API","description":"Tavily\'s Search API is a search engine built specifically for AI agents (LLMs), delivering real-time, accurate, and factual results at speed.","sidebar":"integrations"},"integrations/retrievers/time-weighted-retriever":{"id":"integrations/retrievers/time-weighted-retriever","title":"Time-Weighted Retriever","description":"A Time-Weighted Retriever is a retriever that takes into account recency in addition to similarity. The scoring algorithm is:","sidebar":"integrations"},"integrations/retrievers/vectorstore":{"id":"integrations/retrievers/vectorstore","title":"Vector Store","description":"Once you\'ve created a Vector Store, the way to use it as a Retriever is very simple:","sidebar":"integrations"},"integrations/retrievers/vespa-retriever":{"id":"integrations/retrievers/vespa-retriever","title":"Vespa Retriever","description":"This shows how to use Vespa.ai as a LangChain retriever.","sidebar":"integrations"},"integrations/retrievers/zep-retriever":{"id":"integrations/retrievers/zep-retriever","title":"Zep Retriever","description":"Zep is a long-term memory service for AI Assistant apps.","sidebar":"integrations"},"integrations/stores/cassandra_storage":{"id":"integrations/stores/cassandra_storage","title":"Cassandra KV","description":"This example demonstrates how to setup chat history storage using the CassandraKVStore BaseStore integration. Note there is a CassandraChatMessageHistory","sidebar":"integrations"},"integrations/stores/file_system":{"id":"integrations/stores/file_system","title":"File System Store","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/stores/in_memory":{"id":"integrations/stores/in_memory","title":"In Memory Store","description":"This example demonstrates how to setup chat history storage using the InMemoryStore KV store integration.","sidebar":"integrations"},"integrations/stores/index":{"id":"integrations/stores/index","title":"Stores","description":"Storing data in key value format is quick and efficient, and can be a powerful tool for LLM applications. The BaseStore class provides a simple interface for getting, setting, deleting and iterating over lists of key value pairs.","sidebar":"integrations"},"integrations/stores/ioredis_storage":{"id":"integrations/stores/ioredis_storage","title":"IORedis","description":"This example demonstrates how to setup chat history storage using the RedisByteStore BaseStore integration.","sidebar":"integrations"},"integrations/stores/upstash_redis_storage":{"id":"integrations/stores/upstash_redis_storage","title":"Upstash Redis","description":"This example demonstrates how to setup chat history storage using the UpstashRedisStore BaseStore integration.","sidebar":"integrations"},"integrations/stores/vercel_kv_storage":{"id":"integrations/stores/vercel_kv_storage","title":"Vercel KV","description":"This example demonstrates how to setup chat history storage using the VercelKVStore BaseStore integration.","sidebar":"integrations"},"integrations/text_embedding/alibaba_tongyi":{"id":"integrations/text_embedding/alibaba_tongyi","title":"Alibaba Tongyi","description":"The AlibabaTongyiEmbeddings class uses the Alibaba Tongyi API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/azure_openai":{"id":"integrations/text_embedding/azure_openai","title":"Azure OpenAI","description":"Azure OpenAI is a cloud service to help you quickly develop generative AI experiences with a diverse set of prebuilt and curated models from OpenAI, Meta and beyond.","sidebar":"integrations"},"integrations/text_embedding/baidu_qianfan":{"id":"integrations/text_embedding/baidu_qianfan","title":"Baidu Qianfan","description":"The BaiduQianfanEmbeddings class uses the Baidu Qianfan API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/bedrock":{"id":"integrations/text_embedding/bedrock","title":"Bedrock","description":"Amazon Bedrock is a fully managed service that makes base models from Amazon and third-party model providers accessible through an API.","sidebar":"integrations"},"integrations/text_embedding/cloudflare_ai":{"id":"integrations/text_embedding/cloudflare_ai","title":"Cloudflare Workers AI","description":"If you\'re deploying your project in a Cloudflare worker, you can use Cloudflare\'s built-in Workers AI embeddings with LangChain.js.","sidebar":"integrations"},"integrations/text_embedding/cohere":{"id":"integrations/text_embedding/cohere","title":"Cohere","description":"The CohereEmbeddings class uses the Cohere API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/fireworks":{"id":"integrations/text_embedding/fireworks","title":"Fireworks","description":"The FireworksEmbeddings class allows you to use the Fireworks AI API to generate embeddings.","sidebar":"integrations"},"integrations/text_embedding/google_generativeai":{"id":"integrations/text_embedding/google_generativeai","title":"Google Generative AI","description":"You can access Google\'s generative AI embeddings models through","sidebar":"integrations"},"integrations/text_embedding/google_palm":{"id":"integrations/text_embedding/google_palm","title":"Google PaLM","description":"This integration does not support embeddings-* model. Check Google AI embeddings.","sidebar":"integrations"},"integrations/text_embedding/google_vertex_ai":{"id":"integrations/text_embedding/google_vertex_ai","title":"Google Vertex AI","description":"The GoogleVertexAIEmbeddings class uses Google\'s Vertex AI PaLM models","sidebar":"integrations"},"integrations/text_embedding/gradient_ai":{"id":"integrations/text_embedding/gradient_ai","title":"Gradient AI","description":"The GradientEmbeddings class uses the Gradient AI API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/hugging_face_inference":{"id":"integrations/text_embedding/hugging_face_inference","title":"HuggingFace Inference","description":"This Embeddings integration uses the HuggingFace Inference API to generate embeddings for a given text using by default the sentence-transformers/distilbert-base-nli-mean-tokens model. You can pass a different model name to the constructor to use a different model.","sidebar":"integrations"},"integrations/text_embedding/llama_cpp":{"id":"integrations/text_embedding/llama_cpp","title":"Llama CPP","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/text_embedding/minimax":{"id":"integrations/text_embedding/minimax","title":"Minimax","description":"The MinimaxEmbeddings class uses the Minimax API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/mistralai":{"id":"integrations/text_embedding/mistralai","title":"Mistral AI","description":"The MistralAIEmbeddings class uses the Mistral AI API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/nomic":{"id":"integrations/text_embedding/nomic","title":"Nomic","description":"The NomicEmbeddings class uses the Nomic AI API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/ollama":{"id":"integrations/text_embedding/ollama","title":"Ollama","description":"The OllamaEmbeddings class uses the /api/embeddings route of a locally hosted Ollama server to generate embeddings for given texts.","sidebar":"integrations"},"integrations/text_embedding/openai":{"id":"integrations/text_embedding/openai","title":"OpenAI","description":"The OpenAIEmbeddings class uses the OpenAI API to generate embeddings for a given text. By default it strips new line characters from the text, as recommended by OpenAI, but you can disable this by passing stripNewLines: false to the constructor.","sidebar":"integrations"},"integrations/text_embedding/premai":{"id":"integrations/text_embedding/premai","title":"Prem AI","description":"The PremEmbeddings class uses the Prem AI API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/tensorflow":{"id":"integrations/text_embedding/tensorflow","title":"TensorFlow","description":"This Embeddings integration runs the embeddings entirely in your browser or Node.js environment, using TensorFlow.js. This means that your data isn\'t sent to any third party, and you don\'t need to sign up for any API keys. However, it does require more memory and processing power than the other integrations.","sidebar":"integrations"},"integrations/text_embedding/togetherai":{"id":"integrations/text_embedding/togetherai","title":"Together AI","description":"The TogetherAIEmbeddings class uses the Together AI API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/transformers":{"id":"integrations/text_embedding/transformers","title":"HuggingFace Transformers","description":"The TransformerEmbeddings class uses the Transformers.js package to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/voyageai":{"id":"integrations/text_embedding/voyageai","title":"Voyage AI","description":"The VoyageEmbeddings class uses the Voyage AI REST API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/text_embedding/zhipuai":{"id":"integrations/text_embedding/zhipuai","title":"ZhipuAI","description":"The ZhipuAIEmbeddings class uses the ZhipuAI API to generate embeddings for a given text.","sidebar":"integrations"},"integrations/toolkits/connery":{"id":"integrations/toolkits/connery","title":"Connery Toolkit","description":"Using this toolkit, you can integrate Connery Actions into your LangChain agent.","sidebar":"integrations"},"integrations/toolkits/json":{"id":"integrations/toolkits/json","title":"JSON Agent Toolkit","description":"This example shows how to load and use an agent with a JSON toolkit.","sidebar":"integrations"},"integrations/toolkits/openapi":{"id":"integrations/toolkits/openapi","title":"OpenAPI Agent Toolkit","description":"This example shows how to load and use an agent with a OpenAPI toolkit.","sidebar":"integrations"},"integrations/toolkits/sfn_agent":{"id":"integrations/toolkits/sfn_agent","title":"AWS Step Functions Toolkit","description":"AWS Step Functions are a visual workflow service that helps developers use AWS services to build distributed applications, automate processes, orchestrate microservices, and create data and machine learning (ML) pipelines.","sidebar":"integrations"},"integrations/toolkits/sql":{"id":"integrations/toolkits/sql","title":"SQL Agent Toolkit","description":"This example shows how to load and use an agent with a SQL toolkit.","sidebar":"integrations"},"integrations/toolkits/vectorstore":{"id":"integrations/toolkits/vectorstore","title":"VectorStore Agent Toolkit","description":"This example shows how to load and use an agent with a vectorstore toolkit.","sidebar":"integrations"},"integrations/tools/aiplugin-tool":{"id":"integrations/tools/aiplugin-tool","title":"ChatGPT Plugins","description":"This example shows how to use ChatGPT Plugins within LangChain abstractions.","sidebar":"integrations"},"integrations/tools/connery":{"id":"integrations/tools/connery","title":"Connery Action Tool","description":"Using this tool, you can integrate individual Connery Action into your LangChain agent.","sidebar":"integrations"},"integrations/tools/dalle":{"id":"integrations/tools/dalle","title":"Dall-E Tool","description":"The Dall-E tool allows your agent to create images using OpenAI\'s Dall-E image generation tool.","sidebar":"integrations"},"integrations/tools/discord":{"id":"integrations/tools/discord","title":"Discord Tool","description":"The Discord Tool gives your agent the ability to search, read, and write messages to discord channels.","sidebar":"integrations"},"integrations/tools/duckduckgo_search":{"id":"integrations/tools/duckduckgo_search","title":"DuckDuckGoSearch","description":"DuckDuckGoSearch offers a privacy-focused search API designed for LLM Agents. It provides seamless integration with a wide range of data sources, prioritizing user privacy and relevant search results.","sidebar":"integrations"},"integrations/tools/exa_search":{"id":"integrations/tools/exa_search","title":"Exa Search","description":"Exa (formerly Metaphor Search) is a search engine fully designed for use by LLMs. Search for documents on the internet using natural language queries, then retrieve cleaned HTML content from desired documents.","sidebar":"integrations"},"integrations/tools/gmail":{"id":"integrations/tools/gmail","title":"Gmail Tool","description":"The Gmail Tool allows your agent to create and view messages from a linked email account.","sidebar":"integrations"},"integrations/tools/google_calendar":{"id":"integrations/tools/google_calendar","title":"Google Calendar Tool","description":"The Google Calendar Tools allow your agent to create and view Google Calendar events from a linked calendar.","sidebar":"integrations"},"integrations/tools/google_places":{"id":"integrations/tools/google_places","title":"Google Places Tool","description":"The Google Places Tool allows your agent to utilize the Google Places API in order to find addresses,","sidebar":"integrations"},"integrations/tools/google_routes":{"id":"integrations/tools/google_routes","title":"Google Routes Tool","description":"The Google Routes Tool allows your agent to utilize the Google Routes API in order to find a route between","sidebar":"integrations"},"integrations/tools/lambda_agent":{"id":"integrations/tools/lambda_agent","title":"Agent with AWS Lambda Integration","description":"Full docs here//docs.aws.amazon.com/lambda/index.html","sidebar":"integrations"},"integrations/tools/pyinterpreter":{"id":"integrations/tools/pyinterpreter","title":"Python interpreter tool","description":"This tool executes code and can potentially perform destructive actions. Be careful that you trust any code passed to it!","sidebar":"integrations"},"integrations/tools/searchapi":{"id":"integrations/tools/searchapi","title":"SearchApi tool","description":"The SearchApi tool connects your agents and chains to the internet.","sidebar":"integrations"},"integrations/tools/searxng":{"id":"integrations/tools/searxng","title":"Searxng Search tool","description":"The SearxngSearch tool connects your agents and chains to the internet.","sidebar":"integrations"},"integrations/tools/stackexchange":{"id":"integrations/tools/stackexchange","title":"StackExchange Tool","description":"The StackExchange tool connects your agents and chains to StackExchange\'s API.","sidebar":"integrations"},"integrations/tools/tavily_search":{"id":"integrations/tools/tavily_search","title":"Tavily Search","description":"Tavily Search is a robust search API tailored specifically for LLM Agents. It seamlessly integrates with diverse data sources to ensure a superior, relevant search experience.","sidebar":"integrations"},"integrations/tools/webbrowser":{"id":"integrations/tools/webbrowser","title":"Web Browser Tool","description":"The Webbrowser Tool gives your agent the ability to visit a website and extract information. It is described to the agent as","sidebar":"integrations"},"integrations/tools/wikipedia":{"id":"integrations/tools/wikipedia","title":"Wikipedia tool","description":"The WikipediaQueryRun tool connects your agents and chains to Wikipedia.","sidebar":"integrations"},"integrations/tools/wolframalpha":{"id":"integrations/tools/wolframalpha","title":"WolframAlpha Tool","description":"The WolframAlpha tool connects your agents and chains to WolframAlpha\'s state-of-the-art computational intelligence engine.","sidebar":"integrations"},"integrations/tools/zapier_agent":{"id":"integrations/tools/zapier_agent","title":"Agent with Zapier NLA Integration","description":"This module has been deprecated and is no longer supported. The documentation below will not work in versions 0.2.0 or later.","sidebar":"integrations"},"integrations/vectorstores/analyticdb":{"id":"integrations/vectorstores/analyticdb","title":"AnalyticDB","description":"AnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.","sidebar":"integrations"},"integrations/vectorstores/astradb":{"id":"integrations/vectorstores/astradb","title":"Astra DB","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/azure_aisearch":{"id":"integrations/vectorstores/azure_aisearch","title":"Azure AI Search","description":"Azure AI Search (formerly known as Azure Search and Azure Cognitive Search) is a distributed, RESTful search engine optimized for speed and relevance on production-scale workloads on Azure. It supports also vector search using the k-nearest neighbor (kNN) algorithm and also semantic search.","sidebar":"integrations"},"integrations/vectorstores/azure_cosmosdb":{"id":"integrations/vectorstores/azure_cosmosdb","title":"Azure Cosmos DB","description":"Azure Cosmos DB for MongoDB vCore makes it easy to create a database with full native MongoDB support. You can apply your MongoDB experience and continue to use your favorite MongoDB drivers, SDKs, and tools by pointing your application to the API for MongoDB vCore account\u2019s connection string. Use vector search in Azure Cosmos DB for MongoDB vCore to seamlessly integrate your AI-based applications with your data that\u2019s stored in Azure Cosmos DB.","sidebar":"integrations"},"integrations/vectorstores/cassandra":{"id":"integrations/vectorstores/cassandra","title":"Cassandra","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/chroma":{"id":"integrations/vectorstores/chroma","title":"Chroma","description":"Chroma is a AI-native open-source vector database focused on developer productivity and happiness. Chroma is licensed under Apache 2.0.","sidebar":"integrations"},"integrations/vectorstores/clickhouse":{"id":"integrations/vectorstores/clickhouse","title":"ClickHouse","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/closevector":{"id":"integrations/vectorstores/closevector","title":"CloseVector","description":"available on both browser and Node.js","sidebar":"integrations"},"integrations/vectorstores/cloudflare_vectorize":{"id":"integrations/vectorstores/cloudflare_vectorize","title":"Cloudflare Vectorize","description":"If you\'re deploying your project in a Cloudflare worker, you can use Cloudflare Vectorize with LangChain.js.","sidebar":"integrations"},"integrations/vectorstores/convex":{"id":"integrations/vectorstores/convex","title":"Convex","description":"LangChain.js supports Convex as a vector store, and supports the standard similarity search.","sidebar":"integrations"},"integrations/vectorstores/couchbase":{"id":"integrations/vectorstores/couchbase","title":"Couchbase","description":"Couchbase is an award-winning distributed NoSQL cloud database that delivers unmatched versatility, performance, scalability, and financial value for all of your cloud, mobile,","sidebar":"integrations"},"integrations/vectorstores/elasticsearch":{"id":"integrations/vectorstores/elasticsearch","title":"Elasticsearch","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/faiss":{"id":"integrations/vectorstores/faiss","title":"Faiss","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/googlevertexai":{"id":"integrations/vectorstores/googlevertexai","title":"Google Vertex AI Matching Engine","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/hanavector":{"id":"integrations/vectorstores/hanavector","title":"SAP HANA Cloud Vector Engine","description":"SAP HANA Cloud Vector Engine is a vector store fully integrated into the SAP HANA Cloud database.","sidebar":"integrations"},"integrations/vectorstores/hnswlib":{"id":"integrations/vectorstores/hnswlib","title":"HNSWLib","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/lancedb":{"id":"integrations/vectorstores/lancedb","title":"LanceDB","description":"LanceDB is an embedded vector database for AI applications. It is open source and distributed with an Apache-2.0 license.","sidebar":"integrations"},"integrations/vectorstores/memory":{"id":"integrations/vectorstores/memory","title":"MemoryVectorStore","description":"MemoryVectorStore is an in-memory, ephemeral vectorstore that stores embeddings in-memory and does an exact, linear search for the most similar embeddings. The default similarity metric is cosine similarity, but can be changed to any of the similarity metrics supported by ml-distance.","sidebar":"integrations"},"integrations/vectorstores/milvus":{"id":"integrations/vectorstores/milvus","title":"Milvus","description":"Milvus is a vector database built for embeddings similarity search and AI applications.","sidebar":"integrations"},"integrations/vectorstores/momento_vector_index":{"id":"integrations/vectorstores/momento_vector_index","title":"Momento Vector Index (MVI)","description":"MVI: the most productive, easiest to use, serverless vector index for your data. To get started with MVI, simply sign up for an account. There\'s no need to handle infrastructure, manage servers, or be concerned about scaling. MVI is a service that scales automatically to meet your needs. Whether in Node.js, browser, or edge, Momento has you covered.","sidebar":"integrations"},"integrations/vectorstores/myscale":{"id":"integrations/vectorstores/myscale","title":"MyScale","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/neo4jvector":{"id":"integrations/vectorstores/neo4jvector","title":"Neo4j Vector Index","description":"Neo4j is an open-source graph database with integrated support for vector similarity search.","sidebar":"integrations"},"integrations/vectorstores/neon":{"id":"integrations/vectorstores/neon","title":"Neon Postgres","description":"Neon is a fully managed serverless PostgreSQL database. It separates storage and compute to offer","sidebar":"integrations"},"integrations/vectorstores/opensearch":{"id":"integrations/vectorstores/opensearch","title":"OpenSearch","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/pgvector":{"id":"integrations/vectorstores/pgvector","title":"PGVector","description":"To enable vector search in a generic PostgreSQL database, LangChain.js supports using the pgvector Postgres extension.","sidebar":"integrations"},"integrations/vectorstores/pinecone":{"id":"integrations/vectorstores/pinecone","title":"Pinecone","description":"You can use Pinecone vectorstores with LangChain.","sidebar":"integrations"},"integrations/vectorstores/prisma":{"id":"integrations/vectorstores/prisma","title":"Prisma","description":"For augmenting existing models in PostgreSQL database with vector search, Langchain supports using Prisma together with PostgreSQL and pgvector Postgres extension.","sidebar":"integrations"},"integrations/vectorstores/qdrant":{"id":"integrations/vectorstores/qdrant","title":"Qdrant","description":"Qdrant is a vector similarity search engine. It provides a production-ready service with a convenient API to store, search, and manage points - vectors with an additional payload.","sidebar":"integrations"},"integrations/vectorstores/redis":{"id":"integrations/vectorstores/redis","title":"Redis","description":"Redis is a fast open source, in-memory data store.","sidebar":"integrations"},"integrations/vectorstores/rockset":{"id":"integrations/vectorstores/rockset","title":"Rockset","description":"Rockset is a real-time analyitics SQL database that runs in the cloud.","sidebar":"integrations"},"integrations/vectorstores/singlestore":{"id":"integrations/vectorstores/singlestore","title":"SingleStore","description":"SingleStoreDB is a high-performance distributed SQL database that supports deployment both in the cloud and on-premise. It provides vector storage, as well as vector functions like dotproduct and euclideandistance, thereby supporting AI applications that require text similarity matching.","sidebar":"integrations"},"integrations/vectorstores/supabase":{"id":"integrations/vectorstores/supabase","title":"Supabase","description":"Langchain supports using Supabase Postgres database as a vector store, using the pgvector postgres extension. Refer to the Supabase blog post for more information.","sidebar":"integrations"},"integrations/vectorstores/tigris":{"id":"integrations/vectorstores/tigris","title":"tigris","description":"","sidebar":"integrations"},"integrations/vectorstores/turbopuffer":{"id":"integrations/vectorstores/turbopuffer","title":"Turbopuffer","description":"Setup","sidebar":"integrations"},"integrations/vectorstores/typeorm":{"id":"integrations/vectorstores/typeorm","title":"TypeORM","description":"To enable vector search in a generic PostgreSQL database, LangChain.js supports using TypeORM with the pgvector Postgres extension.","sidebar":"integrations"},"integrations/vectorstores/typesense":{"id":"integrations/vectorstores/typesense","title":"Typesense","description":"Vector store that utilizes the Typesense search engine.","sidebar":"integrations"},"integrations/vectorstores/upstash":{"id":"integrations/vectorstores/upstash","title":"Upstash Vector","description":"Upstash Vector is a REST based serverless vector database, designed for working with vector embeddings.","sidebar":"integrations"},"integrations/vectorstores/usearch":{"id":"integrations/vectorstores/usearch","title":"USearch","description":"Only available on Node.js.","sidebar":"integrations"},"integrations/vectorstores/vectara":{"id":"integrations/vectorstores/vectara","title":"Vectara","description":"Vectara is a platform for building GenAI applications. It provides an easy-to-use API for document indexing and querying that is managed by Vectara and is optimized for performance and accuracy.","sidebar":"integrations"},"integrations/vectorstores/vercel_postgres":{"id":"integrations/vectorstores/vercel_postgres","title":"Vercel Postgres","description":"LangChain.js supports using the @vercel/postgres package to use generic Postgres databases","sidebar":"integrations"},"integrations/vectorstores/voy":{"id":"integrations/vectorstores/voy","title":"Voy","description":"Voy is a WASM vector similarity search engine written in Rust.","sidebar":"integrations"},"integrations/vectorstores/weaviate":{"id":"integrations/vectorstores/weaviate","title":"Weaviate","description":"Weaviate is an open source vector database that stores both objects and vectors, allowing for combining vector search with structured filtering.","sidebar":"integrations"},"integrations/vectorstores/xata":{"id":"integrations/vectorstores/xata","title":"Xata","description":"Xata is a serverless data platform, based on PostgreSQL. It provides a type-safe TypeScript/JavaScript SDK for interacting with your database, and a UI for managing your data.","sidebar":"integrations"},"integrations/vectorstores/zep":{"id":"integrations/vectorstores/zep","title":"Zep","description":"Zep is a long-term memory service for AI Assistant apps.","sidebar":"integrations"},"introduction":{"id":"introduction","title":"\uc18c\uac1c","description":"LangChain\uc740 \uac70\ub300 \uc5b8\uc5b4 \ubaa8\ub378(LLMs)\uc5d0 \uae30\ubc18\uc73c\ub85c \ub3d9\uc791\ud558\ub294 \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc744 \uac1c\ubc1c\ud558\uae30 \uc704\ud55c \ud504\ub808\uc784\uc6cc\ud06c\uc785\ub2c8\ub2e4.","sidebar":"tutorialSidebar"},"langgraph":{"id":"langgraph","title":"\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph.js","description":"\u26a1 Building language agents as graphs \u26a1"},"langsmith":{"id":"langsmith","title":"\ud83e\udd9c\ud83d\udee0\ufe0f LangSmith","description":"LangSmith helps you trace and evaluate your language model applications and intelligent agents to help you"},"mdx_components/integration_install_tooltip":{"id":"mdx_components/integration_install_tooltip","title":"integration_install_tooltip","description":"See this section for general instructions on installing integration packages."},"mdx_components/unified_model_params_tooltip":{"id":"mdx_components/unified_model_params_tooltip","title":"unified_model_params_tooltip","description":"We\'re unifying model params across all packages. We now suggest using model instead of modelName, and apiKey for API keys."},"security":{"id":"security","title":"Security","description":"LangChain has a large ecosystem of integrations with various external resources like local and remote file systems, APIs and databases. These integrations allow developers to create versatile applications that combine the power of LLMs with the ability to access, interact with and manipulate external resources.ov","sidebar":"tutorialSidebar"},"tutorials/agents":{"id":"tutorials/agents","title":"\uc5d0\uc774\uc804\ud2b8 \ub9cc\ub4e4\uae30","description":"By themselves, language models can\'t take actions - they just output text.","sidebar":"tutorialSidebar"},"tutorials/chatbot":{"id":"tutorials/chatbot","title":"\ucc57\ubd07 \ub9cc\ub4e4\uae30","description":"Overview","sidebar":"tutorialSidebar"},"tutorials/classification":{"id":"tutorials/classification","title":"Tagging","description":"Tagging means labeling a document with classes such as:","sidebar":"tutorialSidebar"},"tutorials/extraction":{"id":"tutorials/extraction","title":"\ucd94\ucd9c \uccb4\uc778 \ub9cc\ub4e4\uae30","description":"In this tutorial, we will build a chain to extract structured","sidebar":"tutorialSidebar"},"tutorials/graph":{"id":"tutorials/graph","title":"\uadf8\ub798\ud504 \ub370\uc774\ud130\ubca0\uc774\uc2a4\ub97c \ud1b5\ud55c \uc9c8\ubb38/\ub2f5\ubcc0 \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","description":"In this guide we\u2019ll go over the basic ways to create a Q&A chain over a","sidebar":"tutorialSidebar"},"tutorials/index":{"id":"tutorials/index","title":"\ud29c\ud1a0\ub9ac\uc5bc","description":"\ub7ad\uccb4\uc778\uc774\ub098 LLM\uae30\ubc18 \uc571 \uac1c\ubc1c\uc5d0 \ucc98\uc74c\uc774\uc2dc\ub77c\uba74 \uc544\ub798 \uc790\ub8cc\ub4e4 \uc77d\uace0 \ube60\ub974\uac8c \uc2dc\uc791\ud574\ubcf4\uc138\uc694 !","sidebar":"tutorialSidebar"},"tutorials/llm_chain":{"id":"tutorials/llm_chain","title":"\uac04\ub2e8\ud55c LLM \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","description":"In this quickstart we\u2019ll show you how to build a simple LLM application.","sidebar":"tutorialSidebar"},"tutorials/local_rag":{"id":"tutorials/local_rag","title":"\ub85c\uceec RAG \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","description":"The popularity of projects like","sidebar":"tutorialSidebar"},"tutorials/qa_chat_history":{"id":"tutorials/qa_chat_history","title":"\ub300\ud654\ud615 RAG \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","description":"In many Q&A applications we want to allow the user to have a","sidebar":"tutorialSidebar"},"tutorials/query_analysis":{"id":"tutorials/query_analysis","title":"Build a Query Analysis System","description":"","sidebar":"tutorialSidebar"},"tutorials/rag":{"id":"tutorials/rag","title":"\uac80\uc0c9-\uc99d\uac15 \uc0dd\uc131 (RAG) \uc560\ud50c\ub9ac\ucf00\uc774\uc158 \ub9cc\ub4e4\uae30","description":"One of the most powerful applications enabled by LLMs is sophisticated","sidebar":"tutorialSidebar"},"tutorials/sql_qa":{"id":"tutorials/sql_qa","title":"SQL \ub370\uc774\ud130\ub97c \ud1b5\ud55c \uc9c8\ubb38/\ub2f5\ubcc0 \uc2dc\uc2a4\ud15c \ub9cc\ub4e4\uae30","description":"","sidebar":"tutorialSidebar"},"tutorials/summarization":{"id":"tutorials/summarization","title":"\ud14d\uc2a4\ud2b8 \uc694\uc57d\ud558\uae30","description":"","sidebar":"tutorialSidebar"},"versions/overview":{"id":"versions/overview","title":"LangChain Over Time","description":"","sidebar":"tutorialSidebar"},"versions/packages":{"id":"versions/packages","title":"\ud83d\udcd5 Package versioning","description":"","sidebar":"tutorialSidebar"},"versions/release_policy":{"id":"versions/release_policy","title":"LangChain releases","description":"","sidebar":"tutorialSidebar"},"versions/v0_2":{"id":"versions/v0_2","title":"LangChain v0.2","description":"LangChain v0.2 was released in May 2024. This release includes a number of breaking changes and deprecations. This document contains a guide on upgrading to 0.2.x, as well as a list of deprecations and breaking changes.","sidebar":"tutorialSidebar"}}}}')}}]);