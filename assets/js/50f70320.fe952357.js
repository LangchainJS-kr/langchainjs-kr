(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9848,7817,65],{52041:(n,e,t)=>{"use strict";t.r(e),t.d(e,{assets:()=>C,contentTitle:()=>A,default:()=>S,frontMatter:()=>j,metadata:()=>T,toc:()=>k});var o=t(74848),a=t(28453),s=t(78847),i=t(2280),r=t(64428),l=t(82138),c=t.n(l),h=t(48459),p=t.n(h),d=t(90914),m=t.n(d),u=t(92443),g=t.n(u),f=t(87910),x=t.n(f),b=t(64061),w=t.n(b),_=t(7332),y=t.n(_);const j={sidebar_label:"Anthropic"},A="ChatAnthropic",T={id:"integrations/chat/anthropic",title:"ChatAnthropic",description:"LangChain supports Anthropic's Claude family of chat models.",source:"@site/docs/integrations/chat/anthropic.mdx",sourceDirName:"integrations/chat",slug:"/integrations/chat/anthropic",permalink:"/docs/integrations/chat/anthropic",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/integrations/chat/anthropic.mdx",tags:[],version:"current",frontMatter:{sidebar_label:"Anthropic"},sidebar:"integrations",previous:{title:"Alibaba Tongyi",permalink:"/docs/integrations/chat/alibaba_tongyi"},next:{title:"Anthropic Tools",permalink:"/docs/integrations/chat/anthropic_tools"}},C={},k=[...s.toc,{value:"Usage",id:"usage",level:2},...i.toc,{value:"Multimodal inputs",id:"multimodal-inputs",level:2},{value:"Agents",id:"agents",level:2},{value:"Custom headers",id:"custom-headers",level:2},{value:"Tools",id:"tools",level:2},{value:"Single Tool",id:"single-tool",level:3},{value:"Forced tool calling",id:"forced-tool-calling",level:3},{value:"<code>withStructuredOutput</code>",id:"withstructuredoutput",level:3}];function v(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.h1,{id:"chatanthropic",children:"ChatAnthropic"}),"\n",(0,o.jsx)(e.p,{children:"LangChain supports Anthropic's Claude family of chat models."}),"\n",(0,o.jsxs)(e.p,{children:["You'll first need to install the ",(0,o.jsx)(e.a,{href:"https://www.npmjs.com/package/@langchain/anthropic",children:(0,o.jsx)(e.code,{children:"@langchain/anthropic"})})," package:"]}),"\n","\n",(0,o.jsx)(s.default,{}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/anthropic\n"})}),"\n",(0,o.jsxs)(e.p,{children:["You'll also need to sign up and obtain an ",(0,o.jsx)(e.a,{href:"https://www.anthropic.com/",children:"Anthropic API key"}),".\nSet it as an environment variable named ",(0,o.jsx)(e.code,{children:"ANTHROPIC_API_KEY"}),", or pass it into the constructor as shown below."]}),"\n",(0,o.jsx)(e.h2,{id:"usage",children:"Usage"}),"\n","\n",(0,o.jsx)(i.default,{}),"\n",(0,o.jsx)(e.p,{children:"You can initialize an instance like this:"}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:c()}),"\n",(0,o.jsx)(e.h2,{id:"multimodal-inputs",children:"Multimodal inputs"}),"\n",(0,o.jsxs)(e.p,{children:["Claude-3 models support image multimodal inputs. The passed input must be a base64 encoded image with the\nfiletype as a prefix (e.g. ",(0,o.jsx)(e.code,{children:"data:image/png;base64,{YOUR_BASE64_ENCODED_DATA}"}),").\nHere's an example:"]}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:p()}),"\n",(0,o.jsxs)(e.p,{children:["See ",(0,o.jsx)(e.a,{href:"https://docs.anthropic.com/claude/docs/vision#what-image-file-types-does-claude-support",children:"the official docs"}),"\nfor a complete list of supported file types."]}),"\n",(0,o.jsx)(e.h2,{id:"agents",children:"Agents"}),"\n",(0,o.jsx)(e.p,{children:"Anthropic models that support tool calling can be used in the Tool Calling agent. Here's an example:"}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:m()}),"\n",(0,o.jsx)(e.admonition,{type:"tip",children:(0,o.jsxs)(e.p,{children:["See the LangSmith trace ",(0,o.jsx)(e.a,{href:"https://smith.langchain.com/public/e93ff7f6-03f7-4eb1-96c8-09a17dee1462/r",children:"here"})]})}),"\n",(0,o.jsx)(e.h2,{id:"custom-headers",children:"Custom headers"}),"\n",(0,o.jsx)(e.p,{children:"You can pass custom headers in your requests like this:"}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:g()}),"\n",(0,o.jsx)(e.h2,{id:"tools",children:"Tools"}),"\n",(0,o.jsx)(e.p,{children:"The Anthropic API supports tool calling, along with multi-tool calling. The following examples demonstrate how to call tools:"}),"\n",(0,o.jsx)(e.h3,{id:"single-tool",children:"Single Tool"}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:x()}),"\n",(0,o.jsx)(e.admonition,{type:"tip",children:(0,o.jsxs)(e.p,{children:["See the LangSmith trace ",(0,o.jsx)(e.a,{href:"https://smith.langchain.com/public/90c03ed0-154b-4a50-afbf-83dcbf302647/r",children:"here"})]})}),"\n",(0,o.jsx)(e.h3,{id:"forced-tool-calling",children:"Forced tool calling"}),"\n","\n",(0,o.jsx)(e.p,{children:"In this example we'll provide the model with two tools:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.code,{children:"calculator"})}),"\n",(0,o.jsx)(e.li,{children:(0,o.jsx)(e.code,{children:"get_weather"})}),"\n"]}),"\n",(0,o.jsxs)(e.p,{children:["Then, when we call ",(0,o.jsx)(e.code,{children:"bindTools"}),", we'll force the model to use the ",(0,o.jsx)(e.code,{children:"get_weather"})," tool by passing the ",(0,o.jsx)(e.code,{children:"tool_choice"})," arg like this:"]}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:'.bindTools({\n  tools,\n  tool_choice: {\n    type: "tool",\n    name: "get_weather",\n  }\n});\n'})}),"\n",(0,o.jsxs)(e.p,{children:["Finally, we'll invoke the model, but instead of asking about the weather, we'll ask it to do some math.\nSince we explicitly forced the model to use the ",(0,o.jsx)(e.code,{children:"get_weather"})," tool, it will ignore the input and return the weather information (in this case it returned ",(0,o.jsx)(e.code,{children:"<UNKNOWN>"}),", which is expected.)"]}),"\n",(0,o.jsx)(r.A,{language:"typescript",children:w()}),"\n",(0,o.jsxs)(e.p,{children:["The ",(0,o.jsx)(e.code,{children:"bind_tools"})," argument has three possible values:"]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:'{ type: "tool", name: "tool_name" }'})," - Forces the model to use the specified tool."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:'"any"'})," - Allows the model to choose the tool, but still forcing it to choose at least one."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.code,{children:'"auto"'})," - The default value. Allows the model to select any tool, or none."]}),"\n"]}),"\n",(0,o.jsx)(e.admonition,{type:"tip",children:(0,o.jsxs)(e.p,{children:["See the LangSmith trace ",(0,o.jsx)(e.a,{href:"https://smith.langchain.com/public/c5cc8fe7-5e76-4607-8c43-1e0b30e4f5ca/r",children:"here"})]})}),"\n",(0,o.jsx)(e.h3,{id:"withstructuredoutput",children:(0,o.jsx)(e.code,{children:"withStructuredOutput"})}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:y()}),"\n",(0,o.jsx)(e.admonition,{type:"tip",children:(0,o.jsxs)(e.p,{children:["See the LangSmith trace ",(0,o.jsx)(e.a,{href:"https://smith.langchain.com/public/efbd11c5-886e-4e07-be1a-951690fa8a27/r",children:"here"})]})})]})}function S(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(v,{...n})}):v(n)}},78847:(n,e,t)=>{"use strict";t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var o=t(74848),a=t(28453);const s={},i=void 0,r={id:"mdx_components/integration_install_tooltip",title:"integration_install_tooltip",description:"See this section for general instructions on installing integration packages.",source:"@site/docs/mdx_components/integration_install_tooltip.mdx",sourceDirName:"mdx_components",slug:"/mdx_components/integration_install_tooltip",permalink:"/docs/mdx_components/integration_install_tooltip",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/mdx_components/integration_install_tooltip.mdx",tags:[],version:"current",frontMatter:{}},l={},c=[];function h(n){const e={a:"a",admonition:"admonition",p:"p",...(0,a.R)(),...n.components};return(0,o.jsx)(e.admonition,{type:"tip",children:(0,o.jsxs)(e.p,{children:["See ",(0,o.jsx)(e.a,{href:"/docs/how_to/installation#installing-integration-packages",children:"this section for general instructions on installing integration packages"}),"."]})})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(h,{...n})}):h(n)}},2280:(n,e,t)=>{"use strict";t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>s,metadata:()=>r,toc:()=>c});var o=t(74848),a=t(28453);const s={},i=void 0,r={id:"mdx_components/unified_model_params_tooltip",title:"unified_model_params_tooltip",description:"We're unifying model params across all packages. We now suggest using model instead of modelName, and apiKey for API keys.",source:"@site/docs/mdx_components/unified_model_params_tooltip.mdx",sourceDirName:"mdx_components",slug:"/mdx_components/unified_model_params_tooltip",permalink:"/docs/mdx_components/unified_model_params_tooltip",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/mdx_components/unified_model_params_tooltip.mdx",tags:[],version:"current",frontMatter:{}},l={},c=[];function h(n){const e={admonition:"admonition",code:"code",p:"p",...(0,a.R)(),...n.components};return(0,o.jsx)(e.admonition,{type:"tip",children:(0,o.jsxs)(e.p,{children:["We're unifying model params across all packages. We now suggest using ",(0,o.jsx)(e.code,{children:"model"})," instead of ",(0,o.jsx)(e.code,{children:"modelName"}),", and ",(0,o.jsx)(e.code,{children:"apiKey"})," for API keys."]})})}function p(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(h,{...n})}):h(n)}},82138:n=>{n.exports={content:"import { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst model = new ChatAnthropic({\n  temperature: 0.9,\n  model: \"claude-3-sonnet-20240229\",\n  // In Node.js defaults to process.env.ANTHROPIC_API_KEY,\n  // apiKey: \"YOUR-API-KEY\",\n  maxTokens: 1024,\n});\n\nconst res = await model.invoke(\"Why is the sky blue?\");\n\nconsole.log(res);\n\n/*\n  AIMessage {\n    content: \"The sky appears blue because of how air in Earth's atmosphere interacts with sunlight. As sunlight passes through the atmosphere, light waves get scattered by gas molecules and airborne particles. Blue light waves scatter more easily than other color light waves. Since blue light gets scattered across the sky, we perceive the sky as having a blue color.\",\n    name: undefined,\n    additional_kwargs: {\n      id: 'msg_01JuukTnjoXHuzQaPiSVvZQ1',\n      type: 'message',\n      role: 'assistant',\n      model: 'claude-3-sonnet-20240229',\n      stop_reason: 'end_turn',\n      stop_sequence: null,\n      usage: { input_tokens: 15, output_tokens: 70 }\n    }\n  }\n*/\n",imports:[{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"}]}},92443:n=>{n.exports={content:"import { ChatAnthropic } from \"@langchain/anthropic\";\n\nconst model = new ChatAnthropic({\n  model: \"claude-3-sonnet-20240229\",\n  maxTokens: 1024,\n  clientOptions: {\n    defaultHeaders: {\n      \"X-Api-Key\": process.env.ANTHROPIC_API_KEY,\n    },\n  },\n});\n\nconst res = await model.invoke(\"Why is the sky blue?\");\n\nconsole.log(res);\n\n/*\n  AIMessage {\n    content: \"The sky appears blue because of the way sunlight interacts with the gases in Earth's atmosphere. Here's a more detailed explanation:\\n\" +\n      '\\n' +\n      '- Sunlight is made up of different wavelengths of light, including the entire visible spectrum from red to violet.\\n' +\n      '\\n' +\n      '- As sunlight passes through the atmosphere, the gases (nitrogen, oxygen, etc.) cause the shorter wavelengths of light, in the blue and violet range, to be scattered more efficiently in different directions.\\n' +\n      '\\n' +\n      '- The blue wavelengths of about 475 nanometers get scattered more than the other visible wavelengths by the tiny gas molecules in the atmosphere.\\n' +\n      '\\n' +\n      '- This preferential scattering of blue light in all directions by the gas molecules is called Rayleigh scattering.\\n' +\n      '\\n' +\n      '- When we look at the sky, we see this scattered blue light from the sun coming at us from all parts of the sky.\\n' +\n      '\\n' +\n      \"- At sunrise and sunset, the sun's rays have to travel further through the atmosphere before reaching our eyes, causing more of the blue light to be scattered out, leaving more of the red/orange wavelengths visible - which is why sunrises and sunsets appear reddish.\\n\" +\n      '\\n' +\n      'So in summary, the blueness of the sky is caused by this selective scattering of blue wavelengths of sunlight by the gases in the atmosphere.',\n    name: undefined,\n    additional_kwargs: {\n      id: 'msg_01Mvvc5GvomqbUxP3YaeWXRe',\n      type: 'message',\n      role: 'assistant',\n      model: 'claude-3-sonnet-20240229',\n      stop_reason: 'end_turn',\n      stop_sequence: null,\n      usage: { input_tokens: 13, output_tokens: 284 }\n    }\n  }\n*/\n",imports:[{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"}]}},64061:n=>{n.exports={content:'import { ChatAnthropic } from "@langchain/anthropic";\nimport { ChatPromptTemplate } from "@langchain/core/prompts";\nimport { z } from "zod";\nimport { zodToJsonSchema } from "zod-to-json-schema";\n\nconst calculatorSchema = z.object({\n  operation: z\n    .enum(["add", "subtract", "multiply", "divide"])\n    .describe("The type of operation to execute."),\n  number1: z.number().describe("The first number to operate on."),\n  number2: z.number().describe("The second number to operate on."),\n});\n\nconst weatherSchema = z.object({\n  city: z.string().describe("The city to get the weather from"),\n  state: z.string().optional().describe("The state to get the weather from"),\n});\n\nconst tools = [\n  {\n    name: "calculator",\n    description: "A simple calculator tool",\n    input_schema: zodToJsonSchema(calculatorSchema),\n  },\n  {\n    name: "get_weather",\n    description:\n      "Get the weather of a specific location and return the temperature in Celsius.",\n    input_schema: zodToJsonSchema(weatherSchema),\n  },\n];\n\nconst model = new ChatAnthropic({\n  apiKey: process.env.ANTHROPIC_API_KEY,\n  model: "claude-3-haiku-20240307",\n}).bind({\n  tools,\n  tool_choice: {\n    type: "tool",\n    name: "get_weather",\n  },\n});\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  [\n    "system",\n    "You are a helpful assistant who always needs to use a calculator.",\n  ],\n  ["human", "{input}"],\n]);\n\n// Chain your prompt and model together\nconst chain = prompt.pipe(model);\n\nconst response = await chain.invoke({\n  input: "What is the sum of 2725 and 273639",\n});\nconsole.log(JSON.stringify(response, null, 2));\n/*\n{\n  "kwargs": {\n    "tool_calls": [\n      {\n        "name": "get_weather",\n        "args": {\n          "city": "<UNKNOWN>",\n          "state": "<UNKNOWN>"\n        },\n        "id": "toolu_01MGRNudJvSDrrCZcPa2WrBX"\n      }\n    ],\n    "response_metadata": {\n      "id": "msg_01RW3R4ctq7q5g4GJuGMmRPR",\n      "model": "claude-3-haiku-20240307",\n      "stop_sequence": null,\n      "usage": {\n        "input_tokens": 672,\n        "output_tokens": 52\n      },\n      "stop_reason": "tool_use"\n    }\n  }\n}\n*/\n',imports:[{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"},{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"}]}},48459:n=>{n.exports={content:'import * as fs from "node:fs/promises";\n\nimport { ChatAnthropic } from "@langchain/anthropic";\nimport { HumanMessage } from "@langchain/core/messages";\n\nconst imageData = await fs.readFile("./hotdog.jpg");\nconst chat = new ChatAnthropic({\n  model: "claude-3-sonnet-20240229",\n});\nconst message = new HumanMessage({\n  content: [\n    {\n      type: "text",\n      text: "What\'s in this image?",\n    },\n    {\n      type: "image_url",\n      image_url: {\n        url: `data:image/jpeg;base64,${imageData.toString("base64")}`,\n      },\n    },\n  ],\n});\n\nconst res = await chat.invoke([message]);\nconsole.log({ res });\n\n/*\n  {\n    res: AIMessage {\n      content: \'The image shows a hot dog or frankfurter. It has a reddish-pink sausage filling encased in a light brown bun or bread roll. The hot dog is cut lengthwise, revealing the bright red sausage interior contrasted against the lightly toasted bread exterior. This classic fast food item is depicted in detail against a plain white background.\',\n      name: undefined,\n      additional_kwargs: {\n        id: \'msg_0153boCaPL54QDEMQExkVur6\',\n        type: \'message\',\n        role: \'assistant\',\n        model: \'claude-3-sonnet-20240229\',\n        stop_reason: \'end_turn\',\n        stop_sequence: null,\n        usage: [Object]\n      }\n    }\n  }\n*/\n',imports:[{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"},{local:"HumanMessage",imported:"HumanMessage",source:"@langchain/core/messages"}]}},87910:n=>{n.exports={content:'import { ChatAnthropic } from "@langchain/anthropic";\nimport { ChatPromptTemplate } from "@langchain/core/prompts";\nimport { z } from "zod";\nimport { zodToJsonSchema } from "zod-to-json-schema";\n\nconst calculatorSchema = z.object({\n  operation: z\n    .enum(["add", "subtract", "multiply", "divide"])\n    .describe("The type of operation to execute."),\n  number1: z.number().describe("The first number to operate on."),\n  number2: z.number().describe("The second number to operate on."),\n});\n\nconst tool = {\n  name: "calculator",\n  description: "A simple calculator tool",\n  input_schema: zodToJsonSchema(calculatorSchema),\n};\n\nconst model = new ChatAnthropic({\n  apiKey: process.env.ANTHROPIC_API_KEY,\n  model: "claude-3-haiku-20240307",\n}).bind({\n  tools: [tool],\n});\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  [\n    "system",\n    "You are a helpful assistant who always needs to use a calculator.",\n  ],\n  ["human", "{input}"],\n]);\n\n// Chain your prompt and model together\nconst chain = prompt.pipe(model);\n\nconst response = await chain.invoke({\n  input: "What is 2 + 2?",\n});\nconsole.log(JSON.stringify(response, null, 2));\n/*\n{\n  "kwargs": {\n    "content": "Okay, let\'s calculate that using the calculator tool:",\n    "additional_kwargs": {\n      "id": "msg_01YcT1KFV8qH7xG6T6C4EpGq",\n      "role": "assistant",\n      "model": "claude-3-haiku-20240307",\n      "tool_calls": [\n        {\n          "id": "toolu_01UiqGsTTH45MUveRQfzf7KH",\n          "type": "function",\n          "function": {\n            "arguments": "{\\"number1\\":2,\\"number2\\":2,\\"operation\\":\\"add\\"}",\n            "name": "calculator"\n          }\n        }\n      ]\n    },\n    "response_metadata": {}\n  }\n}\n*/\n',imports:[{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"},{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"}]}},90914:n=>{n.exports={content:'import { z } from "zod";\n\nimport { ChatAnthropic } from "@langchain/anthropic";\nimport { DynamicStructuredTool } from "@langchain/core/tools";\nimport { AgentExecutor, createToolCallingAgent } from "langchain/agents";\n\nimport { ChatPromptTemplate } from "@langchain/core/prompts";\n\nconst llm = new ChatAnthropic({\n  model: "claude-3-sonnet-20240229",\n  temperature: 0,\n});\n\n// Prompt template must have "input" and "agent_scratchpad input variables"\nconst prompt = ChatPromptTemplate.fromMessages([\n  ["system", "You are a helpful assistant"],\n  ["placeholder", "{chat_history}"],\n  ["human", "{input}"],\n  ["placeholder", "{agent_scratchpad}"],\n]);\n\nconst currentWeatherTool = new DynamicStructuredTool({\n  name: "get_current_weather",\n  description: "Get the current weather in a given location",\n  schema: z.object({\n    location: z.string().describe("The city and state, e.g. San Francisco, CA"),\n  }),\n  func: async () => Promise.resolve("28 \xb0C"),\n});\n\nconst agent = await createToolCallingAgent({\n  llm,\n  tools: [currentWeatherTool],\n  prompt,\n});\n\nconst agentExecutor = new AgentExecutor({\n  agent,\n  tools: [currentWeatherTool],\n});\n\nconst input = "What\'s the weather like in SF?";\nconst { output } = await agentExecutor.invoke({ input });\n\nconsole.log(output);\n\n/* \n  The current weather in San Francisco, CA is 28\xb0C.\n*/\n',imports:[{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"},{local:"DynamicStructuredTool",imported:"DynamicStructuredTool",source:"@langchain/core/tools"},{local:"AgentExecutor",imported:"AgentExecutor",source:"langchain/agents"},{local:"createToolCallingAgent",imported:"createToolCallingAgent",source:"langchain/agents"},{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"}]}},7332:n=>{n.exports={content:'import { ChatAnthropic } from "@langchain/anthropic";\nimport { ChatPromptTemplate } from "@langchain/core/prompts";\nimport { z } from "zod";\n\nconst calculatorSchema = z\n  .object({\n    operation: z\n      .enum(["add", "subtract", "multiply", "divide"])\n      .describe("The type of operation to execute."),\n    number1: z.number().describe("The first number to operate on."),\n    number2: z.number().describe("The second number to operate on."),\n  })\n  .describe("A simple calculator tool");\n\nconst model = new ChatAnthropic({\n  apiKey: process.env.ANTHROPIC_API_KEY,\n  model: "claude-3-haiku-20240307",\n});\n\n// Pass the schema and tool name to the withStructuredOutput method\nconst modelWithTool = model.withStructuredOutput(calculatorSchema);\n\nconst prompt = ChatPromptTemplate.fromMessages([\n  [\n    "system",\n    "You are a helpful assistant who always needs to use a calculator.",\n  ],\n  ["human", "{input}"],\n]);\n\n// Chain your prompt and model together\nconst chain = prompt.pipe(modelWithTool);\n\nconst response = await chain.invoke({\n  input: "What is 2 + 2?",\n});\nconsole.log(response);\n/*\n  { operation: \'add\', number1: 2, number2: 2 }\n*/\n\n/**\n * You can supply a "name" field to give the LLM additional context\n * around what you are trying to generate. You can also pass\n * \'includeRaw\' to get the raw message back from the model too.\n */\nconst includeRawModel = model.withStructuredOutput(calculatorSchema, {\n  name: "calculator",\n  includeRaw: true,\n});\nconst includeRawChain = prompt.pipe(includeRawModel);\n\nconst includeRawResponse = await includeRawChain.invoke({\n  input: "What is 2 + 2?",\n});\nconsole.log(JSON.stringify(includeRawResponse, null, 2));\n/*\n{\n  "raw": {\n    "kwargs": {\n      "content": "Okay, let me use the calculator tool to find the result of 2 + 2:",\n      "additional_kwargs": {\n        "id": "msg_01HYwRhJoeqwr5LkSCHHks5t",\n        "type": "message",\n        "role": "assistant",\n        "model": "claude-3-haiku-20240307",\n        "usage": {\n          "input_tokens": 458,\n          "output_tokens": 109\n        },\n        "tool_calls": [\n          {\n            "id": "toolu_01LDJpdtEQrq6pXSqSgEHErC",\n            "type": "function",\n            "function": {\n              "arguments": "{\\"number1\\":2,\\"number2\\":2,\\"operation\\":\\"add\\"}",\n              "name": "calculator"\n            }\n          }\n        ]\n      },\n    }\n  },\n  "parsed": {\n    "operation": "add",\n    "number1": 2,\n    "number2": 2\n  }\n}\n*/\n',imports:[{local:"ChatAnthropic",imported:"ChatAnthropic",source:"@langchain/anthropic"},{local:"ChatPromptTemplate",imported:"ChatPromptTemplate",source:"@langchain/core/prompts"}]}}}]);