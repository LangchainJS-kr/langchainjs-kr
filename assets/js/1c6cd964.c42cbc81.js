(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1533],{64254:(e,n,a)=>{"use strict";a.r(n),a.d(n,{assets:()=>h,contentTitle:()=>g,default:()=>f,frontMatter:()=>m,metadata:()=>p,toc:()=>u});var t=a(74848),i=a(28453),s=a(78847),r=a(64428),o=a(6359),l=a.n(o),d=a(86515),c=a.n(d);const m={sidebar_class_name:"node-only"},g="Gradient AI",p={id:"integrations/llms/gradient_ai",title:"Gradient AI",description:"LangChain.js supports integration with Gradient AI. Check out Gradient AI for a list of available models.",source:"@site/docs/integrations/llms/gradient_ai.mdx",sourceDirName:"integrations/llms",slug:"/integrations/llms/gradient_ai",permalink:"/docs/integrations/llms/gradient_ai",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/integrations/llms/gradient_ai.mdx",tags:[],version:"current",frontMatter:{sidebar_class_name:"node-only"},sidebar:"integrations",previous:{title:"Google Vertex AI",permalink:"/docs/integrations/llms/google_vertex_ai"},next:{title:"HuggingFaceInference",permalink:"/docs/integrations/llms/huggingface_inference"}},h={},u=[{value:"Setup",id:"setup",level:2},{value:"Usage",id:"usage",level:2},...s.toc,{value:"Using Gradient&#39;s Base Models",id:"using-gradients-base-models",level:3},{value:"Using your own fine-tuned Adapters",id:"using-your-own-fine-tuned-adapters",level:3}];function x(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"gradient-ai",children:"Gradient AI"}),"\n",(0,t.jsxs)(n.p,{children:["LangChain.js supports integration with Gradient AI. Check out ",(0,t.jsx)(n.a,{href:"https://docs.gradient.ai/docs",children:"Gradient AI"})," for a list of available models."]}),"\n",(0,t.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,t.jsx)(n.p,{children:"You'll need to install the official Gradient Node SDK as a peer dependency:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:"npm2yarn",children:"npm i @gradientai/nodejs-sdk\n"})}),"\n",(0,t.jsx)(n.p,{children:"You will need to set the following environment variables for using the Gradient AI API."}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"GRADIENT_ACCESS_TOKEN"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.code,{children:"GRADIENT_WORKSPACE_ID"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Alternatively, these can be set during the GradientAI Class instantiation as ",(0,t.jsx)(n.code,{children:"gradientAccessKey"})," and ",(0,t.jsx)(n.code,{children:"workspaceId"})," respectively.\nFor example:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const model = new GradientLLM({\n  gradientAccessKey: "My secret Access Token"\n  workspaceId: "My secret workspace id"\n});\n'})}),"\n",(0,t.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n","\n",(0,t.jsx)(s.default,{}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/community\n"})}),"\n","\n",(0,t.jsx)(n.h3,{id:"using-gradients-base-models",children:"Using Gradient's Base Models"}),"\n",(0,t.jsx)(r.A,{language:"typescript",children:l()}),"\n",(0,t.jsx)(n.h3,{id:"using-your-own-fine-tuned-adapters",children:"Using your own fine-tuned Adapters"}),"\n",(0,t.jsxs)(n.p,{children:["The use your own custom adapter simply set ",(0,t.jsx)(n.code,{children:"adapterId"})," during setup."]}),"\n",(0,t.jsx)(r.A,{language:"typescript",children:c()})]})}function f(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(x,{...e})}):x(e)}},86515:e=>{e.exports={content:'import { GradientLLM } from "@langchain/community/llms/gradient_ai";\n\n// Note that inferenceParameters are optional\nconst model = new GradientLLM({\n  adapterId: process.env.GRADIENT_ADAPTER_ID,\n  inferenceParameters: {\n    maxGeneratedTokenCount: 20,\n    temperature: 0,\n  },\n});\nconst res = await model.invoke(\n  "What would be a good company name for a company that makes colorful socks?"\n);\n\nconsole.log({ res });\n',imports:[{local:"GradientLLM",imported:"GradientLLM",source:"@langchain/community/llms/gradient_ai"}]}},6359:e=>{e.exports={content:'import { GradientLLM } from "@langchain/community/llms/gradient_ai";\n\n// Note that inferenceParameters are optional\nconst model = new GradientLLM({\n  modelSlug: "llama2-7b-chat",\n  inferenceParameters: {\n    maxGeneratedTokenCount: 20,\n    temperature: 0,\n  },\n});\nconst res = await model.invoke(\n  "What would be a good company name for a company that makes colorful socks?"\n);\n\nconsole.log({ res });\n',imports:[{local:"GradientLLM",imported:"GradientLLM",source:"@langchain/community/llms/gradient_ai"}]}}}]);