"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3392],{11457:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>p,contentTitle:()=>i,default:()=>b,frontMatter:()=>l,metadata:()=>c,toc:()=>u});var t=o(74848),r=o(28453),s=o(78847),a=o(27846);const l={sidebar_class_name:"hidden",title:"How to get log probabilities"},i=void 0,c={id:"how_to/logprobs",title:"How to get log probabilities",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/logprobs.mdx",sourceDirName:"how_to",slug:"/how_to/logprobs",permalink:"/docs/how_to/logprobs",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/logprobs.mdx",tags:[],version:"current",frontMatter:{sidebar_class_name:"hidden",title:"How to get log probabilities"},sidebar:"tutorialSidebar",previous:{title:"LangChain Expression Language Cheatsheet",permalink:"/docs/how_to/lcel_cheatsheet"},next:{title:"How to add message history",permalink:"/docs/how_to/message_history"}},p={},u=[{value:"OpenAI",id:"openai",level:2},...s.toc,{value:"<code>topLogprobs</code>",id:"toplogprobs",level:2},{value:"Next steps",id:"next-steps",level:2}];function d(n){const e={a:"a",admonition:"admonition",code:"code",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(e.admonition,{title:"Prerequisites",type:"info",children:[(0,t.jsx)(e.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"../../docs/concepts/#chat-models",children:"Chat models"})}),"\n"]})]}),"\n",(0,t.jsx)(e.p,{children:"Certain chat models can be configured to return token-level log\nprobabilities representing the likelihood of a given token. This guide\nwalks through how to get this information in LangChain."}),"\n",(0,t.jsx)(e.h2,{id:"openai",children:"OpenAI"}),"\n",(0,t.jsxs)(e.p,{children:["Install the ",(0,t.jsx)(e.code,{children:"@langchain/openai"})," package and set your API key:"]}),"\n","\n",(0,t.jsx)(s.default,{}),"\n",(0,t.jsx)(a.A,{children:(0,t.jsx)(e.p,{children:"@langchain/openai"})}),"\n",(0,t.jsxs)(e.p,{children:["For the OpenAI API to return log probabilities, we need to set the\n",(0,t.jsx)(e.code,{children:"logprobs"})," param to ",(0,t.jsx)(e.code,{children:"true"}),". Then, the logprobs are included on each\noutput\n",(0,t.jsx)(e.a,{href:"https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html",children:(0,t.jsx)(e.code,{children:"AIMessage"})}),"\nas part of the ",(0,t.jsx)(e.code,{children:"response_metadata"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-typescript",children:'import { ChatOpenAI } from "@langchain/openai";\n\nconst model = new ChatOpenAI({\n  model: "gpt-4o",\n  logprobs: true,\n});\n\nconst responseMessage = await model.invoke("how are you today?");\n\nresponseMessage.response_metadata.logprobs.content.slice(0, 5);\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-text",children:'[\n  {\n    token: "Thank",\n    logprob: -0.70174205,\n    bytes: [ 84, 104, 97, 110, 107 ],\n    top_logprobs: []\n  },\n  {\n    token: " you",\n    logprob: 0,\n    bytes: [ 32, 121, 111, 117 ],\n    top_logprobs: []\n  },\n  {\n    token: " for",\n    logprob: -0.000004723352,\n    bytes: [ 32, 102, 111, 114 ],\n    top_logprobs: []\n  },\n  {\n    token: " asking",\n    logprob: -0.0000013856493,\n    bytes: [\n       32,  97, 115,\n      107, 105, 110,\n      103\n    ],\n    top_logprobs: []\n  },\n  {\n    token: "!",\n    logprob: -0.00030102333,\n    bytes: [ 33 ],\n    top_logprobs: []\n  }\n]\n'})}),"\n",(0,t.jsx)(e.p,{children:"And are part of streamed Message chunks as well:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-typescript",children:'let count = 0;\nconst stream = await model.stream("How are you today?");\nlet aggregateResponse;\n\nfor await (const chunk of stream) {\n  if (count > 5) {\n    break;\n  }\n  if (aggregateResponse === undefined) {\n    aggregateResponse = chunk;\n  } else {\n    aggregateResponse = aggregateResponse.concat(chunk);\n  }\n  console.log(aggregateResponse.response_metadata.logprobs?.content);\n  count++;\n}\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-text",children:'[]\n[\n  {\n    token: "Thank",\n    logprob: -0.23375113,\n    bytes: [ 84, 104, 97, 110, 107 ],\n    top_logprobs: []\n  }\n]\n[\n  {\n    token: "Thank",\n    logprob: -0.23375113,\n    bytes: [ 84, 104, 97, 110, 107 ],\n    top_logprobs: []\n  },\n  {\n    token: " you",\n    logprob: 0,\n    bytes: [ 32, 121, 111, 117 ],\n    top_logprobs: []\n  }\n]\n[\n  {\n    token: "Thank",\n    logprob: -0.23375113,\n    bytes: [ 84, 104, 97, 110, 107 ],\n    top_logprobs: []\n  },\n  {\n    token: " you",\n    logprob: 0,\n    bytes: [ 32, 121, 111, 117 ],\n    top_logprobs: []\n  },\n  {\n    token: " for",\n    logprob: -0.000004723352,\n    bytes: [ 32, 102, 111, 114 ],\n    top_logprobs: []\n  }\n]\n[\n  {\n    token: "Thank",\n    logprob: -0.23375113,\n    bytes: [ 84, 104, 97, 110, 107 ],\n    top_logprobs: []\n  },\n  {\n    token: " you",\n    logprob: 0,\n    bytes: [ 32, 121, 111, 117 ],\n    top_logprobs: []\n  },\n  {\n    token: " for",\n    logprob: -0.000004723352,\n    bytes: [ 32, 102, 111, 114 ],\n    top_logprobs: []\n  },\n  {\n    token: " asking",\n    logprob: -0.0000029352968,\n    bytes: [\n       32,  97, 115,\n      107, 105, 110,\n      103\n    ],\n    top_logprobs: []\n  }\n]\n[\n  {\n    token: "Thank",\n    logprob: -0.23375113,\n    bytes: [ 84, 104, 97, 110, 107 ],\n    top_logprobs: []\n  },\n  {\n    token: " you",\n    logprob: 0,\n    bytes: [ 32, 121, 111, 117 ],\n    top_logprobs: []\n  },\n  {\n    token: " for",\n    logprob: -0.000004723352,\n    bytes: [ 32, 102, 111, 114 ],\n    top_logprobs: []\n  },\n  {\n    token: " asking",\n    logprob: -0.0000029352968,\n    bytes: [\n       32,  97, 115,\n      107, 105, 110,\n      103\n    ],\n    top_logprobs: []\n  },\n  {\n    token: "!",\n    logprob: -0.00039694557,\n    bytes: [ 33 ],\n    top_logprobs: []\n  }\n]\n'})}),"\n",(0,t.jsx)(e.h2,{id:"toplogprobs",children:(0,t.jsx)(e.code,{children:"topLogprobs"})}),"\n",(0,t.jsxs)(e.p,{children:["To see alternate potential generations at each step, you can use the\n",(0,t.jsx)(e.code,{children:"topLogprobs"})," parameter:"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-typescript",children:'const model = new ChatOpenAI({\n  model: "gpt-4o",\n  logprobs: true,\n  topLogprobs: 3,\n});\n\nconst responseMessage = await model.invoke("how are you today?");\n\nresponseMessage.response_metadata.logprobs.content.slice(0, 5);\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-text",children:'[\n  {\n    token: "I\'m",\n    logprob: -2.2864406,\n    bytes: [ 73, 39, 109 ],\n    top_logprobs: [\n      {\n        token: "Thank",\n        logprob: -0.28644064,\n        bytes: [ 84, 104, 97, 110, 107 ]\n      },\n      {\n        token: "Hello",\n        logprob: -2.0364406,\n        bytes: [ 72, 101, 108, 108, 111 ]\n      },\n      { token: "I\'m", logprob: -2.2864406, bytes: [ 73, 39, 109 ] }\n    ]\n  },\n  {\n    token: " just",\n    logprob: -0.14442946,\n    bytes: [ 32, 106, 117, 115, 116 ],\n    top_logprobs: [\n      {\n        token: " just",\n        logprob: -0.14442946,\n        bytes: [ 32, 106, 117, 115, 116 ]\n      },\n      { token: " an", logprob: -2.2694294, bytes: [ 32, 97, 110 ] },\n      {\n        token: " here",\n        logprob: -4.0194297,\n        bytes: [ 32, 104, 101, 114, 101 ]\n      }\n    ]\n  },\n  {\n    token: " a",\n    logprob: -0.00066632946,\n    bytes: [ 32, 97 ],\n    top_logprobs: [\n      { token: " a", logprob: -0.00066632946, bytes: [ 32, 97 ] },\n      {\n        token: " lines",\n        logprob: -7.750666,\n        bytes: [ 32, 108, 105, 110, 101, 115 ]\n      },\n      { token: " an", logprob: -9.250667, bytes: [ 32, 97, 110 ] }\n    ]\n  },\n  {\n    token: " computer",\n    logprob: -0.015423919,\n    bytes: [\n       32,  99, 111, 109,\n      112, 117, 116, 101,\n      114\n    ],\n    top_logprobs: [\n      {\n        token: " computer",\n        logprob: -0.015423919,\n        bytes: [\n           32,  99, 111, 109,\n          112, 117, 116, 101,\n          114\n        ]\n      },\n      {\n        token: " program",\n        logprob: -5.265424,\n        bytes: [\n           32, 112, 114, 111,\n          103, 114,  97, 109\n        ]\n      },\n      {\n        token: " machine",\n        logprob: -5.390424,\n        bytes: [\n           32, 109,  97,  99,\n          104, 105, 110, 101\n        ]\n      }\n    ]\n  },\n  {\n    token: " program",\n    logprob: -0.0010724656,\n    bytes: [\n       32, 112, 114, 111,\n      103, 114,  97, 109\n    ],\n    top_logprobs: [\n      {\n        token: " program",\n        logprob: -0.0010724656,\n        bytes: [\n           32, 112, 114, 111,\n          103, 114,  97, 109\n        ]\n      },\n      {\n        token: "-based",\n        logprob: -6.8760724,\n        bytes: [ 45, 98, 97, 115, 101, 100 ]\n      },\n      {\n        token: " algorithm",\n        logprob: -10.626073,\n        bytes: [\n           32,  97, 108, 103,\n          111, 114, 105, 116,\n          104, 109\n        ]\n      }\n    ]\n  }\n]\n'})}),"\n",(0,t.jsx)(e.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,t.jsx)(e.p,{children:"You\u2019ve now learned how to get logprobs from OpenAI models in LangChain."}),"\n",(0,t.jsxs)(e.p,{children:["Next, check out the other how-to guides chat models in this section,\nlike ",(0,t.jsx)(e.a,{href:"../../docs/how_to/structured_output",children:"how to get a model to return structured\noutput"})," or ",(0,t.jsx)(e.a,{href:"../../docs/how_to/chat_token_usage_tracking",children:"how to track token\nusage"}),"."]})]})}function b(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},19365:(n,e,o)=>{o.d(e,{A:()=>a});o(96540);var t=o(34164);const r={tabItem:"tabItem_Ymn6"};var s=o(74848);function a(n){let{children:e,hidden:o,className:a}=n;return(0,s.jsx)("div",{role:"tabpanel",className:(0,t.A)(r.tabItem,a),hidden:o,children:e})}},11470:(n,e,o)=>{o.d(e,{A:()=>v});var t=o(96540),r=o(34164),s=o(23104),a=o(56347),l=o(205),i=o(57485),c=o(31682),p=o(89466);function u(n){return t.Children.toArray(n).filter((n=>"\n"!==n)).map((n=>{if(!n||(0,t.isValidElement)(n)&&function(n){const{props:e}=n;return!!e&&"object"==typeof e&&"value"in e}(n))return n;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof n.type?n.type:n.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function d(n){const{values:e,children:o}=n;return(0,t.useMemo)((()=>{const n=e??function(n){return u(n).map((n=>{let{props:{value:e,label:o,attributes:t,default:r}}=n;return{value:e,label:o,attributes:t,default:r}}))}(o);return function(n){const e=(0,c.X)(n,((n,e)=>n.value===e.value));if(e.length>0)throw new Error(`Docusaurus error: Duplicate values "${e.map((n=>n.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(n),n}),[e,o])}function b(n){let{value:e,tabValues:o}=n;return o.some((n=>n.value===e))}function g(n){let{queryString:e=!1,groupId:o}=n;const r=(0,a.W6)(),s=function(n){let{queryString:e=!1,groupId:o}=n;if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!o)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return o??null}({queryString:e,groupId:o});return[(0,i.aZ)(s),(0,t.useCallback)((n=>{if(!s)return;const e=new URLSearchParams(r.location.search);e.set(s,n),r.replace({...r.location,search:e.toString()})}),[s,r])]}function h(n){const{defaultValue:e,queryString:o=!1,groupId:r}=n,s=d(n),[a,i]=(0,t.useState)((()=>function(n){let{defaultValue:e,tabValues:o}=n;if(0===o.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!b({value:e,tabValues:o}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${o.map((n=>n.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=o.find((n=>n.default))??o[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:e,tabValues:s}))),[c,u]=g({queryString:o,groupId:r}),[h,m]=function(n){let{groupId:e}=n;const o=function(n){return n?`docusaurus.tab.${n}`:null}(e),[r,s]=(0,p.Dv)(o);return[r,(0,t.useCallback)((n=>{o&&s.set(n)}),[o,s])]}({groupId:r}),f=(()=>{const n=c??h;return b({value:n,tabValues:s})?n:null})();(0,l.A)((()=>{f&&i(f)}),[f]);return{selectedValue:a,selectValue:(0,t.useCallback)((n=>{if(!b({value:n,tabValues:s}))throw new Error(`Can't select invalid tab value=${n}`);i(n),u(n),m(n)}),[u,m,s]),tabValues:s}}var m=o(92303);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=o(74848);function k(n){let{className:e,block:o,selectedValue:t,selectValue:a,tabValues:l}=n;const i=[],{blockElementScrollPositionUntilNextRender:c}=(0,s.a_)(),p=n=>{const e=n.currentTarget,o=i.indexOf(e),r=l[o].value;r!==t&&(c(e),a(r))},u=n=>{let e=null;switch(n.key){case"Enter":p(n);break;case"ArrowRight":{const o=i.indexOf(n.currentTarget)+1;e=i[o]??i[0];break}case"ArrowLeft":{const o=i.indexOf(n.currentTarget)-1;e=i[o]??i[i.length-1];break}}e?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":o},e),children:l.map((n=>{let{value:e,label:o,attributes:s}=n;return(0,y.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:n=>i.push(n),onKeyDown:u,onClick:p,...s,className:(0,r.A)("tabs__item",f.tabItem,s?.className,{"tabs__item--active":t===e}),children:o??e},e)}))})}function x(n){let{lazy:e,children:o,selectedValue:r}=n;const s=(Array.isArray(o)?o:[o]).filter(Boolean);if(e){const n=s.find((n=>n.props.value===r));return n?(0,t.cloneElement)(n,{className:"margin-top--md"}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:s.map(((n,e)=>(0,t.cloneElement)(n,{key:e,hidden:n.props.value!==r})))})}function j(n){const e=h(n);return(0,y.jsxs)("div",{className:(0,r.A)("tabs-container",f.tabList),children:[(0,y.jsx)(k,{...e,...n}),(0,y.jsx)(x,{...e,...n})]})}function v(n){const e=(0,m.A)();return(0,y.jsx)(j,{...n,children:u(n.children)},String(e))}},27846:(n,e,o)=>{o.d(e,{A:()=>l});o(96540);var t=o(11470),r=o(19365),s=o(21432),a=o(74848);function l(n){let{children:e}=n;return(0,a.jsxs)(t.A,{groupId:"npm2yarn",children:[(0,a.jsx)(r.A,{value:"npm",label:"npm",children:(0,a.jsxs)(s.A,{language:"bash",children:["npm i ",e]})}),(0,a.jsx)(r.A,{value:"yarn",label:"yarn",default:!0,children:(0,a.jsxs)(s.A,{language:"bash",children:["yarn add ",e]})}),(0,a.jsx)(r.A,{value:"pnpm",label:"pnpm",children:(0,a.jsxs)(s.A,{language:"bash",children:["pnpm add ",e]})})]})}}}]);