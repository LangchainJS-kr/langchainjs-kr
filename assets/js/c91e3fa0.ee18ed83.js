(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7485],{67635:(e,n,r)=>{"use strict";r.r(n),r.d(n,{assets:()=>m,contentTitle:()=>h,default:()=>g,frontMatter:()=>l,metadata:()=>d,toc:()=>u});var t=r(74848),a=r(28453),s=r(78847),o=r(64428),i=r(50667),c=r.n(i);const l={sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},h="How to reduce retrieval latency",d={id:"how_to/reduce_retrieval_latency",title:"How to reduce retrieval latency",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/reduce_retrieval_latency.mdx",sourceDirName:"how_to",slug:"/how_to/reduce_retrieval_latency",permalink:"/docs/how_to/reduce_retrieval_latency",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/reduce_retrieval_latency.mdx",tags:[],version:"current",frontMatter:{sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},sidebar:"tutorialSidebar"},m={},u=[{value:"Setup",id:"setup",level:3},...s.toc,{value:"Next steps",id:"next-steps",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"how-to-reduce-retrieval-latency",children:"How to reduce retrieval latency"}),"\n",(0,t.jsxs)(n.admonition,{title:"Prerequisites",type:"info",children:[(0,t.jsx)(n.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/docs/concepts/#retrievers",children:"Retrievers"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/docs/concepts/#embedding-models",children:"Embeddings"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/docs/concepts/#vectorstores",children:"Vector stores"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"/docs/tutorials/rag",children:"Retrieval-augmented generation (RAG)"})}),"\n"]})]}),"\n",(0,t.jsxs)(n.p,{children:['One way to reduce retrieval latency is through a technique called "Adaptive Retrieval".\nThe ',(0,t.jsx)(n.a,{href:"https://v02.api.js.langchain.com/classes/langchain_retrievers_matryoshka_retriever.MatryoshkaRetriever.html",children:(0,t.jsx)(n.code,{children:"MatryoshkaRetriever"})})," uses the\nMatryoshka Representation Learning (MRL) technique to retrieve documents for a given query in two steps:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"First-pass"}),": Uses a lower dimensional sub-vector from the MRL embedding for an initial, fast,\nbut less accurate search."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Second-pass"}),": Re-ranks the top results from the first pass using the full, high-dimensional\nembedding for higher accuracy."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Matryoshka Retriever",src:r(79340).A+"",width:"1602",height:"1504"})}),"\n",(0,t.jsxs)(n.p,{children:["It is based on this ",(0,t.jsx)(n.a,{href:"https://supabase.com/",children:"Supabase"})," blog post\n",(0,t.jsx)(n.a,{href:"https://supabase.com/blog/matryoshka-embeddings",children:'"Matryoshka embeddings: faster OpenAI vector search using Adaptive Retrieval"'}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"setup",children:"Setup"}),"\n","\n",(0,t.jsx)(s.default,{}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/openai @langchain/community\n"})}),"\n",(0,t.jsx)(n.p,{children:"To follow the example below, you need an OpenAI API key:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"export OPENAI_API_KEY=your-api-key\n"})}),"\n",(0,t.jsxs)(n.p,{children:["We'll also be using ",(0,t.jsx)(n.code,{children:"chroma"})," for our vector store. Follow the instructions ",(0,t.jsx)(n.a,{href:"/docs/integrations/vectorstores/chroma",children:"here"})," to setup."]}),"\n","\n",(0,t.jsx)(o.A,{language:"typescript",children:c()}),"\n",(0,t.jsx)(n.admonition,{type:"note",children:(0,t.jsxs)(n.p,{children:["Due to the constraints of some vector stores, the large embedding metadata field is stringified (",(0,t.jsx)(n.code,{children:"JSON.stringify"}),") before being stored. This means that the metadata field will need to be parsed (",(0,t.jsx)(n.code,{children:"JSON.parse"}),") when retrieved from the vector store."]})}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,t.jsx)(n.p,{children:"You've now learned a technique that can help speed up your retrieval queries."}),"\n",(0,t.jsxs)(n.p,{children:["Next, check out the ",(0,t.jsx)(n.a,{href:"/docs/tutorials/rag",children:"broader tutorial on RAG"}),", or this section to learn how to\n",(0,t.jsx)(n.a,{href:"/docs/how_to/custom_retriever/",children:"create your own custom retriever over any data source"}),"."]})]})}function g(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},50667:e=>{e.exports={content:'import { MatryoshkaRetriever } from "langchain/retrievers/matryoshka_retriever";\nimport { Chroma } from "@langchain/community/vectorstores/chroma";\nimport { OpenAIEmbeddings } from "@langchain/openai";\nimport { Document } from "@langchain/core/documents";\nimport { faker } from "@faker-js/faker";\n\nconst smallEmbeddings = new OpenAIEmbeddings({\n  model: "text-embedding-3-small",\n  dimensions: 512, // Min number for small\n});\n\nconst largeEmbeddings = new OpenAIEmbeddings({\n  model: "text-embedding-3-large",\n  dimensions: 3072, // Max number for large\n});\n\nconst vectorStore = new Chroma(smallEmbeddings, {\n  numDimensions: 512,\n});\n\nconst retriever = new MatryoshkaRetriever({\n  vectorStore,\n  largeEmbeddingModel: largeEmbeddings,\n  largeK: 5,\n});\n\nconst irrelevantDocs = Array.from({ length: 250 }).map(\n  () =>\n    new Document({\n      pageContent: faker.lorem.word(7), // Similar length to the relevant docs\n    })\n);\nconst relevantDocs = [\n  new Document({\n    pageContent: "LangChain is an open source github repo",\n  }),\n  new Document({\n    pageContent: "There are JS and PY versions of the LangChain github repos",\n  }),\n  new Document({\n    pageContent: "LangGraph is a new open source library by the LangChain team",\n  }),\n  new Document({\n    pageContent: "LangChain announced GA of LangSmith last week!",\n  }),\n  new Document({\n    pageContent: "I heart LangChain",\n  }),\n];\nconst allDocs = [...irrelevantDocs, ...relevantDocs];\n\n/**\n * IMPORTANT:\n * The `addDocuments` method on `MatryoshkaRetriever` will\n * generate the small AND large embeddings for all documents.\n */\nawait retriever.addDocuments(allDocs);\n\nconst query = "What is LangChain?";\nconst results = await retriever.invoke(query);\nconsole.log(results.map(({ pageContent }) => pageContent).join("\\n"));\n\n/**\n  I heart LangChain\n  LangGraph is a new open source library by the LangChain team\n  LangChain is an open source github repo\n  LangChain announced GA of LangSmith last week!\n  There are JS and PY versions of the LangChain github repos\n*/\n',imports:[{local:"MatryoshkaRetriever",imported:"MatryoshkaRetriever",source:"langchain/retrievers/matryoshka_retriever"},{local:"Chroma",imported:"Chroma",source:"@langchain/community/vectorstores/chroma"},{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"Document",imported:"Document",source:"@langchain/core/documents"}]}},79340:(e,n,r)=>{"use strict";r.d(n,{A:()=>t});const t=r.p+"assets/images/adaptive_retrieval-2abb9f6f280c11a424ae6978d39eb011.png"}}]);