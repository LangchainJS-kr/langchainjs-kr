"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9576],{77006:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>h,contentTitle:()=>l,default:()=>u,frontMatter:()=>r,metadata:()=>c,toc:()=>d});var t=a(74848),s=a(28453),o=a(27846),i=a(63142);const r={title:"How to use legacy LangChain Agents (AgentExecutor)",sidebar_class_name:"hidden"},l=void 0,c={id:"how_to/agent_executor",title:"How to use legacy LangChain Agents (AgentExecutor)",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/agent_executor.mdx",sourceDirName:"how_to",slug:"/how_to/agent_executor",permalink:"/docs/how_to/agent_executor",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/agent_executor.mdx",tags:[],version:"current",frontMatter:{title:"How to use legacy LangChain Agents (AgentExecutor)",sidebar_class_name:"hidden"},sidebar:"tutorialSidebar",previous:{title:"How to compose prompts together",permalink:"/docs/how_to/prompts_composition"},next:{title:"How to add values to a chain's state",permalink:"/docs/how_to/assign"}},h={},d=[{value:"Concepts",id:"concepts",level:2},{value:"Setup",id:"setup",level:2},{value:"Jupyter Notebook",id:"jupyter-notebook",level:3},{value:"Installation",id:"installation",level:3},{value:"LangSmith",id:"langsmith",level:3},{value:"Define tools",id:"define-tools",level:2},{value:"Tavily",id:"tavily",level:3},{value:"Retriever",id:"retriever",level:3},{value:"Tools",id:"tools",level:3},{value:"Using Language Models",id:"using-language-models",level:2},{value:"Create the agent",id:"create-the-agent",level:2},{value:"Run the agent",id:"run-the-agent",level:2},{value:"Adding in memory",id:"adding-in-memory",level:2},{value:"Conclusion",id:"conclusion",level:2}];function p(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.admonition,{title:"Prerequisites",type:"info",children:[(0,t.jsx)(n.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"../../docs/concepts#tools",children:"Tools"})}),"\n"]})]}),"\n",(0,t.jsx)(n.p,{children:"By themselves, language models can\u2019t take actions - they just output\ntext. Agents are systems that use an LLM as a reasoning engine to\ndetermine which actions to take and what the inputs to those actions\nshould be. The results of those actions can then be fed back into the\nagent and it determine whether more actions are needed, or whether it is\nokay to finish."}),"\n",(0,t.jsx)(n.p,{children:"In this tutorial we will build an agent that can interact with multiple\ndifferent tools: one being a local database, the other being a search\nengine. You will be able to ask this agent questions, watch it call\ntools, and have conversations with it."}),"\n",(0,t.jsx)(n.admonition,{type:"important",children:(0,t.jsxs)(n.p,{children:["This section will cover building with LangChain Agents. LangChain Agents\nare fine for getting started, but past a certain point you will likely\nwant flexibility and control that they do not offer. For working with\nmore advanced agents, we\u2019d recommend checking out\n",(0,t.jsx)(n.a,{href:"../../docs/concepts/#langgraph",children:"LangGraph"}),"."]})}),"\n",(0,t.jsx)(n.h2,{id:"concepts",children:"Concepts"}),"\n",(0,t.jsxs)(n.p,{children:["Concepts we will cover are: - Using ",(0,t.jsx)(n.a,{href:"../../docs/concepts/#chat-models",children:"language\nmodels"}),", in particular their tool\ncalling ability - Creating a\n",(0,t.jsx)(n.a,{href:"../../docs/concepts/#retrievers",children:"Retriever"})," to expose specific\ninformation to our agent - Using a Search\n",(0,t.jsx)(n.a,{href:"../../docs/concepts/#tools",children:"Tool"})," to look up things online -\n",(0,t.jsx)(n.a,{href:"../../docs/concepts/#chat-history",children:(0,t.jsx)(n.code,{children:"Chat History"})}),", which allows a\nchatbot to \u201cremember\u201d past interactions and take them into account when\nresponding to followup questions. - Debugging and tracing your\napplication using ",(0,t.jsx)(n.a,{href:"../../docs/concepts/#langsmith",children:"LangSmith"})]}),"\n",(0,t.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,t.jsx)(n.h3,{id:"jupyter-notebook",children:"Jupyter Notebook"}),"\n",(0,t.jsxs)(n.p,{children:["This guide (and most of the other guides in the documentation) uses\n",(0,t.jsx)(n.a,{href:"https://jupyter.org/",children:"Jupyter notebooks"})," and assumes the reader is as\nwell. Jupyter notebooks are perfect for learning how to work with LLM\nsystems because oftentimes things can go wrong (unexpected output, API\ndown, etc) and going through guides in an interactive environment is a\ngreat way to better understand them."]}),"\n",(0,t.jsxs)(n.p,{children:["This and other tutorials are perhaps most conveniently run in a Jupyter\nnotebook. See ",(0,t.jsx)(n.a,{href:"https://jupyter.org/install",children:"here"})," for instructions on\nhow to install."]}),"\n",(0,t.jsx)(n.h3,{id:"installation",children:"Installation"}),"\n",(0,t.jsxs)(n.p,{children:["To install LangChain (and ",(0,t.jsx)(n.code,{children:"cheerio"})," for the web loader) run:"]}),"\n","\n",(0,t.jsx)(o.A,{children:(0,t.jsx)(n.p,{children:"langchain cheerio"})}),"\n",(0,t.jsxs)(n.p,{children:["For more details, see our ",(0,t.jsx)(n.a,{href:"../../docs/how_to/installation/",children:"Installation\nguide"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"langsmith",children:"LangSmith"}),"\n",(0,t.jsxs)(n.p,{children:["Many of the applications you build with LangChain will contain multiple\nsteps with multiple invocations of LLM calls. As these applications get\nmore and more complex, it becomes crucial to be able to inspect what\nexactly is going on inside your chain or agent. The best way to do this\nis with ",(0,t.jsx)(n.a,{href:"https://smith.langchain.com",children:"LangSmith"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"After you sign up at the link above, make sure to set your environment\nvariables to start logging traces:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:'export LANGCHAIN_TRACING_V2="true"\nexport LANGCHAIN_API_KEY="..."\n'})}),"\n",(0,t.jsx)(n.h2,{id:"define-tools",children:"Define tools"}),"\n",(0,t.jsxs)(n.p,{children:["We first need to create the tools we want to use. We will use two tools:\n",(0,t.jsx)(n.a,{href:"../../docs/integrations/tools/tavily_search",children:"Tavily"})," (to search online)\nand then a retriever over a local index we will create"]}),"\n",(0,t.jsx)(n.h3,{id:"tavily",children:(0,t.jsx)(n.a,{href:"../../docs/integrations/tools/tavily_search",children:"Tavily"})}),"\n",(0,t.jsx)(n.p,{children:"We have a built-in tool in LangChain to easily use Tavily search engine\nas tool. Note that this requires an API key - they have a free tier, but\nif you don\u2019t have one or don\u2019t want to create one, you can always ignore\nthis step."}),"\n",(0,t.jsx)(n.p,{children:"Once you create your API key, you will need to export that as:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:'export TAVILY_API_KEY="..."\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { TavilySearchResults } from "@langchain/community/tools/tavily_search";\n\nconst search = new TavilySearchResults({\n  maxResults: 2,\n});\n\nawait search.invoke("what is the weather in SF");\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'`[{"title":"Weather in San Francisco","url":"https://www.weatherapi.com/","content":"{\'location\': {\'n`... 1111 more characters\n'})}),"\n",(0,t.jsx)(n.h3,{id:"retriever",children:"Retriever"}),"\n",(0,t.jsxs)(n.p,{children:["We will also create a retriever over some data of our own. For a deeper\nexplanation of each step here, see ",(0,t.jsx)(n.a,{href:"../../docs/tutorials/rag",children:"this\ntutorial"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import "cheerio"; // This is required in notebooks to use the `CheerioWebBaseLoader`\nimport { CheerioWebBaseLoader } from "langchain/document_loaders/web/cheerio";\nimport { MemoryVectorStore } from "langchain/vectorstores/memory";\nimport { OpenAIEmbeddings } from "@langchain/openai";\nimport { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";\n\nconst loader = new CheerioWebBaseLoader(\n  "https://docs.smith.langchain.com/overview"\n);\nconst docs = await loader.load();\nconst documents = await new RecursiveCharacterTextSplitter({\n  chunkSize: 1000,\n  chunkOverlap: 200,\n}).splitDocuments(docs);\nconst vectorStore = await MemoryVectorStore.fromDocuments(\n  documents,\n  new OpenAIEmbeddings()\n);\nconst retriever = vectorStore.asRetriever();\n\n(await retriever.invoke("how to upload a dataset"))[0];\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'Document {\n  pageContent: \'description="A sample dataset in LangSmith.")client.create_examples(    inputs=[        {"postfix": \'... 891 more characters,\n  metadata: {\n    source: "https://docs.smith.langchain.com/overview",\n    loc: { lines: { from: 4, to: 4 } }\n  }\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"Now that we have populated our index that we will do doing retrieval\nover, we can easily turn it into a tool (the format needed for an agent\nto properly use it)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { createRetrieverTool } from "langchain/tools/retriever";\n\nconst retrieverTool = await createRetrieverTool(retriever, {\n  name: "langsmith_search",\n  description:\n    "Search for information about LangSmith. For any questions about LangSmith, you must use this tool!",\n});\n'})}),"\n",(0,t.jsx)(n.h3,{id:"tools",children:"Tools"}),"\n",(0,t.jsx)(n.p,{children:"Now that we have created both, we can create a list of tools that we\nwill use downstream."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"const tools = [search, retrieverTool];\n"})}),"\n",(0,t.jsx)(n.h2,{id:"using-language-models",children:"Using Language Models"}),"\n",(0,t.jsx)(n.p,{children:"Next, let\u2019s learn how to use a language model by to call tools.\nLangChain supports many different language models that you can use\ninterchangably - select the one you want to use below!"}),"\n","\n",(0,t.jsx)(i.A,{openaiParams:'model: "gpt-4"'}),"\n",(0,t.jsxs)(n.p,{children:["You can call the language model by passing in a list of messages. By\ndefault, the response is a ",(0,t.jsx)(n.code,{children:"content"})," string."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { HumanMessage } from "@langchain/core/messages";\n\nconst response = await model.invoke([new HumanMessage("hi!")]);\n\nresponse.content;\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'"Hello! How can I assist you today?"\n'})}),"\n",(0,t.jsxs)(n.p,{children:["We can now see what it is like to enable this model to do tool calling.\nIn order to enable that we use ",(0,t.jsx)(n.code,{children:".bind"})," to give the language model\nknowledge of these tools"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:"const modelWithTools = model.bindTools(tools);\n"})}),"\n",(0,t.jsxs)(n.p,{children:["We can now call the model. Let\u2019s first call it with a normal message,\nand see how it responds. We can look at both the ",(0,t.jsx)(n.code,{children:"content"})," field as well\nas the ",(0,t.jsx)(n.code,{children:"tool_calls"})," field."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const response = await modelWithTools.invoke([new HumanMessage("Hi!")]);\n\nconsole.log(`Content: ${response.content}`);\nconsole.log(`Tool calls: ${response.tool_calls}`);\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:"Content: Hello! How can I assist you today?\nTool calls:\n"})}),"\n",(0,t.jsx)(n.p,{children:"Now, let\u2019s try calling it with some input that would expect a tool to be\ncalled."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'const response = await modelWithTools.invoke([\n  new HumanMessage("What\'s the weather in SF?"),\n]);\n\nconsole.log(`Content: ${response.content}`);\nconsole.log(`Tool calls: ${JSON.stringify(response.tool_calls, null, 2)}`);\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'Content:\nTool calls: [\n  {\n    "name": "tavily_search_results_json",\n    "args": {\n      "input": "weather in San Francisco"\n    },\n    "id": "call_y0nn6mbVCV5paX6RrqqFUqdC"\n  }\n]\n'})}),"\n",(0,t.jsx)(n.p,{children:"We can see that there\u2019s now no content, but there is a tool call! It\nwants us to call the Tavily Search tool."}),"\n",(0,t.jsx)(n.p,{children:"This isn\u2019t calling that tool yet - it\u2019s just telling us to. In order to\nactually calll it, we\u2019ll want to create our agent."}),"\n",(0,t.jsx)(n.h2,{id:"create-the-agent",children:"Create the agent"}),"\n",(0,t.jsxs)(n.p,{children:["Now that we have defined the tools and the LLM, we can create the agent.\nWe will be using a tool calling agent - for more information on this\ntype of agent, as well as other options, see ",(0,t.jsx)(n.a,{href:"../../docs/concepts/#agent_types/",children:"this\nguide"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"We can first choose the prompt we want to use to guide the agent."}),"\n",(0,t.jsx)(n.p,{children:"If you want to see the contents of this prompt in the hub, you can go\nto:"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://smith.langchain.com/hub/hwchase17/openai-functions-agent",children:"https://smith.langchain.com/hub/hwchase17/openai-functions-agent"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { ChatPromptTemplate } from "@langchain/core/prompts";\nimport { pull } from "langchain/hub";\n\n// Get the prompt to use - you can modify this!\nconst prompt = await pull<ChatPromptTemplate>(\n  "hwchase17/openai-functions-agent"\n);\n\nconsole.log(prompt.promptMessages);\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'[\n  SystemMessagePromptTemplate {\n    lc_serializable: true,\n    lc_kwargs: {\n      prompt: PromptTemplate {\n        lc_serializable: true,\n        lc_kwargs: {\n          template: "You are a helpful assistant",\n          inputVariables: [],\n          templateFormat: "f-string",\n          partialVariables: {}\n        },\n        lc_runnable: true,\n        name: undefined,\n        lc_namespace: [ "langchain_core", "prompts", "prompt" ],\n        inputVariables: [],\n        outputParser: undefined,\n        partialVariables: {},\n        template: "You are a helpful assistant",\n        templateFormat: "f-string",\n        validateTemplate: true\n      }\n    },\n    lc_runnable: true,\n    name: undefined,\n    lc_namespace: [ "langchain_core", "prompts", "chat" ],\n    inputVariables: [],\n    additionalOptions: {},\n    prompt: PromptTemplate {\n      lc_serializable: true,\n      lc_kwargs: {\n        template: "You are a helpful assistant",\n        inputVariables: [],\n        templateFormat: "f-string",\n        partialVariables: {}\n      },\n      lc_runnable: true,\n      name: undefined,\n      lc_namespace: [ "langchain_core", "prompts", "prompt" ],\n      inputVariables: [],\n      outputParser: undefined,\n      partialVariables: {},\n      template: "You are a helpful assistant",\n      templateFormat: "f-string",\n      validateTemplate: true\n    },\n    messageClass: undefined,\n    chatMessageClass: undefined\n  },\n  MessagesPlaceholder {\n    lc_serializable: true,\n    lc_kwargs: { optional: true, variableName: "chat_history" },\n    lc_runnable: true,\n    name: undefined,\n    lc_namespace: [ "langchain_core", "prompts", "chat" ],\n    variableName: "chat_history",\n    optional: true\n  },\n  HumanMessagePromptTemplate {\n    lc_serializable: true,\n    lc_kwargs: {\n      prompt: PromptTemplate {\n        lc_serializable: true,\n        lc_kwargs: {\n          template: "{input}",\n          inputVariables: [Array],\n          templateFormat: "f-string",\n          partialVariables: {}\n        },\n        lc_runnable: true,\n        name: undefined,\n        lc_namespace: [ "langchain_core", "prompts", "prompt" ],\n        inputVariables: [ "input" ],\n        outputParser: undefined,\n        partialVariables: {},\n        template: "{input}",\n        templateFormat: "f-string",\n        validateTemplate: true\n      }\n    },\n    lc_runnable: true,\n    name: undefined,\n    lc_namespace: [ "langchain_core", "prompts", "chat" ],\n    inputVariables: [ "input" ],\n    additionalOptions: {},\n    prompt: PromptTemplate {\n      lc_serializable: true,\n      lc_kwargs: {\n        template: "{input}",\n        inputVariables: [ "input" ],\n        templateFormat: "f-string",\n        partialVariables: {}\n      },\n      lc_runnable: true,\n      name: undefined,\n      lc_namespace: [ "langchain_core", "prompts", "prompt" ],\n      inputVariables: [ "input" ],\n      outputParser: undefined,\n      partialVariables: {},\n      template: "{input}",\n      templateFormat: "f-string",\n      validateTemplate: true\n    },\n    messageClass: undefined,\n    chatMessageClass: undefined\n  },\n  MessagesPlaceholder {\n    lc_serializable: true,\n    lc_kwargs: { optional: false, variableName: "agent_scratchpad" },\n    lc_runnable: true,\n    name: undefined,\n    lc_namespace: [ "langchain_core", "prompts", "chat" ],\n    variableName: "agent_scratchpad",\n    optional: false\n  }\n]\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Now, we can initalize the agent with the LLM, the prompt, and the tools.\nThe agent is responsible for taking in input and deciding what actions\nto take. Crucially, the Agent does not execute those actions - that is\ndone by the AgentExecutor (next step). For more information about how to\nthink about these components, see our ",(0,t.jsx)(n.a,{href:"../../docs/concepts/#agents",children:"conceptual\nguide"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["Note that we are passing in the ",(0,t.jsx)(n.code,{children:"model"}),", not ",(0,t.jsx)(n.code,{children:"modelWithTools"}),". That is\nbecause ",(0,t.jsx)(n.code,{children:"createToolCallingAgent"})," will call ",(0,t.jsx)(n.code,{children:".bind"})," for us under the\nhood."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { createToolCallingAgent } from "langchain/agents";\n\nconst agent = await createToolCallingAgent({ llm: model, tools, prompt });\n'})}),"\n",(0,t.jsx)(n.p,{children:"Finally, we combine the agent (the brains) with the tools inside the\nAgentExecutor (which will repeatedly call the agent and execute tools)."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { AgentExecutor } from "langchain/agents";\n\nconst agentExecutor = new AgentExecutor({\n  agent,\n  tools,\n});\n'})}),"\n",(0,t.jsx)(n.h2,{id:"run-the-agent",children:"Run the agent"}),"\n",(0,t.jsxs)(n.p,{children:["We can now run the agent on a few queries! Note that for now, these are\nall ",(0,t.jsx)(n.strong,{children:"stateless"})," queries (it won\u2019t remember previous interactions)."]}),"\n",(0,t.jsx)(n.p,{children:"First up, let\u2019s how it responds when there\u2019s no need to call a tool:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'await agentExecutor.invoke({ input: "hi!" });\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{ input: "hi!", output: "Hello! How can I assist you today?" }\n'})}),"\n",(0,t.jsxs)(n.p,{children:["In order to see exactly what is happening under the hood (and to make\nsure it\u2019s not calling a tool) we can take a look at the ",(0,t.jsx)(n.a,{href:"https://smith.langchain.com/public/b8051e80-14fd-4931-be0f-6416280bc500/r",children:"LangSmith\ntrace"})]}),"\n",(0,t.jsx)(n.p,{children:"Let\u2019s now try it out on an example where it should be invoking the\nretriever"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'await agentExecutor.invoke({ input: "how can langsmith help with testing?" });\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{\n  input: "how can langsmith help with testing?",\n  output: "LangSmith can help with testing by providing a platform for building production-grade LLM applicatio"... 880 more characters\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Let\u2019s take a look at the ",(0,t.jsx)(n.a,{href:"https://smith.langchain.com/public/35bd4f0f-aa2f-4ac2-b9a9-89ce0ca306ca/r",children:"LangSmith\ntrace"}),"\nto make sure it\u2019s actually calling that."]}),"\n",(0,t.jsx)(n.p,{children:"Now let\u2019s try one where it needs to call the search tool:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'await agentExecutor.invoke({ input: "whats the weather in sf?" });\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{\n  input: "whats the weather in sf?",\n  output: "The current weather in San Francisco is partly cloudy with a temperature of 64.0\xb0F (17.8\xb0C). The win"... 112 more characters\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["We can check out the ",(0,t.jsx)(n.a,{href:"https://smith.langchain.com/public/dfde6f46-0e7b-4dfe-813c-87d7bfb2ade5/r",children:"LangSmith\ntrace"}),"\nto make sure it\u2019s calling the search tool effectively."]}),"\n",(0,t.jsx)(n.h2,{id:"adding-in-memory",children:"Adding in memory"}),"\n",(0,t.jsxs)(n.p,{children:["As mentioned earlier, this agent is stateless. This means it does not\nremember previous interactions. To give it memory we need to pass in\nprevious ",(0,t.jsx)(n.code,{children:"chat_history"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note"}),": The input variable needs to be called ",(0,t.jsx)(n.code,{children:"chat_history"})," because\nof the prompt we are using. If we use a different prompt, we could\nchange the variable name."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'// Here we pass in an empty list of messages for chat_history because it is the first message in the chat\nawait agentExecutor.invoke({ input: "hi! my name is bob", chat_history: [] });\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{\n  input: "hi! my name is bob",\n  chat_history: [],\n  output: "Hello Bob! How can I assist you today?"\n}\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { AIMessage, HumanMessage } from "@langchain/core/messages";\n\nawait agentExecutor.invoke({\n  chat_history: [\n    new HumanMessage("hi! my name is bob"),\n    new AIMessage("Hello Bob! How can I assist you today?"),\n  ],\n  input: "what\'s my name?",\n});\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{\n  chat_history: [\n    HumanMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "hi! my name is bob",\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "hi! my name is bob",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {}\n    },\n    AIMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "Hello Bob! How can I assist you today?",\n        tool_calls: [],\n        invalid_tool_calls: [],\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "Hello Bob! How can I assist you today?",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {},\n      tool_calls: [],\n      invalid_tool_calls: []\n    }\n  ],\n  input: "what\'s my name?",\n  output: "Your name is Bob! How can I help you, Bob?"\n}\n'})}),"\n",(0,t.jsx)(n.p,{children:"If we want to keep track of these messages automatically, we can wrap\nthis in a RunnableWithMessageHistory."}),"\n",(0,t.jsx)(n.p,{children:"Because we have multiple inputs, we need to specify two things:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"input_messages_key"}),": The input key to use to add to the\nconversation history."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"history_messages_key"}),": The key to add the loaded messages into."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["For more information on how to use this, see ",(0,t.jsx)(n.a,{href:"../../docs/how_to/message_history",children:"this\nguide"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'import { ChatMessageHistory } from "@langchain/community/stores/message/in_memory";\nimport { BaseChatMessageHistory } from "@langchain/core/chat_history";\nimport { RunnableWithMessageHistory } from "@langchain/core/runnables";\n\nconst store = {};\n\nfunction getMessageHistory(sessionId: string): BaseChatMessageHistory {\n  if (!(sessionId in store)) {\n    store[sessionId] = new ChatMessageHistory();\n  }\n  return store[sessionId];\n}\n\nconst agentWithChatHistory = new RunnableWithMessageHistory({\n  runnable: agentExecutor,\n  getMessageHistory,\n  inputMessagesKey: "input",\n  historyMessagesKey: "chat_history",\n});\n\nawait agentWithChatHistory.invoke(\n  { input: "hi! I\'m bob" },\n  { configurable: { sessionId: "<foo>" } }\n);\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{\n  input: "hi! I\'m bob",\n  chat_history: [\n    HumanMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "hi! I\'m bob",\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "hi! I\'m bob",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {}\n    },\n    AIMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "Hello Bob! How can I assist you today?",\n        tool_calls: [],\n        invalid_tool_calls: [],\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "Hello Bob! How can I assist you today?",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {},\n      tool_calls: [],\n      invalid_tool_calls: []\n    }\n  ],\n  output: "Hello Bob! How can I assist you today?"\n}\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-typescript",children:'await agentWithChatHistory.invoke(\n  { input: "what\'s my name?" },\n  { configurable: { sessionId: "<foo>" } }\n);\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-text",children:'{\n  input: "what\'s my name?",\n  chat_history: [\n    HumanMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "hi! I\'m bob",\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "hi! I\'m bob",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {}\n    },\n    AIMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "Hello Bob! How can I assist you today?",\n        tool_calls: [],\n        invalid_tool_calls: [],\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "Hello Bob! How can I assist you today?",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {},\n      tool_calls: [],\n      invalid_tool_calls: []\n    },\n    HumanMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "what\'s my name?",\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "what\'s my name?",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {}\n    },\n    AIMessage {\n      lc_serializable: true,\n      lc_kwargs: {\n        content: "Your name is Bob! How can I help you, Bob?",\n        tool_calls: [],\n        invalid_tool_calls: [],\n        additional_kwargs: {},\n        response_metadata: {}\n      },\n      lc_namespace: [ "langchain_core", "messages" ],\n      content: "Your name is Bob! How can I help you, Bob?",\n      name: undefined,\n      additional_kwargs: {},\n      response_metadata: {},\n      tool_calls: [],\n      invalid_tool_calls: []\n    }\n  ],\n  output: "Your name is Bob! How can I help you, Bob?"\n}\n'})}),"\n",(0,t.jsxs)(n.p,{children:["Example LangSmith trace:\n",(0,t.jsx)(n.a,{href:"https://smith.langchain.com/public/98c8d162-60ae-4493-aa9f-992d87bd0429/r",children:"https://smith.langchain.com/public/98c8d162-60ae-4493-aa9f-992d87bd0429/r"})]}),"\n",(0,t.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,t.jsx)(n.p,{children:"That\u2019s a wrap! In this quick start we covered how to create a simple\nagent. Agents are a complex topic, and there\u2019s lot to learn!"}),"\n",(0,t.jsx)(n.admonition,{type:"important",children:(0,t.jsxs)(n.p,{children:["This section covered building with LangChain Agents. LangChain Agents\nare fine for getting started, but past a certain point you will likely\nwant flexibility and control that they do not offer. For working with\nmore advanced agents, we\u2019d recommend checking out\n",(0,t.jsx)(n.a,{href:"../../docs/concepts/#langgraph",children:"LangGraph"})]})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(p,{...e})}):p(e)}},63142:(e,n,a)=>{a.d(n,{A:()=>p});a(96540);var t=a(11470),s=a(19365),o=a(21432),i=a(27846),r=a(27293),l=a(74848);function c(e){let{children:n}=e;return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(r.A,{type:"tip",children:(0,l.jsxs)("p",{children:["See"," ",(0,l.jsx)("a",{href:"/docs/get_started/installation#installing-integration-packages",children:"this section for general instructions on installing integration packages"}),"."]})}),(0,l.jsx)(i.A,{children:n})]})}const h={openaiParams:'{\n  model: "gpt-3.5-turbo",\n  temperature: 0\n}',anthropicParams:'{\n  model: "claude-3-sonnet-20240229",\n  temperature: 0\n}',fireworksParams:'{\n  model: "accounts/fireworks/models/firefunction-v1",\n  temperature: 0\n}',mistralParams:'{\n  model: "mistral-large-latest",\n  temperature: 0\n}',groqParams:'{\n  model: "mixtral-8x7b-32768",\n  temperature: 0\n}',vertexParams:'{\n  model: "gemini-1.5-pro",\n  temperature: 0\n}'},d=["openai","anthropic","mistral","groq","vertex"];function p(e){const{customVarName:n,additionalDependencies:a}=e,i=n??"model",r=e.openaiParams??h.openaiParams,p=e.anthropicParams??h.anthropicParams,u=e.fireworksParams??h.fireworksParams,m=e.mistralParams??h.mistralParams,g=e.groqParams??h.groqParams,x=e.vertexParams??h.vertexParams,w=e.providers??["openai","anthropic","fireworks","mistral","groq","vertex"],y={openai:{value:"openai",label:"OpenAI",default:!0,text:`import { ChatOpenAI } from "@langchain/openai";\n\nconst ${i} = new ChatOpenAI(${r});`,envs:"OPENAI_API_KEY=your-api-key",dependencies:"@langchain/openai"},anthropic:{value:"anthropic",label:"Anthropic",default:!1,text:`import { ChatAnthropic } from "@langchain/anthropic";\n\nconst ${i} = new ChatAnthropic(${p});`,envs:"ANTHROPIC_API_KEY=your-api-key",dependencies:"@langchain/anthropic"},fireworks:{value:"fireworks",label:"FireworksAI",default:!1,text:`import { ChatFireworks } from "@langchain/community/chat_models/fireworks";\n\nconst ${i} = new ChatFireworks(${u});`,envs:"FIREWORKS_API_KEY=your-api-key",dependencies:"@langchain/community"},mistral:{value:"mistral",label:"MistralAI",default:!1,text:`import { ChatMistralAI } from "@langchain/mistralai";\n\nconst ${i} = new ChatMistralAI(${m});`,envs:"MISTRAL_API_KEY=your-api-key",dependencies:"@langchain/mistralai"},groq:{value:"groq",label:"Groq",default:!1,text:`import { ChatGroq } from "@langchain/groq";\n\nconst ${i} = new ChatGroq(${g});`,envs:"GROQ_API_KEY=your-api-key",dependencies:"@langchain/groq"},vertex:{value:"vertex",label:"VertexAI",default:!1,text:`import { ChatVertexAI } from "@langchain/google-vertexai";\n\nconst ${i} = new ChatVertexAI(${x});`,envs:"GOOGLE_APPLICATION_CREDENTIALS=credentials.json",dependencies:"@langchain/google-vertexai"}},f=(e.onlyWso?d:w).map((e=>y[e]));return(0,l.jsxs)("div",{children:[(0,l.jsx)("h3",{children:"Pick your chat model:"}),(0,l.jsx)(t.A,{groupId:"modelTabs",children:f.map((e=>(0,l.jsxs)(s.A,{value:e.value,label:e.label,children:[(0,l.jsx)("h4",{children:"Install dependencies"}),(0,l.jsx)(c,{children:[e.dependencies,a].join(" ")}),(0,l.jsx)("h4",{children:"Add environment variables"}),(0,l.jsx)(o.A,{language:"bash",children:e.envs}),(0,l.jsx)("h4",{children:"Instantiate the model"}),(0,l.jsx)(o.A,{language:"typescript",children:e.text})]},e.value)))})]})}},27846:(e,n,a)=>{a.d(n,{A:()=>r});a(96540);var t=a(11470),s=a(19365),o=a(21432),i=a(74848);function r(e){let{children:n}=e;return(0,i.jsxs)(t.A,{groupId:"npm2yarn",children:[(0,i.jsx)(s.A,{value:"npm",label:"npm",children:(0,i.jsxs)(o.A,{language:"bash",children:["npm i ",n]})}),(0,i.jsx)(s.A,{value:"yarn",label:"yarn",default:!0,children:(0,i.jsxs)(o.A,{language:"bash",children:["yarn add ",n]})}),(0,i.jsx)(s.A,{value:"pnpm",label:"pnpm",children:(0,i.jsxs)(o.A,{language:"bash",children:["pnpm add ",n]})})]})}}}]);