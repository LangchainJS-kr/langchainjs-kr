(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9471,65],{32153:(n,e,t)=>{"use strict";t.r(e),t.d(e,{assets:()=>m,contentTitle:()=>d,default:()=>h,frontMatter:()=>c,metadata:()=>p,toc:()=>g});var a=t(74848),s=t(28453),o=t(78847),r=t(64428),i=t(9866),l=t.n(i);const c={},d="AWS SageMakerEndpoint",p={id:"integrations/llms/aws_sagemaker",title:"AWS SageMakerEndpoint",description:"LangChain.js supports integration with AWS SageMaker-hosted endpoints. Check Amazon SageMaker JumpStart for a list of available models, and how to deploy your own.",source:"@site/docs/integrations/llms/aws_sagemaker.mdx",sourceDirName:"integrations/llms",slug:"/integrations/llms/aws_sagemaker",permalink:"/docs/integrations/llms/aws_sagemaker",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/integrations/llms/aws_sagemaker.mdx",tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"AlephAlpha",permalink:"/docs/integrations/llms/aleph_alpha"},next:{title:"Azure OpenAI",permalink:"/docs/integrations/llms/azure"}},m={},g=[{value:"Setup",id:"setup",level:2},...o.toc,{value:"Usage",id:"usage",level:2}];function u(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,s.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.h1,{id:"aws-sagemakerendpoint",children:"AWS SageMakerEndpoint"}),"\n",(0,a.jsxs)(e.p,{children:["LangChain.js supports integration with AWS SageMaker-hosted endpoints. Check ",(0,a.jsx)(e.a,{href:"https://aws.amazon.com/sagemaker/jumpstart/",children:"Amazon SageMaker JumpStart"})," for a list of available models, and how to deploy your own."]}),"\n",(0,a.jsx)(e.h2,{id:"setup",children:"Setup"}),"\n",(0,a.jsx)(e.p,{children:"You'll need to install the official SageMaker SDK as a peer dependency:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @aws-sdk/client-sagemaker-runtime\n"})}),"\n","\n",(0,a.jsx)(o.default,{}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/community\n"})}),"\n",(0,a.jsx)(e.h2,{id:"usage",children:"Usage"}),"\n","\n",(0,a.jsx)(r.A,{language:"typescript",children:l()})]})}function h(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(u,{...n})}):u(n)}},78847:(n,e,t)=>{"use strict";t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var a=t(74848),s=t(28453);const o={},r=void 0,i={id:"mdx_components/integration_install_tooltip",title:"integration_install_tooltip",description:"See this section for general instructions on installing integration packages.",source:"@site/docs/mdx_components/integration_install_tooltip.mdx",sourceDirName:"mdx_components",slug:"/mdx_components/integration_install_tooltip",permalink:"/docs/mdx_components/integration_install_tooltip",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/mdx_components/integration_install_tooltip.mdx",tags:[],version:"current",frontMatter:{}},l={},c=[];function d(n){const e={a:"a",admonition:"admonition",p:"p",...(0,s.R)(),...n.components};return(0,a.jsx)(e.admonition,{type:"tip",children:(0,a.jsxs)(e.p,{children:["See ",(0,a.jsx)(e.a,{href:"/docs/how_to/installation#installing-integration-packages",children:"this section for general instructions on installing integration packages"}),"."]})})}function p(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},9866:n=>{n.exports={content:'import {\n  SageMakerEndpoint,\n  SageMakerLLMContentHandler,\n} from "@langchain/community/llms/sagemaker_endpoint";\n\ninterface ResponseJsonInterface {\n  generation: {\n    content: string;\n  };\n}\n\n// Custom for whatever model you\'ll be using\nclass LLama213BHandler implements SageMakerLLMContentHandler {\n  contentType = "application/json";\n\n  accepts = "application/json";\n\n  async transformInput(\n    prompt: string,\n    modelKwargs: Record<string, unknown>\n  ): Promise<Uint8Array> {\n    const payload = {\n      inputs: [[{ role: "user", content: prompt }]],\n      parameters: modelKwargs,\n    };\n\n    const stringifiedPayload = JSON.stringify(payload);\n\n    return new TextEncoder().encode(stringifiedPayload);\n  }\n\n  async transformOutput(output: Uint8Array): Promise<string> {\n    const response_json = JSON.parse(\n      new TextDecoder("utf-8").decode(output)\n    ) as ResponseJsonInterface[];\n    const content = response_json[0]?.generation.content ?? "";\n    return content;\n  }\n}\n\nconst contentHandler = new LLama213BHandler();\n\nconst model = new SageMakerEndpoint({\n  endpointName: "aws-llama-2-13b-chat",\n  modelKwargs: {\n    temperature: 0.5,\n    max_new_tokens: 700,\n    top_p: 0.9,\n  },\n  endpointKwargs: {\n    CustomAttributes: "accept_eula=true",\n  },\n  contentHandler,\n  clientOptions: {\n    region: "YOUR AWS ENDPOINT REGION",\n    credentials: {\n      accessKeyId: "YOUR AWS ACCESS ID",\n      secretAccessKey: "YOUR AWS SECRET ACCESS KEY",\n    },\n  },\n});\n\nconst res = await model.invoke(\n  "Hello, my name is John Doe, tell me a joke about llamas "\n);\n\nconsole.log(res);\n\n/*\n  [\n    {\n      content: "Hello, John Doe! Here\'s a llama joke for you:\n        Why did the llama become a gardener?\n        Because it was great at llama-scaping!"\n    }\n  ]\n */\n',imports:[{local:"SageMakerEndpoint",imported:"SageMakerEndpoint",source:"@langchain/community/llms/sagemaker_endpoint"},{local:"SageMakerLLMContentHandler",imported:"SageMakerLLMContentHandler",source:"@langchain/community/llms/sagemaker_endpoint"}]}}}]);