(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[9486],{86904:(e,n,t)=>{"use strict";t.r(n),t.d(n,{assets:()=>w,contentTitle:()=>f,default:()=>S,frontMatter:()=>v,metadata:()=>g,toc:()=>x});var r=t(74848),o=t(28453),i=t(64428),a=t(90132),s=t.n(a),c=t(48501),l=t.n(c),d=t(12760),h=t.n(d),m=t(58936),u=t.n(m),p=t(78847);const v={sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},f="How to retrieve the whole document for a chunk",g={id:"how_to/parent_document_retriever",title:"How to retrieve the whole document for a chunk",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/parent_document_retriever.mdx",sourceDirName:"how_to",slug:"/how_to/parent_document_retriever",permalink:"/docs/how_to/parent_document_retriever",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/parent_document_retriever.mdx",tags:[],version:"current",frontMatter:{sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},sidebar:"tutorialSidebar"},w={},x=[{value:"Usage",id:"usage",level:2},...p.toc,{value:"With Score Threshold",id:"with-score-threshold",level:2},{value:"With Contextual chunk headers",id:"with-contextual-chunk-headers",level:2},{value:"With Reranking",id:"with-reranking",level:2},{value:"Next steps",id:"next-steps",level:2}];function y(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"how-to-retrieve-the-whole-document-for-a-chunk",children:"How to retrieve the whole document for a chunk"}),"\n",(0,r.jsxs)(n.admonition,{title:"Prerequisites",type:"info",children:[(0,r.jsx)(n.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/concepts/#retrievers",children:"Retrievers"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/concepts/#text-splitters",children:"Text splitters"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/tutorials/rag",children:"Retrieval-augmented generation (RAG)"})}),"\n"]})]}),"\n",(0,r.jsx)(n.p,{children:"When splitting documents for retrieval, there are often conflicting desires:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"You may want to have small documents, so that their embeddings can most accurately reflect their meaning. If documents are too long, then the embeddings can lose meaning."}),"\n",(0,r.jsx)(n.li,{children:"You want to have long enough documents that the context of each chunk is retained."}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["The ",(0,r.jsx)(n.a,{href:"https://v02.api.js.langchain.com/classes/langchain_retrievers_parent_document.ParentDocumentRetriever.html",children:(0,r.jsx)(n.code,{children:"ParentDocumentRetriever"})})," strikes that balance by splitting and storing small chunks of data. During retrieval, it first fetches the small chunks but then looks up the parent ids for those chunks and returns those larger documents."]}),"\n",(0,r.jsx)(n.p,{children:'Note that "parent document" refers to the document that a small chunk originated from. This can either be the whole raw document OR a larger chunk.'}),"\n",(0,r.jsxs)(n.p,{children:["This is a more specific form of ",(0,r.jsx)(n.a,{href:"/docs/how_to/multi_vector",children:"generating multiple embeddings per document"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n","\n",(0,r.jsx)(p.default,{}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/openai\n"})}),"\n",(0,r.jsx)(i.A,{language:"typescript",children:s()}),"\n",(0,r.jsx)(n.h2,{id:"with-score-threshold",children:"With Score Threshold"}),"\n",(0,r.jsxs)(n.p,{children:["By setting the options in ",(0,r.jsx)(n.code,{children:"scoreThresholdOptions"})," we can force the ",(0,r.jsx)(n.code,{children:"ParentDocumentRetriever"})," to use the ",(0,r.jsx)(n.code,{children:"ScoreThresholdRetriever"})," under the hood.\nThis sets the vector store inside ",(0,r.jsx)(n.code,{children:"ScoreThresholdRetriever"})," as the one we passed when initializing ",(0,r.jsx)(n.code,{children:"ParentDocumentRetriever"}),", while also allowing us to also set a score threshold for the retriever."]}),"\n",(0,r.jsxs)(n.p,{children:["This can be helpful when you're not sure how many documents you want (or if you are sure, just set the ",(0,r.jsx)(n.code,{children:"maxK"})," option), but you want to make sure that the documents you do get are within a certain relevancy threshold."]}),"\n",(0,r.jsxs)(n.p,{children:["Note: if a retriever is passed, ",(0,r.jsx)(n.code,{children:"ParentDocumentRetriever"})," will default to use it for retrieving small chunks, as well as adding documents via the ",(0,r.jsx)(n.code,{children:"addDocuments"})," method."]}),"\n",(0,r.jsx)(i.A,{language:"typescript",children:l()}),"\n",(0,r.jsx)(n.h2,{id:"with-contextual-chunk-headers",children:"With Contextual chunk headers"}),"\n",(0,r.jsx)(n.p,{children:"Consider a scenario where you want to store collection of documents in a vector store and perform Q&A tasks on them. Simply splitting documents with overlapping text may not provide sufficient context for LLMs to determine if multiple chunks are referencing the same information, or how to resolve information from contradictory sources."}),"\n",(0,r.jsx)(n.p,{children:"Tagging each document with metadata is a solution if you know what to filter against, but you may not know ahead of time exactly what kind of queries your vector store will be expected to handle. Including additional contextual information directly in each chunk in the form of headers can help deal with arbitrary queries."}),"\n",(0,r.jsx)(n.p,{children:"This is particularly important if you have several fine-grained child chunks that need to be correctly retrieved from the vector store."}),"\n",(0,r.jsx)(i.A,{language:"typescript",children:h()}),"\n",(0,r.jsx)(n.h2,{id:"with-reranking",children:"With Reranking"}),"\n",(0,r.jsx)(n.p,{children:"With many documents from the vector store that are passed to LLM, final answers sometimes consist of information from\nirrelevant chunks, making it less precise and sometimes incorrect. Also, passing multiple irrelevant documents makes it\nmore expensive.\nSo there are two reasons to use rerank - precision and costs."}),"\n",(0,r.jsx)(i.A,{language:"typescript",children:u()}),"\n",(0,r.jsx)(n.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,r.jsxs)(n.p,{children:["You've now learned how to use the ",(0,r.jsx)(n.code,{children:"ParentDocumentRetriever"}),"."]}),"\n",(0,r.jsxs)(n.p,{children:["Next, check out the more general form of ",(0,r.jsx)(n.a,{href:"/docs/how_to/multi_vector",children:"generating multiple embeddings per document"}),", the ",(0,r.jsx)(n.a,{href:"/docs/tutorials/rag",children:"broader tutorial on RAG"}),", or this section to learn how to\n",(0,r.jsx)(n.a,{href:"/docs/how_to/custom_retriever/",children:"create your own custom retriever over any data source"}),"."]})]})}function S(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(y,{...e})}):y(e)}},90132:e=>{e.exports={content:"import { OpenAIEmbeddings } from \"@langchain/openai\";\nimport { MemoryVectorStore } from \"langchain/vectorstores/memory\";\nimport { InMemoryStore } from \"@langchain/core/stores\";\nimport { ParentDocumentRetriever } from \"langchain/retrievers/parent_document\";\nimport { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\nimport { TextLoader } from \"langchain/document_loaders/fs/text\";\n\nconst vectorstore = new MemoryVectorStore(new OpenAIEmbeddings());\nconst docstore = new InMemoryStore();\nconst retriever = new ParentDocumentRetriever({\n  vectorstore,\n  docstore,\n  // Optional, not required if you're already passing in split documents\n  parentSplitter: new RecursiveCharacterTextSplitter({\n    chunkOverlap: 0,\n    chunkSize: 500,\n  }),\n  childSplitter: new RecursiveCharacterTextSplitter({\n    chunkOverlap: 0,\n    chunkSize: 50,\n  }),\n  // Optional `k` parameter to search for more child documents in VectorStore.\n  // Note that this does not exactly correspond to the number of final (parent) documents\n  // retrieved, as multiple child documents can point to the same parent.\n  childK: 20,\n  // Optional `k` parameter to limit number of final, parent documents returned from this\n  // retriever and sent to LLM. This is an upper-bound, and the final count may be lower than this.\n  parentK: 5,\n});\nconst textLoader = new TextLoader(\"../examples/state_of_the_union.txt\");\nconst parentDocuments = await textLoader.load();\n\n// We must add the parent documents via the retriever's addDocuments method\nawait retriever.addDocuments(parentDocuments);\n\nconst retrievedDocs = await retriever.invoke(\"justice breyer\");\n\n// Retrieved chunks are the larger parent chunks\nconsole.log(retrievedDocs);\n/*\n  [\n    Document {\n      pageContent: 'Tonight, I call on the Senate to pass \u2014 pass the Freedom to Vote Act. Pass the John Lewis Act \u2014 Voting Rights Act. And while you\u2019re at it, pass the DISCLOSE Act so Americans know who is funding our elections.\\n' +\n        '\\n' +\n        'Look, tonight, I\u2019d \u2014 I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Breyer \u2014 an Army veteran, Constitutional scholar, retiring Justice of the United States Supreme Court.',\n      metadata: { source: '../examples/state_of_the_union.txt', loc: [Object] }\n    },\n    Document {\n      pageContent: 'As I did four days ago, I\u2019ve nominated a Circuit Court of Appeals \u2014 Ketanji Brown Jackson. One of our nation\u2019s top legal minds who will continue in just Brey- \u2014 Justice Breyer\u2019s legacy of excellence. A former top litigator in private practice, a former federal public defender from a family of public-school educators and police officers \u2014 she\u2019s a consensus builder.',\n      metadata: { source: '../examples/state_of_the_union.txt', loc: [Object] }\n    },\n    Document {\n      pageContent: 'Justice Breyer, thank you for your service. Thank you, thank you, thank you. I mean it. Get up. Stand \u2014 let me see you. Thank you.\\n' +\n        '\\n' +\n        'And we all know \u2014 no matter what your ideology, we all know one of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.',\n      metadata: { source: '../examples/state_of_the_union.txt', loc: [Object] }\n    }\n  ]\n*/\n",imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"MemoryVectorStore",imported:"MemoryVectorStore",source:"langchain/vectorstores/memory"},{local:"InMemoryStore",imported:"InMemoryStore",source:"@langchain/core/stores"},{local:"ParentDocumentRetriever",imported:"ParentDocumentRetriever",source:"langchain/retrievers/parent_document"},{local:"RecursiveCharacterTextSplitter",imported:"RecursiveCharacterTextSplitter",source:"@langchain/textsplitters"},{local:"TextLoader",imported:"TextLoader",source:"langchain/document_loaders/fs/text"}]}},12760:e=>{e.exports={content:'import { OpenAIEmbeddings } from "@langchain/openai";\nimport { HNSWLib } from "@langchain/community/vectorstores/hnswlib";\nimport { InMemoryStore } from "@langchain/core/stores";\nimport { ParentDocumentRetriever } from "langchain/retrievers/parent_document";\nimport { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";\n\nconst splitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 1500,\n  chunkOverlap: 0,\n});\n\nconst jimDocs = await splitter.createDocuments([`My favorite color is blue.`]);\nconst jimChunkHeaderOptions = {\n  chunkHeader: "DOC NAME: Jim Interview\\n---\\n",\n  appendChunkOverlapHeader: true,\n};\n\nconst pamDocs = await splitter.createDocuments([`My favorite color is red.`]);\nconst pamChunkHeaderOptions = {\n  chunkHeader: "DOC NAME: Pam Interview\\n---\\n",\n  appendChunkOverlapHeader: true,\n};\n\nconst vectorstore = await HNSWLib.fromDocuments([], new OpenAIEmbeddings());\nconst docstore = new InMemoryStore();\n\nconst retriever = new ParentDocumentRetriever({\n  vectorstore,\n  docstore,\n  // Very small chunks for demo purposes.\n  // Use a bigger chunk size for serious use-cases.\n  childSplitter: new RecursiveCharacterTextSplitter({\n    chunkSize: 10,\n    chunkOverlap: 0,\n  }),\n  childK: 50,\n  parentK: 5,\n});\n\n// We pass additional option `childDocChunkHeaderOptions`\n// that will add the chunk header to child documents\nawait retriever.addDocuments(jimDocs, {\n  childDocChunkHeaderOptions: jimChunkHeaderOptions,\n});\nawait retriever.addDocuments(pamDocs, {\n  childDocChunkHeaderOptions: pamChunkHeaderOptions,\n});\n\n// This will search child documents in vector store with the help of chunk header,\n// returning the unmodified parent documents\nconst retrievedDocs = await retriever.invoke("What is Pam\'s favorite color?");\n\n// Pam\'s favorite color is returned first!\nconsole.log(JSON.stringify(retrievedDocs, null, 2));\n/*\n  [\n    {\n      "pageContent": "My favorite color is red.",\n      "metadata": {\n        "loc": {\n          "lines": {\n            "from": 1,\n            "to": 1\n          }\n        }\n      }\n    },\n    {\n      "pageContent": "My favorite color is blue.",\n      "metadata": {\n        "loc": {\n          "lines": {\n            "from": 1,\n            "to": 1\n          }\n        }\n      }\n    }\n  ]\n*/\n\nconst rawDocs = await vectorstore.similaritySearch(\n  "What is Pam\'s favorite color?"\n);\n\n// Raw docs in vectorstore are short but have chunk headers\nconsole.log(JSON.stringify(rawDocs, null, 2));\n\n/*\n  [\n    {\n      "pageContent": "DOC NAME: Pam Interview\\n---\\n(cont\'d) color is",\n      "metadata": {\n        "loc": {\n          "lines": {\n            "from": 1,\n            "to": 1\n          }\n        },\n        "doc_id": "affdcbeb-6bfb-42e9-afe5-80f4f2e9f6aa"\n      }\n    },\n    {\n      "pageContent": "DOC NAME: Pam Interview\\n---\\n(cont\'d) favorite",\n      "metadata": {\n        "loc": {\n          "lines": {\n            "from": 1,\n            "to": 1\n          }\n        },\n        "doc_id": "affdcbeb-6bfb-42e9-afe5-80f4f2e9f6aa"\n      }\n    },\n    {\n      "pageContent": "DOC NAME: Pam Interview\\n---\\n(cont\'d) red.",\n      "metadata": {\n        "loc": {\n          "lines": {\n            "from": 1,\n            "to": 1\n          }\n        },\n        "doc_id": "affdcbeb-6bfb-42e9-afe5-80f4f2e9f6aa"\n      }\n    },\n    {\n      "pageContent": "DOC NAME: Pam Interview\\n---\\nMy",\n      "metadata": {\n        "loc": {\n          "lines": {\n            "from": 1,\n            "to": 1\n          }\n        },\n        "doc_id": "affdcbeb-6bfb-42e9-afe5-80f4f2e9f6aa"\n      }\n    }\n  ]\n*/\n',imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"HNSWLib",imported:"HNSWLib",source:"@langchain/community/vectorstores/hnswlib"},{local:"InMemoryStore",imported:"InMemoryStore",source:"@langchain/core/stores"},{local:"ParentDocumentRetriever",imported:"ParentDocumentRetriever",source:"langchain/retrievers/parent_document"},{local:"RecursiveCharacterTextSplitter",imported:"RecursiveCharacterTextSplitter",source:"@langchain/textsplitters"}]}},58936:e=>{e.exports={content:'import { OpenAIEmbeddings } from "@langchain/openai";\nimport { CohereRerank } from "@langchain/cohere";\nimport { HNSWLib } from "@langchain/community/vectorstores/hnswlib";\nimport { InMemoryStore } from "@langchain/core/stores";\nimport {\n  ParentDocumentRetriever,\n  type SubDocs,\n} from "langchain/retrievers/parent_document";\nimport { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";\n\n// init Cohere Rerank. Remember to add COHERE_API_KEY to your .env\nconst reranker = new CohereRerank({\n  topN: 50,\n  model: "rerank-multilingual-v2.0",\n});\n\nexport function documentCompressorFiltering({\n  relevanceScore,\n}: { relevanceScore?: number } = {}) {\n  return (docs: SubDocs) => {\n    let outputDocs = docs;\n\n    if (relevanceScore) {\n      const docsRelevanceScoreValues = docs.map(\n        (doc) => doc?.metadata?.relevanceScore\n      );\n      outputDocs = docs.filter(\n        (_doc, index) =>\n          (docsRelevanceScoreValues?.[index] || 1) >= relevanceScore\n      );\n    }\n\n    return outputDocs;\n  };\n}\n\nconst splitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 500,\n  chunkOverlap: 0,\n});\n\nconst jimDocs = await splitter.createDocuments([`Jim favorite color is blue.`]);\n\nconst pamDocs = await splitter.createDocuments([`Pam favorite color is red.`]);\n\nconst vectorstore = await HNSWLib.fromDocuments([], new OpenAIEmbeddings());\nconst docstore = new InMemoryStore();\n\nconst retriever = new ParentDocumentRetriever({\n  vectorstore,\n  docstore,\n  // Very small chunks for demo purposes.\n  // Use a bigger chunk size for serious use-cases.\n  childSplitter: new RecursiveCharacterTextSplitter({\n    chunkSize: 10,\n    chunkOverlap: 0,\n  }),\n  childK: 50,\n  parentK: 5,\n  // We add Reranker\n  documentCompressor: reranker,\n  documentCompressorFilteringFn: documentCompressorFiltering({\n    relevanceScore: 0.3,\n  }),\n});\n\nconst docs = jimDocs.concat(pamDocs);\nawait retriever.addDocuments(docs);\n\n// This will search for documents in vector store and return for LLM already reranked and sorted document\n// with appropriate minimum relevance score\nconst retrievedDocs = await retriever.getRelevantDocuments(\n  "What is Pam\'s favorite color?"\n);\n\n// Pam\'s favorite color is returned first!\nconsole.log(JSON.stringify(retrievedDocs, null, 2));\n/*\n  [\n    {\n      "pageContent": "My favorite color is red.",\n      "metadata": {\n        "relevanceScore": 0.9\n        "loc": {\n          "lines": {\n            "from": 1,\n            "to": 1\n          }\n        }\n      }\n    }\n  ]\n*/\n',imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"CohereRerank",imported:"CohereRerank",source:"@langchain/cohere"},{local:"HNSWLib",imported:"HNSWLib",source:"@langchain/community/vectorstores/hnswlib"},{local:"InMemoryStore",imported:"InMemoryStore",source:"@langchain/core/stores"},{local:"ParentDocumentRetriever",imported:"ParentDocumentRetriever",source:"langchain/retrievers/parent_document"},{local:"SubDocs",imported:"SubDocs",source:"langchain/retrievers/parent_document"},{local:"RecursiveCharacterTextSplitter",imported:"RecursiveCharacterTextSplitter",source:"@langchain/textsplitters"}]}},48501:e=>{e.exports={content:'import { OpenAIEmbeddings } from "@langchain/openai";\nimport { MemoryVectorStore } from "langchain/vectorstores/memory";\nimport { InMemoryStore } from "@langchain/core/stores";\nimport { ParentDocumentRetriever } from "langchain/retrievers/parent_document";\nimport { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";\nimport { TextLoader } from "langchain/document_loaders/fs/text";\nimport { ScoreThresholdRetriever } from "langchain/retrievers/score_threshold";\n\nconst vectorstore = new MemoryVectorStore(new OpenAIEmbeddings());\nconst docstore = new InMemoryStore();\nconst childDocumentRetriever = ScoreThresholdRetriever.fromVectorStore(\n  vectorstore,\n  {\n    minSimilarityScore: 0.01, // Essentially no threshold\n    maxK: 1, // Only return the top result\n  }\n);\nconst retriever = new ParentDocumentRetriever({\n  vectorstore,\n  docstore,\n  childDocumentRetriever,\n  // Optional, not required if you\'re already passing in split documents\n  parentSplitter: new RecursiveCharacterTextSplitter({\n    chunkOverlap: 0,\n    chunkSize: 500,\n  }),\n  childSplitter: new RecursiveCharacterTextSplitter({\n    chunkOverlap: 0,\n    chunkSize: 50,\n  }),\n});\nconst textLoader = new TextLoader("../examples/state_of_the_union.txt");\nconst parentDocuments = await textLoader.load();\n\n// We must add the parent documents via the retriever\'s addDocuments method\nawait retriever.addDocuments(parentDocuments);\n\nconst retrievedDocs = await retriever.invoke("justice breyer");\n\n// Retrieved chunk is the larger parent chunk\nconsole.log(retrievedDocs);\n/*\n  [\n    Document {\n      pageContent: \'Tonight, I call on the Senate to pass \u2014 pass the Freedom to Vote Act. Pass the John Lewis Act \u2014 Voting Rights Act. And while you\u2019re at it, pass the DISCLOSE Act so Americans know who is funding our elections.\\n\' +\n        \'\\n\' +\n        \'Look, tonight, I\u2019d \u2014 I\u2019d like to honor someone who has dedicated his life to serve this country: Justice Breyer \u2014 an Army veteran, Constitutional scholar, retiring Justice of the United States Supreme Court.\',\n      metadata: { source: \'../examples/state_of_the_union.txt\', loc: [Object] }\n    },\n  ]\n*/\n',imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"MemoryVectorStore",imported:"MemoryVectorStore",source:"langchain/vectorstores/memory"},{local:"InMemoryStore",imported:"InMemoryStore",source:"@langchain/core/stores"},{local:"ParentDocumentRetriever",imported:"ParentDocumentRetriever",source:"langchain/retrievers/parent_document"},{local:"RecursiveCharacterTextSplitter",imported:"RecursiveCharacterTextSplitter",source:"@langchain/textsplitters"},{local:"TextLoader",imported:"TextLoader",source:"langchain/document_loaders/fs/text"},{local:"ScoreThresholdRetriever",imported:"ScoreThresholdRetriever",source:"langchain/retrievers/score_threshold"}]}}}]);