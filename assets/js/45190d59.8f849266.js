"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3746],{28538:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var a=t(74848),i=t(28453);const o={sidebar_position:4,sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},s="\uc5d0\uc774\uc804\ud2b8 \ub9cc\ub4e4\uae30",r={id:"tutorials/agents",title:"\uc5d0\uc774\uc804\ud2b8 \ub9cc\ub4e4\uae30",description:"By themselves, language models can't take actions - they just output text.",source:"@site/docs/tutorials/agents.mdx",sourceDirName:"tutorials",slug:"/tutorials/agents",permalink:"/docs/tutorials/agents",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/tutorials/agents.mdx",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},sidebar:"tutorialSidebar"},c={},l=[{value:"Concepts",id:"concepts",level:2},{value:"Setup: LangSmith",id:"setup-langsmith",level:2},{value:"Define tools",id:"define-tools",level:2},{value:"Tavily",id:"tavily",level:3},{value:"Retriever",id:"retriever",level:3},{value:"Tools",id:"tools",level:3},{value:"Create the agent",id:"create-the-agent",level:2},{value:"Run the agent",id:"run-the-agent",level:2},{value:"Adding in memory",id:"adding-in-memory",level:2},{value:"Conclusion",id:"conclusion",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"\uc5d0\uc774\uc804\ud2b8-\ub9cc\ub4e4\uae30",children:"\uc5d0\uc774\uc804\ud2b8 \ub9cc\ub4e4\uae30"}),"\n",(0,a.jsxs)(n.p,{children:["By themselves, language models can't take actions - they just output text.\nA big use case for LangChain is creating ",(0,a.jsx)(n.strong,{children:"agents"}),".\nAgents are systems that use an LLM as a reasoning enginer to determine which actions to take and what the inputs to those actions should be.\nThe results of those actions can then be fed back into the agent and it determine whether more actions are needed, or whether it is okay to finish."]}),"\n",(0,a.jsx)(n.p,{children:"In this tutorial we will build an agent that can interact with multiple different tools: one being a local database, the other being a search engine. You will be able to ask this agent questions, watch it call tools, and have conversations with it."}),"\n",(0,a.jsx)(n.h2,{id:"concepts",children:"Concepts"}),"\n",(0,a.jsx)(n.p,{children:"Concepts we will cover are:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Using ",(0,a.jsx)(n.a,{href:"/docs/concepts/#chat-models",children:"language models"}),", in particular their tool calling ability"]}),"\n",(0,a.jsxs)(n.li,{children:["Creating a ",(0,a.jsx)(n.a,{href:"/docs/concepts/#retrievers",children:"Retriever"})," to expose specific information to our agent"]}),"\n",(0,a.jsxs)(n.li,{children:["Using a Search ",(0,a.jsx)(n.a,{href:"/docs/concepts/#tools",children:"Tool"})," to look up things online"]}),"\n",(0,a.jsxs)(n.li,{children:["Using ",(0,a.jsx)(n.a,{href:"/docs/concepts/#agents",children:"LangGraph Agents"})," which use an LLM to think about what to do and then execute upon that"]}),"\n",(0,a.jsxs)(n.li,{children:["Debugging and tracing your application using ",(0,a.jsx)(n.a,{href:"/docs/concepts/#langsmith",children:"LangSmith"})]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"setup-langsmith",children:"Setup: LangSmith"}),"\n",(0,a.jsxs)(n.p,{children:["By definition, agents take a self-determined, input-dependent sequence of steps before returning a user-facing output. This makes debugging these systems particularly tricky, and observability particularly important.\n",(0,a.jsx)(n.a,{href:"https://smith.langchain.com",children:"LangSmith"})," is especially useful for such cases."]}),"\n",(0,a.jsx)(n.p,{children:"When building with LangChain, all steps will automatically be traced in LangSmith. To set up LangSmith we just need set the following environment variables:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'export LANGCHAIN_TRACING_V2="true"\nexport LANGCHAIN_API_KEY="<your-api-key>"\n'})}),"\n",(0,a.jsx)(n.h2,{id:"define-tools",children:"Define tools"}),"\n",(0,a.jsxs)(n.p,{children:["We first need to create the tools we want to use. We will use two tools: ",(0,a.jsx)(n.a,{href:"https://app.tavily.com",children:"Tavily"})," (to search online) and then a retriever over a local index we will create."]}),"\n",(0,a.jsx)(n.h3,{id:"tavily",children:(0,a.jsx)(n.a,{href:"https://app.tavily.com",children:"Tavily"})}),"\n",(0,a.jsxs)(n.p,{children:["We have a built-in tool in LangChain to easily use Tavily search engine as tool.\nNote that this requires a Tavily API key set as an environment variable named ",(0,a.jsx)(n.code,{children:"TAVILY_API_KEY"})," - they have a free tier, but if you don\u2019t have one or don\u2019t want to create one, you can always ignore this step."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { TavilySearchResults } from "@langchain/community/tools/tavily_search";\n\nconst searchTool = new TavilySearchResults();\n\nconst toolResult = await searchTool.invoke("what is the weather in SF?");\n\nconsole.log(toolResult);\n\n/*\n  [{"title":"Weather in December 2023 in San Francisco, California, USA","url":"https://www.timeanddate.com/weather/@5391959/historic?month=12&year=2023","content":"Currently: 52 \xb0F. Broken clouds. (Weather station: San Francisco International Airport, USA). See more current weather Select month: December 2023 Weather in San Francisco \u2014 Graph \xb0F Sun, Dec 17 Lo:55 6 pm Hi:57 4 Mon, Dec 18 Lo:54 12 am Hi:55 7 Lo:54 6 am Hi:55 10 Lo:57 12 pm Hi:64 9 Lo:63 6 pm Hi:64 14 Tue, Dec 19 Lo:61","score":0.96006},...]\n*/\n'})}),"\n",(0,a.jsx)(n.h3,{id:"retriever",children:"Retriever"}),"\n",(0,a.jsxs)(n.p,{children:["We will also create a retriever over some data of our own. For a deeper explanation of each step here, see our ",(0,a.jsx)(n.a,{href:"/docs/how_to/",children:"how to guides"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";\nimport { CheerioWebBaseLoader } from "langchain/document_loaders/web/cheerio";\nimport { MemoryVectorStore } from "langchain/vectorstores/memory";\nimport { OpenAIEmbeddings } from "@langchain/openai";\n\nconst loader = new CheerioWebBaseLoader(\n  "https://docs.smith.langchain.com/user_guide"\n);\nconst rawDocs = await loader.load();\n\nconst splitter = new RecursiveCharacterTextSplitter({\n  chunkSize: 1000,\n  chunkOverlap: 200,\n});\nconst docs = await splitter.splitDocuments(rawDocs);\n\nconst vectorstore = await MemoryVectorStore.fromDocuments(\n  docs,\n  new OpenAIEmbeddings()\n);\nconst retriever = vectorstore.asRetriever();\n\nconst retrieverResult = await retriever.getRelevantDocuments(\n  "how to upload a dataset"\n);\nconsole.log(retrieverResult[0]);\n\n/*\n  Document {\n    pageContent: "your application progresses through the beta testing phase, it\'s essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you\u2019ll also want to do once your app hits production. However, especially at the production stage, it\u2019s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it\'s delivering desirable results at scale.Monitoring and A/B Testing\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to",\n    metadata: {\n      source: \'https://docs.smith.langchain.com/user_guide\',\n      loc: { lines: [Object] }\n    }\n  }\n*/\n'})}),"\n",(0,a.jsx)(n.p,{children:"Now that we have populated our index that we will do doing retrieval over, we can easily turn it into a tool (the format needed for an agent to properly use it):"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { createRetrieverTool } from "langchain/tools/retriever";\n\nconst retrieverTool = createRetrieverTool(retriever, {\n  name: "langsmith_search",\n  description:\n    "Search for information about LangSmith. For any questions about LangSmith, you must use this tool!",\n});\n'})}),"\n",(0,a.jsx)(n.h3,{id:"tools",children:"Tools"}),"\n",(0,a.jsx)(n.p,{children:"Now that we have created both, we can create a list of tools that we will use downstream:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"const tools = [searchTool, retrieverTool];\n"})}),"\n",(0,a.jsx)(n.h2,{id:"create-the-agent",children:"Create the agent"}),"\n",(0,a.jsxs)(n.p,{children:["Now that we have defined the tools, we can create the agent. We will be using an OpenAI Functions agent - for more information on this type of agent, as well as other options, see ",(0,a.jsx)(n.a,{href:"https://js.langchain.com/v0.1/docs/modules/agents/agent_types/",children:"this guide"}),"."]}),"\n",(0,a.jsx)(n.p,{children:"First, we choose the LLM we want to be guiding the agent."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { ChatOpenAI } from "@langchain/openai";\n\nconst llm = new ChatOpenAI({\n  model: "gpt-3.5-turbo",\n  temperature: 0,\n});\n'})}),"\n",(0,a.jsx)(n.p,{children:"Next, we choose the prompt we want to use to guide the agent:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import type { ChatPromptTemplate } from "@langchain/core/prompts";\nimport { pull } from "langchain/hub";\n\n// Get the prompt to use - you can modify this!\n// If you want to see the prompt in full, you can at:\n// https://smith.langchain.com/hub/hwchase17/openai-functions-agent\nconst prompt = await pull<ChatPromptTemplate>(\n  "hwchase17/openai-functions-agent"\n);\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Now, we can initalize the agent with the LLM, the prompt, and the tools. The agent is responsible for taking in input and deciding what actions to take.\nCrucially, the Agent does not execute those actions - that is done by the AgentExecutor (next step). For more information about how to thing about these components, see our ",(0,a.jsx)(n.a,{href:"/docs/concepts#agents",children:"conceptual guide"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { createOpenAIFunctionsAgent } from "langchain/agents";\n\nconst agent = await createOpenAIFunctionsAgent({\n  llm,\n  tools,\n  prompt,\n});\n'})}),"\n",(0,a.jsxs)(n.p,{children:["Finally, we combine the agent (the brains) with the tools inside the AgentExecutor (which will repeatedly call the agent and execute tools).\nFor more information about how to thing about these components, see our ",(0,a.jsx)(n.a,{href:"/docs/concepts#agents",children:"conceptual guide"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { AgentExecutor } from "langchain/agents";\n\nconst agentExecutor = new AgentExecutor({\n  agent,\n  tools,\n});\n'})}),"\n",(0,a.jsx)(n.h2,{id:"run-the-agent",children:"Run the agent"}),"\n",(0,a.jsx)(n.p,{children:"We can now run the agent on a few queries! Note that for now, these are all stateless queries (it won\u2019t remember previous interactions)."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const result1 = await agentExecutor.invoke({\n  input: "hi!",\n});\n\nconsole.log(result1);\n/*\n  [chain/start] [1:chain:AgentExecutor] Entering Chain run with input: {\n    "input": "hi!"\n  }\n  [chain/end] [1:chain:AgentExecutor] [1.36s] Exiting Chain run with output: {\n    "output": "Hello! How can I assist you today?"\n  }\n  {\n    input: \'hi!\',\n    output: \'Hello! How can I assist you today?\'\n  }\n*/\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const result2 = await agentExecutor.invoke({\n  input: "how can langsmith help with testing?",\n});\n\nconsole.log(result2);\n\n/*\n  [chain/start] [1:chain:AgentExecutor] Entering Chain run with input: {\n    "input": "how can langsmith help with testing?"\n  }\n  [chain/end] [1:chain:AgentExecutor > 2:chain:RunnableAgent > 7:parser:OpenAIFunctionsAgentOutputParser] [66ms] Exiting Chain run with output: {\n    "tool": "langsmith_search",\n    "toolInput": {\n      "query": "how can LangSmith help with testing?"\n    },\n    "log": "Invoking \\"langsmith_search\\" with {\\"query\\":\\"how can LangSmith help with testing?\\"}\\n",\n    "messageLog": [\n      {\n        "lc": 1,\n        "type": "constructor",\n        "id": [\n          "langchain_core",\n          "messages",\n          "AIMessage"\n        ],\n        "kwargs": {\n          "content": "",\n          "additional_kwargs": {\n            "function_call": {\n              "name": "langsmith_search",\n              "arguments": "{\\"query\\":\\"how can LangSmith help with testing?\\"}"\n            }\n          }\n        }\n      }\n    ]\n  }\n  [tool/start] [1:chain:AgentExecutor > 8:tool:langsmith_search] Entering Tool run with input: "{"query":"how can LangSmith help with testing?"}"\n  [retriever/start] [1:chain:AgentExecutor > 8:tool:langsmith_search > 9:retriever:VectorStoreRetriever] Entering Retriever run with input: {\n    "query": "how can LangSmith help with testing?"\n  }\n  [retriever/end] [1:chain:AgentExecutor > 8:tool:langsmith_search > 9:retriever:VectorStoreRetriever] [294ms] Exiting Retriever run with output: {\n    "documents": [\n      {\n        "pageContent": "You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We\u2019ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing \u2014 mirroring the",\n        "metadata": {\n          "source": "https://docs.smith.langchain.com/user_guide",\n          "loc": {\n            "lines": {\n              "from": 11,\n              "to": 11\n            }\n          }\n        }\n      },\n      {\n        "pageContent": "the time that we do\u2026 it\u2019s so helpful. We can use LangSmith to debug:An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebugging\u200bDebugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?\u200bLLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string \u2192 string (or chat messages \u2192 chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come directly from user input or from an auxiliary function (like retrieval). By the time these input variables go into the LLM they will have been converted to a string format, but often times they are not naturally represented as a string",\n        "metadata": {\n          "source": "https://docs.smith.langchain.com/user_guide",\n          "loc": {\n            "lines": {\n              "from": 3,\n              "to": 3\n            }\n          }\n        }\n      },\n      {\n        "pageContent": "inputs, and see what happens. At some point though, our application is performing\\nwell and we want to be more rigorous about testing changes. We can use a dataset\\nthat we\u2019ve constructed along the way (see above). Alternatively, we could spend some\\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies",\n        "metadata": {\n          "source": "https://docs.smith.langchain.com/user_guide",\n          "loc": {\n            "lines": {\n              "from": 4,\n              "to": 7\n            }\n          }\n        }\n      },\n      {\n        "pageContent": "feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing \u2014 mirroring the debug mode approach.We\u2019ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We\'re eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasets\u200bLangSmith makes it easy to curate datasets. However, these aren\u2019t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime",\n        "metadata": {\n          "source": "https://docs.smith.langchain.com/user_guide",\n          "loc": {\n            "lines": {\n              "from": 11,\n              "to": 11\n            }\n          }\n        }\n      }\n    ]\n  }\n  [chain/start] [1:chain:AgentExecutor > 10:chain:RunnableAgent] Entering Chain run with input: {\n    "input": "how can langsmith help with testing?",\n    "steps": [\n      {\n        "action": {\n          "tool": "langsmith_search",\n          "toolInput": {\n            "query": "how can LangSmith help with testing?"\n          },\n          "log": "Invoking \\"langsmith_search\\" with {\\"query\\":\\"how can LangSmith help with testing?\\"}\\n",\n          "messageLog": [\n            {\n              "lc": 1,\n              "type": "constructor",\n              "id": [\n                "langchain_core",\n                "messages",\n                "AIMessage"\n              ],\n              "kwargs": {\n                "content": "",\n                "additional_kwargs": {\n                  "function_call": {\n                    "name": "langsmith_search",\n                    "arguments": "{\\"query\\":\\"how can LangSmith help with testing?\\"}"\n                  }\n                }\n              }\n            }\n          ]\n        },\n        "observation": "You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be assigned string tags or key-value metadata, allowing you to attach correlation ids or AB test variants, and filter runs accordingly.We\u2019ve also made it possible to associate feedback programmatically with runs. This means that if your application has a thumbs up/down button on it, you can use that to log feedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing \u2014 mirroring the\\n\\nthe time that we do\u2026 it\u2019s so helpful. We can use LangSmith to debug:An unexpected end resultWhy an agent is loopingWhy a chain was slower than expectedHow many tokens an agent usedDebugging\u200bDebugging LLMs, chains, and agents can be tough. LangSmith helps solve the following pain points:What was the exact input to the LLM?\u200bLLM calls are often tricky and non-deterministic. The inputs/outputs may seem straightforward, given they are technically string \u2192 string (or chat messages \u2192 chat message), but this can be misleading as the input string is usually constructed from a combination of user input and auxiliary functions.Most inputs to an LLM call are a combination of some type of fixed template along with input variables. These input variables could come directly from user input or from an auxiliary function (like retrieval). By the time these input variables go into the LLM they will have been converted to a string format, but often times they are not naturally represented as a string\\n\\ninputs, and see what happens. At some point though, our application is performing\\nwell and we want to be more rigorous about testing changes. We can use a dataset\\nthat we\u2019ve constructed along the way (see above). Alternatively, we could spend some\\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies\\n\\nfeedback back to LangSmith. This can be used to track performance over time and pinpoint under performing data points, which you can subsequently add to a dataset for future testing \u2014 mirroring the debug mode approach.We\u2019ve provided several examples in the LangSmith documentation for extracting insights from logged runs. In addition to guiding you on performing this task yourself, we also provide examples of integrating with third parties for this purpose. We\'re eager to expand this area in the coming months! If you have ideas for either -- an open-source way to evaluate, or are building a company that wants to do analytics over these runs, please reach out.Exporting datasets\u200bLangSmith makes it easy to curate datasets. However, these aren\u2019t just useful inside LangSmith; they can be exported for use in other contexts. Notable applications include exporting for use in OpenAI Evals or fine-tuning, such as with FireworksAI.To set up tracing in Deno, web browsers, or other runtime"\n      }\n    ]\n  }\n  [chain/end] [1:chain:AgentExecutor] [5.83s] Exiting Chain run with output: {\n    "input": "how can langsmith help with testing?",\n    "output": "LangSmith can help with testing in several ways:\\n\\n1. Debugging: LangSmith can be used to debug unexpected end results, agent loops, slow chains, and token usage. It helps in pinpointing underperforming data points and tracking performance over time.\\n\\n2. Monitoring: LangSmith can monitor applications by logging all traces, visualizing latency and token usage statistics, and troubleshooting specific issues as they arise. It also allows for associating feedback programmatically with runs, which can be used to track performance over time.\\n\\n3. Exporting Datasets: LangSmith makes it easy to curate datasets, which can be exported for use in other contexts such as OpenAI Evals or fine-tuning with FireworksAI.\\n\\nOverall, LangSmith simplifies the process of testing changes, constructing datasets, and extracting insights from logged runs, making it a valuable tool for testing and evaluation."\n  }\n  {\n    input: \'how can langsmith help with testing?\',\n    output: \'LangSmith can help with testing in several ways:\\n\' +\n      \'\\n\' +\n      \'1. Initial Test Set: LangSmith allows developers to create datasets of inputs and reference outputs to run tests on their LLM applications. These test cases can be uploaded in bulk, created on the fly, or exported from application traces.\\n\' +\n      \'\\n\' +\n      "2. Comparison View: When making changes to your applications, LangSmith provides a comparison view to see whether you\'ve regressed with respect to your initial test cases. This is helpful for evaluating changes in prompts, retrieval strategies, or model choices.\\n" +\n      \'\\n\' +\n      \'3. Monitoring and A/B Testing: LangSmith provides monitoring charts to track key metrics over time and allows for A/B testing changes in prompt, model, or retrieval strategy.\\n\' +\n      \'\\n\' +\n      \'4. Debugging: LangSmith offers tracing and debugging information at each step of an LLM sequence, making it easier to identify and root-cause issues when things go wrong.\\n\' +\n      \'\\n\' +\n      \'5. Beta Testing and Production: LangSmith enables the addition of runs as examples to datasets, expanding test coverage on real-world scenarios. It also provides monitoring for application performance with respect to latency, cost, and feedback scores at the production stage.\\n\' +\n      \'\\n\' +\n      \'Overall, LangSmith provides comprehensive testing and monitoring capabilities for LLM applications.\'\n  }\n*/\n'})}),"\n",(0,a.jsx)(n.h2,{id:"adding-in-memory",children:"Adding in memory"}),"\n",(0,a.jsxs)(n.p,{children:["As mentioned earlier, this agent is stateless. This means it does not remember previous interactions.\nTo give it memory we need to pass in previous ",(0,a.jsx)(n.code,{children:"chat_history"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Note:"})," the input variable below needs to be called ",(0,a.jsx)(n.code,{children:"chat_history"})," because of the prompt we are using. If we use a different prompt, we could change the variable name."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const result3 = await agentExecutor.invoke({\n  input: "hi! my name is cob.",\n  chat_history: [],\n});\n\nconsole.log(result3);\n/*\n  {\n    input: \'hi! my name is cob.\',\n    chat_history: [],\n    output: "Hello Cob! It\'s nice to meet you. How can I assist you today?"\n  }\n*/\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { HumanMessage, AIMessage } from "@langchain/core/messages";\n\nconst result4 = await agentExecutor.invoke({\n  input: "what\'s my name?",\n  chat_history: [\n    new HumanMessage("hi! my name is cob."),\n    new AIMessage("Hello Cob! How can I assist you today?"),\n  ],\n});\n\nconsole.log(result4);\n/*\n  {\n    input: "what\'s my name?",\n    chat_history: [\n      HumanMessage {\n        content: \'hi! my name is cob.\',\n        additional_kwargs: {}\n      },\n      AIMessage {\n        content: \'Hello Cob! How can I assist you today?\',\n        additional_kwargs: {}\n      }\n    ],\n    output: \'Your name is Cob. How can I assist you today, Cob?\'\n  }\n*/\n'})}),"\n",(0,a.jsxs)(n.p,{children:["If we want to keep track of these messages automatically, we can wrap this in a RunnableWithMessageHistory. For more information on how to use this, see ",(0,a.jsx)(n.a,{href:"/docs/how_to/message_history/",children:"this guide"}),"."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { ChatMessageHistory } from "langchain/stores/message/in_memory";\nimport { RunnableWithMessageHistory } from "@langchain/core/runnables";\n\nconst messageHistory = new ChatMessageHistory();\n\nconst agentWithChatHistory = new RunnableWithMessageHistory({\n  runnable: agentExecutor,\n  // This is needed because in most real world scenarios, a session id is needed per user.\n  // It isn\'t really used here because we are using a simple in memory ChatMessageHistory.\n  getMessageHistory: (_sessionId) => messageHistory,\n  inputMessagesKey: "input",\n  historyMessagesKey: "chat_history",\n});\n\nconst result5 = await agentWithChatHistory.invoke(\n  {\n    input: "hi! i\'m cob",\n  },\n  {\n    // This is needed because in most real world scenarios, a session id is needed per user.\n    // It isn\'t really used here because we are using a simple in memory ChatMessageHistory.\n    configurable: {\n      sessionId: "foo",\n    },\n  }\n);\n\nconsole.log(result5);\n/*\n  {\n    input: "hi! i\'m cob",\n    chat_history: [\n      HumanMessage {\n        content: "hi! i\'m cob",\n        additional_kwargs: {}\n      },\n      AIMessage {\n        content: \'Hello Cob! How can I assist you today?\',\n        additional_kwargs: {}\n      }\n    ],\n    output: \'Hello Cob! How can I assist you today?\'\n  }\n*/\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"const result6 = await agentWithChatHistory.invoke(\n  {\n    input: \"what's my name?\",\n  },\n  {\n    // This is needed because in most real world scenarios, a session id is needed per user.\n    // It isn't really used here because we are using a simple in memory ChatMessageHistory.\n    configurable: {\n      sessionId: \"foo\",\n    },\n  }\n);\n\nconsole.log(result6);\n/*\n  {\n    input: \"what's my name?\",\n    chat_history: [\n      HumanMessage {\n        content: \"hi! i'm cob\",\n        additional_kwargs: {}\n      },\n      AIMessage {\n        content: 'Hello Cob! How can I assist you today?',\n        additional_kwargs: {}\n      },\n      HumanMessage {\n        content: \"what's my name?\",\n        additional_kwargs: {}\n      },\n      AIMessage {\n        content: 'Your name is Cob. How can I assist you today, Cob?',\n        additional_kwargs: {}\n      }\n    ],\n    output: 'Your name is Cob. How can I assist you today, Cob?'\n  }\n*/\n"})}),"\n",(0,a.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsxs)(n.p,{children:["That\u2019s a wrap! In this quick start we covered how to create a simple agent. Agents are a complex topic, and there\u2019s lot to learn!\nHead back to the ",(0,a.jsx)(n.a,{href:"/docs/how_to/agent_executor/",children:"main agent page"})," to find more resources on conceptual guides, different types of agents, how to create custom tools, and more!"]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}}}]);