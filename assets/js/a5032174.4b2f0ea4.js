(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[980],{82981:(n,e,o)=>{"use strict";o.r(e),o.d(e,{assets:()=>w,contentTitle:()=>b,default:()=>v,frontMatter:()=>g,metadata:()=>f,toc:()=>x});var t=o(74848),i=o(28453),a=o(78847),c=o(64428),r=o(58851),s=o.n(r),d=o(94275),p=o.n(d),l=o(71470),m=o.n(l),h=o(67617),u=o.n(h);const g={},b="Pinecone",f={id:"integrations/vectorstores/pinecone",title:"Pinecone",description:"You can use Pinecone vectorstores with LangChain.",source:"@site/docs/integrations/vectorstores/pinecone.mdx",sourceDirName:"integrations/vectorstores",slug:"/integrations/vectorstores/pinecone",permalink:"/docs/integrations/vectorstores/pinecone",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/integrations/vectorstores/pinecone.mdx",tags:[],version:"current",frontMatter:{},sidebar:"integrations",previous:{title:"PGVector",permalink:"/docs/integrations/vectorstores/pgvector"},next:{title:"Prisma",permalink:"/docs/integrations/vectorstores/prisma"}},w={},x=[...a.toc,{value:"Index docs",id:"index-docs",level:2},{value:"Query docs",id:"query-docs",level:2},{value:"Delete docs",id:"delete-docs",level:2},{value:"Maximal marginal relevance search",id:"maximal-marginal-relevance-search",level:2}];function I(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,i.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.h1,{id:"pinecone",children:"Pinecone"}),"\n",(0,t.jsxs)(e.p,{children:["You can use ",(0,t.jsx)(e.a,{href:"https://www.pinecone.io/",children:"Pinecone"})," vectorstores with LangChain.\nTo get started, install the integration package and the official Pinecone SDK with:"]}),"\n","\n",(0,t.jsx)(a.default,{}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install -S @langchain/pinecone @pinecone-database/pinecone\n"})}),"\n",(0,t.jsx)(e.p,{children:"The below examples use OpenAI embeddings, but you can swap in whichever provider you'd like.\nKeep in mind different embeddings models may have a different number of dimensions:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install -S @langchain/openai\n"})}),"\n",(0,t.jsx)(e.h2,{id:"index-docs",children:"Index docs"}),"\n","\n",(0,t.jsx)(c.A,{language:"typescript",children:s()}),"\n",(0,t.jsx)(e.h2,{id:"query-docs",children:"Query docs"}),"\n","\n",(0,t.jsx)(c.A,{language:"typescript",children:p()}),"\n",(0,t.jsx)(e.h2,{id:"delete-docs",children:"Delete docs"}),"\n","\n",(0,t.jsx)(c.A,{language:"typescript",children:m()}),"\n",(0,t.jsx)(e.h2,{id:"maximal-marginal-relevance-search",children:"Maximal marginal relevance search"}),"\n",(0,t.jsx)(e.p,{children:"Pinecone supports maximal marginal relevance search, which takes a combination of documents\nthat are most similar to the inputs, then reranks and optimizes for diversity."}),"\n","\n",(0,t.jsx)(c.A,{language:"typescript",children:u()})]})}function v(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(I,{...n})}):I(n)}},71470:n=>{n.exports={content:'/* eslint-disable @typescript-eslint/no-non-null-assertion */\nimport { Pinecone } from "@pinecone-database/pinecone";\nimport { Document } from "@langchain/core/documents";\nimport { OpenAIEmbeddings } from "@langchain/openai";\nimport { PineconeStore } from "@langchain/pinecone";\n\n// Instantiate a new Pinecone client, which will automatically read the\n// env vars: PINECONE_API_KEY and PINECONE_ENVIRONMENT which come from\n// the Pinecone dashboard at https://app.pinecone.io\n\nconst pinecone = new Pinecone();\n\nconst pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX!);\nconst embeddings = new OpenAIEmbeddings();\nconst pineconeStore = new PineconeStore(embeddings, { pineconeIndex });\n\nconst docs = [\n  new Document({\n    metadata: { foo: "bar" },\n    pageContent: "pinecone is a vector db",\n  }),\n  new Document({\n    metadata: { foo: "bar" },\n    pageContent: "the quick brown fox jumped over the lazy dog",\n  }),\n  new Document({\n    metadata: { baz: "qux" },\n    pageContent: "lorem ipsum dolor sit amet",\n  }),\n  new Document({\n    metadata: { baz: "qux" },\n    pageContent: "pinecones are the woody fruiting body and of a pine tree",\n  }),\n];\n\nconst pageContent = "some arbitrary content";\n\n// Also takes an additional {ids: []} parameter for upsertion\nconst ids = await pineconeStore.addDocuments(docs);\n\nconst results = await pineconeStore.similaritySearch(pageContent, 2, {\n  foo: "bar",\n});\n\nconsole.log(results);\n/*\n[\n  Document {\n    pageContent: \'pinecone is a vector db\',\n    metadata: { foo: \'bar\' },\n  },\n  Document {\n    pageContent: "the quick brown fox jumped over the lazy dog",\n    metadata: { foo: "bar" },\n  }\n]\n*/\n\nawait pineconeStore.delete({\n  ids: [ids[0], ids[1]],\n});\n\nconst results2 = await pineconeStore.similaritySearch(pageContent, 2, {\n  foo: "bar",\n});\n\nconsole.log(results2);\n/*\n  []\n*/\n',imports:[{local:"Document",imported:"Document",source:"@langchain/core/documents"},{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"PineconeStore",imported:"PineconeStore",source:"@langchain/pinecone"}]}},58851:n=>{n.exports={content:'/* eslint-disable @typescript-eslint/no-non-null-assertion */\nimport { Pinecone } from "@pinecone-database/pinecone";\nimport { Document } from "@langchain/core/documents";\nimport { OpenAIEmbeddings } from "@langchain/openai";\nimport { PineconeStore } from "@langchain/pinecone";\n\n// Instantiate a new Pinecone client, which will automatically read the\n// env vars: PINECONE_API_KEY and PINECONE_ENVIRONMENT which come from\n// the Pinecone dashboard at https://app.pinecone.io\n\nconst pinecone = new Pinecone();\n\nconst pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX!);\n\nconst docs = [\n  new Document({\n    metadata: { foo: "bar" },\n    pageContent: "pinecone is a vector db",\n  }),\n  new Document({\n    metadata: { foo: "bar" },\n    pageContent: "the quick brown fox jumped over the lazy dog",\n  }),\n  new Document({\n    metadata: { baz: "qux" },\n    pageContent: "lorem ipsum dolor sit amet",\n  }),\n  new Document({\n    metadata: { baz: "qux" },\n    pageContent: "pinecones are the woody fruiting body and of a pine tree",\n  }),\n];\n\nawait PineconeStore.fromDocuments(docs, new OpenAIEmbeddings(), {\n  pineconeIndex,\n  maxConcurrency: 5, // Maximum number of batch requests to allow at once. Each batch is 1000 vectors.\n});\n',imports:[{local:"Document",imported:"Document",source:"@langchain/core/documents"},{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"PineconeStore",imported:"PineconeStore",source:"@langchain/pinecone"}]}},67617:n=>{n.exports={content:'/* eslint-disable @typescript-eslint/no-non-null-assertion */\nimport { Pinecone } from "@pinecone-database/pinecone";\nimport { OpenAIEmbeddings } from "@langchain/openai";\nimport { PineconeStore } from "@langchain/pinecone";\n\n// Instantiate a new Pinecone client, which will automatically read the\n// env vars: PINECONE_API_KEY and PINECONE_ENVIRONMENT which come from\n// the Pinecone dashboard at https://app.pinecone.io\n\nconst pinecone = new Pinecone();\n\nconst pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX!);\n\nconst vectorStore = await PineconeStore.fromExistingIndex(\n  new OpenAIEmbeddings(),\n  { pineconeIndex }\n);\n\n/* Search the vector DB independently with meta filters */\nconst results = await vectorStore.maxMarginalRelevanceSearch("pinecone", {\n  k: 5,\n  fetchK: 20, // Default value for the number of initial documents to fetch for reranking.\n  // You can pass a filter as well\n  // filter: {},\n});\nconsole.log(results);\n',imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"PineconeStore",imported:"PineconeStore",source:"@langchain/pinecone"}]}},94275:n=>{n.exports={content:'/* eslint-disable @typescript-eslint/no-non-null-assertion */\nimport { Pinecone } from "@pinecone-database/pinecone";\nimport { OpenAIEmbeddings } from "@langchain/openai";\nimport { PineconeStore } from "@langchain/pinecone";\n\n// Instantiate a new Pinecone client, which will automatically read the\n// env vars: PINECONE_API_KEY and PINECONE_ENVIRONMENT which come from\n// the Pinecone dashboard at https://app.pinecone.io\n\nconst pinecone = new Pinecone();\n\nconst pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX!);\n\nconst vectorStore = await PineconeStore.fromExistingIndex(\n  new OpenAIEmbeddings(),\n  { pineconeIndex }\n);\n\n/* Search the vector DB independently with metadata filters */\nconst results = await vectorStore.similaritySearch("pinecone", 1, {\n  foo: "bar",\n});\nconsole.log(results);\n/*\n  [\n    Document {\n      pageContent: \'pinecone is a vector db\',\n      metadata: { foo: \'bar\' }\n    }\n  ]\n*/\n',imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"PineconeStore",imported:"PineconeStore",source:"@langchain/pinecone"}]}}}]);