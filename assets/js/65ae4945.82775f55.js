(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1558],{74998:(e,n,t)=>{"use strict";t.r(n),t.d(n,{assets:()=>g,contentTitle:()=>y,default:()=>b,frontMatter:()=>x,metadata:()=>f,toc:()=>S});var o=t(74848),a=t(28453),r=t(64428),i=t(45272),l=t.n(i),s=t(78847),p=t(119),m=t.n(p),c=t(73255),u=t.n(c),d=t(11825),h=t.n(d);const x={sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},y="How to select examples by similarity",f={id:"how_to/example_selectors_similarity",title:"How to select examples by similarity",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/example_selectors_similarity.mdx",sourceDirName:"how_to",slug:"/how_to/example_selectors_similarity",permalink:"/docs/how_to/example_selectors_similarity",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/example_selectors_similarity.mdx",tags:[],version:"current",frontMatter:{sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},sidebar:"tutorialSidebar"},g={},S=[...s.toc,{value:"Loading from an existing vectorstore",id:"loading-from-an-existing-vectorstore",level:2},{value:"Metadata filtering",id:"metadata-filtering",level:2},{value:"Custom vectorstore retrievers",id:"custom-vectorstore-retrievers",level:2},{value:"Next steps",id:"next-steps",level:2}];function w(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"how-to-select-examples-by-similarity",children:"How to select examples by similarity"}),"\n",(0,o.jsxs)(n.admonition,{title:"Prerequisites",type:"info",children:[(0,o.jsx)(n.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/docs/concepts/#prompt-templates",children:"Prompt templates"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/docs/how_to/example_selectors",children:"Example selectors"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"/docs/concepts#vectorstores",children:"Vector stores"})}),"\n"]})]}),"\n",(0,o.jsx)(n.p,{children:"This object selects examples based on similarity to the inputs.\nIt does this by finding the examples with the embeddings that have the greatest cosine similarity with the inputs."}),"\n","\n",(0,o.jsxs)(n.p,{children:["The fields of the examples object will be used as parameters to format the ",(0,o.jsx)(n.code,{children:"examplePrompt"})," passed to the ",(0,o.jsx)(n.code,{children:"FewShotPromptTemplate"}),".\nEach example should therefore contain all required fields for the example prompt you are using."]}),"\n","\n",(0,o.jsx)(s.default,{}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/openai @langchain/community\n"})}),"\n",(0,o.jsx)(r.A,{language:"typescript",children:l()}),"\n",(0,o.jsx)(n.p,{children:"By default, each field in the examples object is concatenated together, embedded, and stored in the vectorstore for\nlater similarity search against user queries."}),"\n",(0,o.jsxs)(n.p,{children:["If you only want to embed specific keys\n(e.g., you only want to search for examples that have a similar query to the one the user provides), you can pass an ",(0,o.jsx)(n.code,{children:"inputKeys"}),"\narray in the final ",(0,o.jsx)(n.code,{children:"options"})," parameter."]}),"\n",(0,o.jsx)(n.h2,{id:"loading-from-an-existing-vectorstore",children:"Loading from an existing vectorstore"}),"\n",(0,o.jsxs)(n.p,{children:["You can also use a pre-initialized vector store by passing an instance to the ",(0,o.jsx)(n.code,{children:"SemanticSimilarityExampleSelector"})," constructor\ndirectly, as shown below. You can also add more examples via the ",(0,o.jsx)(n.code,{children:"addExample"})," method:"]}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:m()}),"\n",(0,o.jsx)(n.h2,{id:"metadata-filtering",children:"Metadata filtering"}),"\n",(0,o.jsxs)(n.p,{children:["When adding examples, each field is available as metadata in the produced document. If you would like further control over your\nsearch space, you can add extra fields to your examples and pass a ",(0,o.jsx)(n.code,{children:"filter"})," parameter when initializing your selector:"]}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:u()}),"\n",(0,o.jsx)(n.h2,{id:"custom-vectorstore-retrievers",children:"Custom vectorstore retrievers"}),"\n",(0,o.jsx)(n.p,{children:"You can also pass a vectorstore retriever instead of a vectorstore. One way this could be useful is if you want to use retrieval\nbesides similarity search such as maximal marginal relevance:"}),"\n","\n",(0,o.jsx)(r.A,{language:"typescript",children:h()}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,o.jsx)(n.p,{children:"You've now learned a bit about using similarity in an example selector."}),"\n",(0,o.jsxs)(n.p,{children:["Next, check out this guide on how to use a ",(0,o.jsx)(n.a,{href:"/docs/how_to/example_selectors_length_based",children:"length-based example selector"}),"."]})]})}function b(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(w,{...e})}):w(e)}},45272:e=>{e.exports={content:'import { OpenAIEmbeddings } from "@langchain/openai";\nimport { HNSWLib } from "@langchain/community/vectorstores/hnswlib";\nimport { PromptTemplate, FewShotPromptTemplate } from "@langchain/core/prompts";\nimport { SemanticSimilarityExampleSelector } from "@langchain/core/example_selectors";\n\n// Create a prompt template that will be used to format the examples.\nconst examplePrompt = PromptTemplate.fromTemplate(\n  "Input: {input}\\nOutput: {output}"\n);\n\n// Create a SemanticSimilarityExampleSelector that will be used to select the examples.\nconst exampleSelector = await SemanticSimilarityExampleSelector.fromExamples(\n  [\n    { input: "happy", output: "sad" },\n    { input: "tall", output: "short" },\n    { input: "energetic", output: "lethargic" },\n    { input: "sunny", output: "gloomy" },\n    { input: "windy", output: "calm" },\n  ],\n  new OpenAIEmbeddings(),\n  HNSWLib,\n  { k: 1 }\n);\n\n// Create a FewShotPromptTemplate that will use the example selector.\nconst dynamicPrompt = new FewShotPromptTemplate({\n  // We provide an ExampleSelector instead of examples.\n  exampleSelector,\n  examplePrompt,\n  prefix: "Give the antonym of every input",\n  suffix: "Input: {adjective}\\nOutput:",\n  inputVariables: ["adjective"],\n});\n\n// Input is about the weather, so should select eg. the sunny/gloomy example\nconsole.log(await dynamicPrompt.format({ adjective: "rainy" }));\n/*\n  Give the antonym of every input\n\n  Input: sunny\n  Output: gloomy\n\n  Input: rainy\n  Output:\n*/\n\n// Input is a measurement, so should select the tall/short example\nconsole.log(await dynamicPrompt.format({ adjective: "large" }));\n/*\n  Give the antonym of every input\n\n  Input: tall\n  Output: short\n\n  Input: large\n  Output:\n*/\n',imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"HNSWLib",imported:"HNSWLib",source:"@langchain/community/vectorstores/hnswlib"},{local:"PromptTemplate",imported:"PromptTemplate",source:"@langchain/core/prompts"},{local:"FewShotPromptTemplate",imported:"FewShotPromptTemplate",source:"@langchain/core/prompts"},{local:"SemanticSimilarityExampleSelector",imported:"SemanticSimilarityExampleSelector",source:"@langchain/core/example_selectors"}]}},11825:e=>{e.exports={content:'/* eslint-disable @typescript-eslint/no-non-null-assertion */\n\n// Requires a vectorstore that supports maximal marginal relevance search\nimport { Pinecone } from "@pinecone-database/pinecone";\nimport { OpenAIEmbeddings, ChatOpenAI } from "@langchain/openai";\nimport { PineconeStore } from "@langchain/pinecone";\nimport { PromptTemplate, FewShotPromptTemplate } from "@langchain/core/prompts";\nimport { SemanticSimilarityExampleSelector } from "@langchain/core/example_selectors";\n\nconst pinecone = new Pinecone();\n\nconst pineconeIndex = pinecone.Index(process.env.PINECONE_INDEX!);\n\nconst pineconeVectorstore = await PineconeStore.fromExistingIndex(\n  new OpenAIEmbeddings(),\n  { pineconeIndex }\n);\n\nconst pineconeMmrRetriever = pineconeVectorstore.asRetriever({\n  searchType: "mmr",\n  k: 2,\n});\n\nconst examples = [\n  {\n    query: "healthy food",\n    output: `lettuce`,\n    food_type: "vegetable",\n  },\n  {\n    query: "healthy food",\n    output: `schnitzel`,\n    food_type: "veal",\n  },\n  {\n    query: "foo",\n    output: `bar`,\n    food_type: "baz",\n  },\n];\n\nconst exampleSelector = new SemanticSimilarityExampleSelector({\n  vectorStoreRetriever: pineconeMmrRetriever,\n  // Only embed the "query" key of each example\n  inputKeys: ["query"],\n});\n\nfor (const example of examples) {\n  // Format and add an example to the underlying vector store\n  await exampleSelector.addExample(example);\n}\n\n// Create a prompt template that will be used to format the examples.\nconst examplePrompt = PromptTemplate.fromTemplate(`<example>\n  <user_input>\n    {query}\n  </user_input>\n  <output>\n    {output}\n  </output>\n</example>`);\n\n// Create a FewShotPromptTemplate that will use the example selector.\nconst dynamicPrompt = new FewShotPromptTemplate({\n  // We provide an ExampleSelector instead of examples.\n  exampleSelector,\n  examplePrompt,\n  prefix: `Answer the user\'s question, using the below examples as reference:`,\n  suffix: "User question:\\n{query}",\n  inputVariables: ["query"],\n});\n\nconst model = new ChatOpenAI({});\n\nconst chain = dynamicPrompt.pipe(model);\n\nconst result = await chain.invoke({\n  query: "What is exactly one type of healthy food?",\n});\n\nconsole.log(result);\n\n/*\n  AIMessage {\n    content: \'lettuce.\',\n    additional_kwargs: { function_call: undefined }\n  }\n*/\n',imports:[{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"ChatOpenAI",imported:"ChatOpenAI",source:"@langchain/openai"},{local:"PineconeStore",imported:"PineconeStore",source:"@langchain/pinecone"},{local:"PromptTemplate",imported:"PromptTemplate",source:"@langchain/core/prompts"},{local:"FewShotPromptTemplate",imported:"FewShotPromptTemplate",source:"@langchain/core/prompts"},{local:"SemanticSimilarityExampleSelector",imported:"SemanticSimilarityExampleSelector",source:"@langchain/core/example_selectors"}]}},119:e=>{e.exports={content:'// Ephemeral, in-memory vector store for demo purposes\nimport { MemoryVectorStore } from "langchain/vectorstores/memory";\nimport { OpenAIEmbeddings, ChatOpenAI } from "@langchain/openai";\nimport { PromptTemplate, FewShotPromptTemplate } from "@langchain/core/prompts";\nimport { SemanticSimilarityExampleSelector } from "@langchain/core/example_selectors";\n\nconst embeddings = new OpenAIEmbeddings();\n\nconst memoryVectorStore = new MemoryVectorStore(embeddings);\n\nconst examples = [\n  {\n    query: "healthy food",\n    output: `galbi`,\n  },\n  {\n    query: "healthy food",\n    output: `schnitzel`,\n  },\n  {\n    query: "foo",\n    output: `bar`,\n  },\n];\n\nconst exampleSelector = new SemanticSimilarityExampleSelector({\n  vectorStore: memoryVectorStore,\n  k: 2,\n  // Only embed the "query" key of each example\n  inputKeys: ["query"],\n});\n\nfor (const example of examples) {\n  // Format and add an example to the underlying vector store\n  await exampleSelector.addExample(example);\n}\n\n// Create a prompt template that will be used to format the examples.\nconst examplePrompt = PromptTemplate.fromTemplate(`<example>\n  <user_input>\n    {query}\n  </user_input>\n  <output>\n    {output}\n  </output>\n</example>`);\n\n// Create a FewShotPromptTemplate that will use the example selector.\nconst dynamicPrompt = new FewShotPromptTemplate({\n  // We provide an ExampleSelector instead of examples.\n  exampleSelector,\n  examplePrompt,\n  prefix: `Answer the user\'s question, using the below examples as reference:`,\n  suffix: "User question: {query}",\n  inputVariables: ["query"],\n});\n\nconst formattedValue = await dynamicPrompt.format({\n  query: "What is a healthy food?",\n});\nconsole.log(formattedValue);\n\n/*\nAnswer the user\'s question, using the below examples as reference:\n\n<example>\n  <user_input>\n    healthy\n  </user_input>\n  <output>\n    galbi\n  </output>\n</example>\n\n<example>\n  <user_input>\n    healthy\n  </user_input>\n  <output>\n    schnitzel\n  </output>\n</example>\n\nUser question: What is a healthy food?\n*/\n\nconst model = new ChatOpenAI({});\n\nconst chain = dynamicPrompt.pipe(model);\n\nconst result = await chain.invoke({ query: "What is a healthy food?" });\nconsole.log(result);\n/*\n  AIMessage {\n    content: \'A healthy food can be galbi or schnitzel.\',\n    additional_kwargs: { function_call: undefined }\n  }\n*/\n',imports:[{local:"MemoryVectorStore",imported:"MemoryVectorStore",source:"langchain/vectorstores/memory"},{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"ChatOpenAI",imported:"ChatOpenAI",source:"@langchain/openai"},{local:"PromptTemplate",imported:"PromptTemplate",source:"@langchain/core/prompts"},{local:"FewShotPromptTemplate",imported:"FewShotPromptTemplate",source:"@langchain/core/prompts"},{local:"SemanticSimilarityExampleSelector",imported:"SemanticSimilarityExampleSelector",source:"@langchain/core/example_selectors"}]}},73255:e=>{e.exports={content:'// Ephemeral, in-memory vector store for demo purposes\nimport { MemoryVectorStore } from "langchain/vectorstores/memory";\nimport { OpenAIEmbeddings, ChatOpenAI } from "@langchain/openai";\nimport { PromptTemplate, FewShotPromptTemplate } from "@langchain/core/prompts";\nimport { Document } from "@langchain/core/documents";\nimport { SemanticSimilarityExampleSelector } from "@langchain/core/example_selectors";\n\nconst embeddings = new OpenAIEmbeddings();\n\nconst memoryVectorStore = new MemoryVectorStore(embeddings);\n\nconst examples = [\n  {\n    query: "healthy food",\n    output: `lettuce`,\n    food_type: "vegetable",\n  },\n  {\n    query: "healthy food",\n    output: `schnitzel`,\n    food_type: "veal",\n  },\n  {\n    query: "foo",\n    output: `bar`,\n    food_type: "baz",\n  },\n];\n\nconst exampleSelector = new SemanticSimilarityExampleSelector({\n  vectorStore: memoryVectorStore,\n  k: 2,\n  // Only embed the "query" key of each example\n  inputKeys: ["query"],\n  // Filter type will depend on your specific vector store.\n  // See the section of the docs for the specific vector store you are using.\n  filter: (doc: Document) => doc.metadata.food_type === "vegetable",\n});\n\nfor (const example of examples) {\n  // Format and add an example to the underlying vector store\n  await exampleSelector.addExample(example);\n}\n\n// Create a prompt template that will be used to format the examples.\nconst examplePrompt = PromptTemplate.fromTemplate(`<example>\n  <user_input>\n    {query}\n  </user_input>\n  <output>\n    {output}\n  </output>\n</example>`);\n\n// Create a FewShotPromptTemplate that will use the example selector.\nconst dynamicPrompt = new FewShotPromptTemplate({\n  // We provide an ExampleSelector instead of examples.\n  exampleSelector,\n  examplePrompt,\n  prefix: `Answer the user\'s question, using the below examples as reference:`,\n  suffix: "User question:\\n{query}",\n  inputVariables: ["query"],\n});\n\nconst model = new ChatOpenAI({});\n\nconst chain = dynamicPrompt.pipe(model);\n\nconst result = await chain.invoke({\n  query: "What is exactly one type of healthy food?",\n});\nconsole.log(result);\n/*\n  AIMessage {\n    content: \'One type of healthy food is lettuce.\',\n    additional_kwargs: { function_call: undefined }\n  }\n*/\n',imports:[{local:"MemoryVectorStore",imported:"MemoryVectorStore",source:"langchain/vectorstores/memory"},{local:"OpenAIEmbeddings",imported:"OpenAIEmbeddings",source:"@langchain/openai"},{local:"ChatOpenAI",imported:"ChatOpenAI",source:"@langchain/openai"},{local:"PromptTemplate",imported:"PromptTemplate",source:"@langchain/core/prompts"},{local:"FewShotPromptTemplate",imported:"FewShotPromptTemplate",source:"@langchain/core/prompts"},{local:"Document",imported:"Document",source:"@langchain/core/documents"},{local:"SemanticSimilarityExampleSelector",imported:"SemanticSimilarityExampleSelector",source:"@langchain/core/example_selectors"}]}}}]);