"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7082],{92157:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var a=n(74848),s=n(28453);const o={sidebar_class_name:"hidden",sidebar_position:5,title:"How to compose prompts together"},i=void 0,r={id:"how_to/prompts_composition",title:"How to compose prompts together",description:"This guide assumes familiarity with the following concepts:",source:"@site/docs/how_to/prompts_composition.mdx",sourceDirName:"how_to",slug:"/how_to/prompts_composition",permalink:"/docs/how_to/prompts_composition",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/prompts_composition.mdx",tags:[],version:"current",sidebarPosition:5,frontMatter:{sidebar_class_name:"hidden",sidebar_position:5,title:"How to compose prompts together"},sidebar:"tutorialSidebar",previous:{title:"How to pass through arguments from one step to the next",permalink:"/docs/how_to/passthrough"},next:{title:"How to use legacy LangChain Agents (AgentExecutor)",permalink:"/docs/how_to/agent_executor"}},p={},l=[{value:"String prompt composition",id:"string-prompt-composition",level:2},{value:"Chat prompt composition",id:"chat-prompt-composition",level:2},{value:"Using PipelinePrompt",id:"using-pipelineprompt",level:2},{value:"Next steps",id:"next-steps",level:2}];function m(e){const t={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)(t.admonition,{title:"Prerequisites",type:"info",children:[(0,a.jsx)(t.p,{children:"This guide assumes familiarity with the following concepts:"}),(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:(0,a.jsx)(t.a,{href:"../../docs/concepts/#prompt-templates",children:"Prompt templates"})}),"\n"]})]}),"\n",(0,a.jsx)(t.p,{children:"LangChain provides a user friendly interface for composing different\nparts of prompts together. You can do this with either string prompts or\nchat prompts. Constructing prompts this way allows for easy reuse of\ncomponents."}),"\n",(0,a.jsx)(t.h2,{id:"string-prompt-composition",children:"String prompt composition"}),"\n",(0,a.jsx)(t.p,{children:"When working with string prompts, each template is joined together. You\ncan work with either prompts directly or strings (the first element in\nthe list needs to be a prompt)."}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'import { PromptTemplate } from "@langchain/core/prompts";\n\nconst prompt = PromptTemplate.fromTemplate(\n  `Tell me a joke about {topic}, make it funny and in {language}`\n);\n\nprompt;\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:'PromptTemplate {\n  lc_serializable: true,\n  lc_kwargs: {\n    inputVariables: [ "topic", "language" ],\n    templateFormat: "f-string",\n    template: "Tell me a joke about {topic}, make it funny and in {language}"\n  },\n  lc_runnable: true,\n  name: undefined,\n  lc_namespace: [ "langchain_core", "prompts", "prompt" ],\n  inputVariables: [ "topic", "language" ],\n  outputParser: undefined,\n  partialVariables: undefined,\n  templateFormat: "f-string",\n  template: "Tell me a joke about {topic}, make it funny and in {language}",\n  validateTemplate: true\n}\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'await prompt.format({ topic: "sports", language: "spanish" });\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:'"Tell me a joke about sports, make it funny and in spanish"\n'})}),"\n",(0,a.jsx)(t.h2,{id:"chat-prompt-composition",children:"Chat prompt composition"}),"\n",(0,a.jsx)(t.p,{children:"A chat prompt is made up a of a list of messages. Similarly to the above\nexample, we can concatenate chat prompt templates. Each new element is a\nnew message in the final prompt."}),"\n",(0,a.jsxs)(t.p,{children:["First, let\u2019s initialize the a\n",(0,a.jsx)(t.a,{href:"https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html",children:(0,a.jsx)(t.code,{children:"ChatPromptTemplate"})}),"\nwith a\n",(0,a.jsx)(t.a,{href:"https://api.python.langchain.com/en/latest/messages/langchain_core.messages.system.SystemMessage.html",children:(0,a.jsx)(t.code,{children:"SystemMessage"})}),"."]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'import {\n  AIMessage,\n  HumanMessage,\n  SystemMessage,\n} from "@langchain/core/messages";\n\nconst prompt = new SystemMessage("You are a nice pirate");\n'})}),"\n",(0,a.jsxs)(t.p,{children:["You can then easily create a pipeline combining it with other messages\n",(0,a.jsx)(t.em,{children:"or"})," message templates. Use a ",(0,a.jsx)(t.code,{children:"BaseMessage"})," when there are no variables\nto be formatted, use a ",(0,a.jsx)(t.code,{children:"MessageTemplate"})," when there are variables to be\nformatted. You can also use just a string (note: this will automatically\nget inferred as a\n",(0,a.jsx)(t.a,{href:"https://v02.api.js.langchain.com/classes/langchain_core_prompts.HumanMessagePromptTemplate.html",children:(0,a.jsx)(t.code,{children:"HumanMessagePromptTemplate"})}),".)"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'import { HumanMessagePromptTemplate } from "@langchain/core/prompts";\n\nconst newPrompt = HumanMessagePromptTemplate.fromTemplate([\n  prompt,\n  new HumanMessage("Hi"),\n  new AIMessage("what?"),\n  "{input}",\n]);\n'})}),"\n",(0,a.jsx)(t.p,{children:"Under the hood, this creates an instance of the ChatPromptTemplate\nclass, so you can use it just as you did before!"}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'await newPrompt.formatMessages({ input: "i said hi" });\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:'[\n  HumanMessage {\n    lc_serializable: true,\n    lc_kwargs: {\n      content: [\n        { type: "text", text: "You are a nice pirate" },\n        { type: "text", text: "Hi" },\n        { type: "text", text: "what?" },\n        { type: "text", text: "i said hi" }\n      ],\n      additional_kwargs: {},\n      response_metadata: {}\n    },\n    lc_namespace: [ "langchain_core", "messages" ],\n    content: [\n      { type: "text", text: "You are a nice pirate" },\n      { type: "text", text: "Hi" },\n      { type: "text", text: "what?" },\n      { type: "text", text: "i said hi" }\n    ],\n    name: undefined,\n    additional_kwargs: {},\n    response_metadata: {}\n  }\n]\n'})}),"\n",(0,a.jsx)(t.h2,{id:"using-pipelineprompt",children:"Using PipelinePrompt"}),"\n",(0,a.jsxs)(t.p,{children:["LangChain includes a class called\n",(0,a.jsx)(t.a,{href:"https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.pipeline.PipelinePromptTemplate.html",children:(0,a.jsx)(t.code,{children:"PipelinePromptTemplate"})}),",\nwhich can be useful when you want to reuse parts of prompts. A\nPipelinePrompt consists of two main parts:"]}),"\n",(0,a.jsxs)(t.ul,{children:["\n",(0,a.jsx)(t.li,{children:"Final prompt: The final prompt that is returned"}),"\n",(0,a.jsx)(t.li,{children:"Pipeline prompts: A list of tuples, consisting of a string name and\na prompt template. Each prompt template will be formatted and then\npassed to future prompt templates as a variable with the same name."}),"\n"]}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'import {\n  PromptTemplate,\n  PipelinePromptTemplate,\n} from "@langchain/core/prompts";\n\nconst fullPrompt = PromptTemplate.fromTemplate(`{introduction}\n\n{example}\n\n{start}`);\n\nconst introductionPrompt = PromptTemplate.fromTemplate(\n  `You are impersonating {person}.`\n);\n\nconst examplePrompt =\n  PromptTemplate.fromTemplate(`Here\'s an example of an interaction:\nQ: {example_q}\nA: {example_a}`);\n\nconst startPrompt = PromptTemplate.fromTemplate(`Now, do this for real!\nQ: {input}\nA:`);\n\nconst composedPrompt = new PipelinePromptTemplate({\n  pipelinePrompts: [\n    {\n      name: "introduction",\n      prompt: introductionPrompt,\n    },\n    {\n      name: "example",\n      prompt: examplePrompt,\n    },\n    {\n      name: "start",\n      prompt: startPrompt,\n    },\n  ],\n  finalPrompt: fullPrompt,\n});\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-typescript",children:'const formattedPrompt = await composedPrompt.format({\n  person: "Elon Musk",\n  example_q: `What\'s your favorite car?`,\n  example_a: "Telsa",\n  input: `What\'s your favorite social media site?`,\n});\n\nconsole.log(formattedPrompt);\n'})}),"\n",(0,a.jsx)(t.pre,{children:(0,a.jsx)(t.code,{className:"language-text",children:"You are impersonating Elon Musk.\n\nHere's an example of an interaction:\nQ: What's your favorite car?\nA: Telsa\n\nNow, do this for real!\nQ: What's your favorite social media site?\nA:\n"})}),"\n",(0,a.jsx)(t.h2,{id:"next-steps",children:"Next steps"}),"\n",(0,a.jsx)(t.p,{children:"You\u2019ve now learned how to compose prompts together."}),"\n",(0,a.jsxs)(t.p,{children:["Next, check out the other how-to guides on prompt templates in this\nsection, like ",(0,a.jsx)(t.a,{href:"../../docs/how_to/few_shot_examples_chat",children:"adding few-shot examples to your prompt\ntemplates"}),"."]})]})}function c(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,a.jsx)(t,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}}}]);