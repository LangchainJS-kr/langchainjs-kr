"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4849],{24270:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>p,contentTitle:()=>i,default:()=>c,frontMatter:()=>r,metadata:()=>l,toc:()=>h});var a=t(74848),o=t(28453),s=t(78847);const r={sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},i="Few Shot Prompt Templates",l={id:"how_to/few_shot",title:"Few Shot Prompt Templates",description:"Few shot prompting is a prompting technique which provides the Large Language Model (LLM) with a list of examples, and then asks the LLM to generate some text following the lead of the examples provided.",source:"@site/docs/how_to/few_shot.mdx",sourceDirName:"how_to",slug:"/how_to/few_shot",permalink:"/docs/how_to/few_shot",draft:!1,unlisted:!1,editUrl:"https://langchainjs-kr.site/docs/how_to/few_shot.mdx",tags:[],version:"current",frontMatter:{sidebar_class_name:"hidden",pagination_prev:null,pagination_next:null},sidebar:"tutorialSidebar"},p={},h=[{value:"Use Case",id:"use-case",level:3},...s.toc,{value:"Few Shotting With Functions",id:"few-shotting-with-functions",level:3},{value:"Few Shot vs Chat Few Shot",id:"few-shot-vs-chat-few-shot",level:3},{value:"With Non Chat Models",id:"with-non-chat-models",level:2},{value:"Partials With Functions",id:"partials-with-functions",level:3},{value:"With Functions and Example Selector",id:"with-functions-and-example-selector",level:3}];function m(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.h1,{id:"few-shot-prompt-templates",children:"Few Shot Prompt Templates"}),"\n",(0,a.jsx)(n.p,{children:"Few shot prompting is a prompting technique which provides the Large Language Model (LLM) with a list of examples, and then asks the LLM to generate some text following the lead of the examples provided."}),"\n",(0,a.jsx)(n.p,{children:"An example of this is the following:"}),"\n",(0,a.jsx)(n.p,{children:"Say you want your LLM to respond in a specific format. You can few shot prompt the LLM with a list of question answer pairs so it knows what format to respond in."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-txt",children:"Respond to the users question in the with the following format:\n\nQuestion: What is your name?\nAnswer: My name is John.\n\nQuestion: What is your age?\nAnswer: I am 25 years old.\n\nQuestion: What is your favorite color?\nAnswer:\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Here we left the last ",(0,a.jsx)(n.code,{children:"Answer:"})," undefined so the LLM can fill it in. The LLM will then generate the following:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-txt",children:"Answer: I don't have a favorite color; I don't have preferences.\n"})}),"\n",(0,a.jsx)(n.h3,{id:"use-case",children:"Use Case"}),"\n",(0,a.jsx)(n.p,{children:"In the following example we're few shotting the LLM to rephrase questions into more general queries."}),"\n",(0,a.jsxs)(n.p,{children:["We provide two sets of examples with specific questions, and rephrased general questions. The ",(0,a.jsx)(n.code,{children:"FewShotChatMessagePromptTemplate"})," will use our examples and when ",(0,a.jsx)(n.code,{children:".format"})," is called, we'll see those examples formatted into a string we can pass to the LLM."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import {\n  ChatPromptTemplate,\n  FewShotChatMessagePromptTemplate,\n} from "langchain/prompts";\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const examples = [\n  {\n    input: "Could the members of The Police perform lawful arrests?",\n    output: "what can the members of The Police do?",\n  },\n  {\n    input: "Jan Sindel\'s was born in what country?",\n    output: "what is Jan Sindel\'s personal history?",\n  },\n];\nconst examplePrompt = ChatPromptTemplate.fromTemplate(`Human: {input}\nAI: {output}`);\nconst fewShotPrompt = new FewShotChatMessagePromptTemplate({\n  examplePrompt,\n  examples,\n  inputVariables: [], // no input variables\n});\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"const formattedPrompt = await fewShotPrompt.format({});\nconsole.log(formattedPrompt);\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"[\n  HumanMessage {\n    lc_namespace: [ 'langchain', 'schema' ],\n    content: 'Human: Could the members of The Police perform lawful arrests?\\n' +\n      'AI: what can the members of The Police do?',\n    additional_kwargs: {}\n  },\n  HumanMessage {\n    lc_namespace: [ 'langchain', 'schema' ],\n    content: \"Human: Jan Sindel's was born in what country?\\n\" +\n      \"AI: what is Jan Sindel's personal history?\",\n    additional_kwargs: {}\n  }\n]\n"})}),"\n",(0,a.jsx)(n.p,{children:"Then, if we use this with another question, the LLM will rephrase the question how we want."}),"\n","\n",(0,a.jsx)(s.default,{}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",metastring:"npm2yarn",children:"npm install @langchain/openai\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import { ChatOpenAI } from "@langchain/openai";\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const model = new ChatOpenAI({});\nconst examples = [\n  {\n    input: "Could the members of The Police perform lawful arrests?",\n    output: "what can the members of The Police do?",\n  },\n  {\n    input: "Jan Sindel\'s was born in what country?",\n    output: "what is Jan Sindel\'s personal history?",\n  },\n];\nconst examplePrompt = ChatPromptTemplate.fromTemplate(`Human: {input}\nAI: {output}`);\nconst fewShotPrompt = new FewShotChatMessagePromptTemplate({\n  prefix:\n    "Rephrase the users query to be more general, using the following examples",\n  suffix: "Human: {input}",\n  examplePrompt,\n  examples,\n  inputVariables: ["input"],\n});\nconst formattedPrompt = await fewShotPrompt.format({\n  input: "What\'s France\'s main city?",\n});\n\nconst response = await model.invoke(formattedPrompt);\nconsole.log(response);\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"AIMessage {\n  lc_namespace: [ 'langchain', 'schema' ],\n  content: 'What is the capital of France?',\n  additional_kwargs: { function_call: undefined }\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"few-shotting-with-functions",children:"Few Shotting With Functions"}),"\n",(0,a.jsx)(n.p,{children:"You can also partial with a function. The use case for this is when you have a variable you know that you always want to fetch in a common way. A prime example of this is with date or time. Imagine you have a prompt which you always want to have the current date. You can't hard code it in the prompt, and passing it along with the other input variables can be tedious. In this case, it's very handy to be able to partial the prompt with a function that always returns the current date."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const getCurrentDate = () => {\n  return new Date().toISOString();\n};\n\nconst prompt = new FewShotChatMessagePromptTemplate({\n  template: "Tell me a {adjective} joke about the day {date}",\n  inputVariables: ["adjective", "date"],\n});\n\nconst partialPrompt = await prompt.partial({\n  date: getCurrentDate,\n});\n\nconst formattedPrompt = await partialPrompt.format({\n  adjective: "funny",\n});\n\nconsole.log(formattedPrompt);\n\n// Tell me a funny joke about the day 2023-07-13T00:54:59.287Z\n'})}),"\n",(0,a.jsx)(n.h3,{id:"few-shot-vs-chat-few-shot",children:"Few Shot vs Chat Few Shot"}),"\n",(0,a.jsx)(n.p,{children:"The chat and non chat few shot prompt templates act in a similar way. The below example will demonstrate using chat and non chat, and the differences with their outputs."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import {\n  FewShotPromptTemplate,\n  FewShotChatMessagePromptTemplate,\n} from "langchain/prompts";\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const examples = [\n  {\n    input: "Could the members of The Police perform lawful arrests?",\n    output: "what can the members of The Police do?",\n  },\n  {\n    input: "Jan Sindel\'s was born in what country?",\n    output: "what is Jan Sindel\'s personal history?",\n  },\n];\nconst prompt = `Human: {input}\nAI: {output}`;\nconst examplePromptTemplate = PromptTemplate.fromTemplate(prompt);\nconst exampleChatPromptTemplate = ChatPromptTemplate.fromTemplate(prompt);\nconst chatFewShotPrompt = new FewShotChatMessagePromptTemplate({\n  examplePrompt: exampleChatPromptTemplate,\n  examples,\n  inputVariables: [], // no input variables\n});\nconst fewShotPrompt = new FewShotPromptTemplate({\n  examplePrompt: examplePromptTemplate,\n  examples,\n  inputVariables: [], // no input variables\n});\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"console.log(\"Chat Few Shot: \", await chatFewShotPrompt.formatMessages({}));\n/**\nChat Few Shot:  [\n  HumanMessage {\n    lc_namespace: [ 'langchain', 'schema' ],\n    content: 'Human: Could the members of The Police perform lawful arrests?\\n' +\n      'AI: what can the members of The Police do?',\n    additional_kwargs: {}\n  },\n  HumanMessage {\n    lc_namespace: [ 'langchain', 'schema' ],\n    content: \"Human: Jan Sindel's was born in what country?\\n\" +\n      \"AI: what is Jan Sindel's personal history?\",\n    additional_kwargs: {}\n  }\n]\n */\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"console.log(\"Few Shot: \", await fewShotPrompt.formatPromptValue({}));\n/**\nFew Shot:\n\nHuman: Could the members of The Police perform lawful arrests?\nAI: what can the members of The Police do?\n\nHuman: Jan Sindel's was born in what country?\nAI: what is Jan Sindel's personal history?\n */\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Here we can see the main distinctions between ",(0,a.jsx)(n.code,{children:"FewShotChatMessagePromptTemplate"})," and ",(0,a.jsx)(n.code,{children:"FewShotPromptTemplate"}),": input and output values."]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"FewShotChatMessagePromptTemplate"})," works by taking in a list of ",(0,a.jsx)(n.code,{children:"ChatPromptTemplate"})," for examples, and its output is a list of instances of ",(0,a.jsx)(n.code,{children:"BaseMessage"}),"."]}),"\n",(0,a.jsxs)(n.p,{children:["On the other hand, ",(0,a.jsx)(n.code,{children:"FewShotPromptTemplate"})," works by taking in a ",(0,a.jsx)(n.code,{children:"PromptTemplate"})," for examples, and its output is a string."]}),"\n",(0,a.jsx)(n.h2,{id:"with-non-chat-models",children:"With Non Chat Models"}),"\n",(0,a.jsxs)(n.p,{children:["LangChain also provides a class for few shot prompt formatting for non chat models: ",(0,a.jsx)(n.code,{children:"FewShotPromptTemplate"}),". The API is largely the same, but the output is formatted differently (chat messages vs strings)."]}),"\n",(0,a.jsx)(n.h3,{id:"partials-with-functions",children:"Partials With Functions"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import {\n  ChatPromptTemplate,\n  FewShotChatMessagePromptTemplate,\n} from "langchain/prompts";\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const examplePrompt = PromptTemplate.fromTemplate("{foo}{bar}");\nconst prompt = new FewShotPromptTemplate({\n  prefix: "{foo}{bar}",\n  examplePrompt,\n  inputVariables: ["foo", "bar"],\n});\nconst partialPrompt = await prompt.partial({\n  foo: () => Promise.resolve("boo"),\n});\nconst formatted = await partialPrompt.format({ bar: "baz" });\nconsole.log(formatted);\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-txt",children:"boobaz\\n\n"})}),"\n",(0,a.jsx)(n.h3,{id:"with-functions-and-example-selector",children:"With Functions and Example Selector"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'import {\n  ChatPromptTemplate,\n  FewShotChatMessagePromptTemplate,\n} from "langchain/prompts";\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:'const examplePrompt = PromptTemplate.fromTemplate("An example about {x}");\nconst exampleSelector = await LengthBasedExampleSelector.fromExamples(\n  [{ x: "foo" }, { x: "bar" }],\n  { examplePrompt, maxLength: 200 }\n);\nconst prompt = new FewShotPromptTemplate({\n  prefix: "{foo}{bar}",\n  exampleSelector,\n  examplePrompt,\n  inputVariables: ["foo", "bar"],\n});\nconst partialPrompt = await prompt.partial({\n  foo: () => Promise.resolve("boo"),\n});\nconst formatted = await partialPrompt.format({ bar: "baz" });\nconsole.log(formatted);\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-txt",children:"boobaz\nAn example about foo\nAn example about bar\n"})})]})}function c(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}}}]);