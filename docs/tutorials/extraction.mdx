---
sidebar_position: 4
title: 추출 체인 만들기
sidebar_class_name: hidden
pagination_prev: null
pagination_next: null
---

이 튜토리얼에선 비정형 텍스트에서 정형화된 정보를 추출하는 체인을 구축할 것입니다.

:::중요

이 튜토리얼은 **함수/도구 호출 ( Function/tool calling )** 을 지원하는 모델에서만 작동합니다.
:::

## 개념

우리가 다룰 개념들: 
- [language models](../../docs/concepts/#chat-models) 사용하기
- [function/toolcalling](../../docs/concepts/#function-tool-calling) 사용하기
- [LangSmith](../../docs/concepts/#langsmith)를 사용해 애플리케이션 디버깅 및 추적하기

## 설정

### 설치

LangChain을 설치하려면 다음 명령을 실행하세요:

```mdx-code-block
import Npm2Yarn from '@theme/Npm2Yarn';

<Npm2Yarn>
  langchain
</Npm2Yarn>
```

For more details, see our [Installation
guide](../../docs/how_to/installation/).

### LangSmith


랭체인을 이용한 수많은 애플리케이션은 LLM 호출을 여러 단계에서, 여러 번 수행할 것입니다.
애플리케이션이 복잡하면 복잡해질수록, 애플리케이션의 체인이나 에이전트 안에서 무슨 일이 일어나고 있는지 검토하는 것이 중요합니다.
최고의 방법은 [LangSmith](https://smith.langchain.com)를 이용하는 것입니다.

위의 링크에 가입하고, 반드시 환경변수를 설정해 로그 추적을 시작하세요.

로그 추적을 시작하기 위한 변수들:

```shell
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY="..."
```

## 스키마 (The Schema)

먼저 우리가 텍스트에서 추출하고자 하는 정보를 정확히 설명하는 스키마를 정의해야 합니다

[Zod](https://zod.dev)을 이용해서 개인정보를 추출하는 예제 스키마를 정의할 것입니다.

```mdx-code-block
<Npm2Yarn>
  zod @langchain/core
</Npm2Yarn>
```

```typescript
import { z } from "zod";

const personSchema = z.object({
  name: z.string().nullish().describe("The name of the person"),
  hair_color: z
    .string()
    .nullish()
    .describe("The color of the person's hair if known"),
  height_in_meters: z.string().nullish().describe("Height measured in meters"),
});
```

스키마를 정의할 때 두 가지 모범 사례 :

1. **속성(Attributes)**과 **스키마(Schema)** 자체를 문서화하세요 : 이 정보는 LLM에 전달되어 정보 추출의 품질을 향상하는 데 사용됩니다.
2.  LLM이 정보를 꾸며내게 하지 마세요 : 위에서는 LLM이 답을 모를 경우 `.nullish()`를 이용하여 LLM에게 결괏값으로 `null` 또는 `undefined`를 출력하도록 허용했습니다.

:::중요

좋은 성능을 위해 스키마를 문서화하세요. 

텍스트에서 추출할 정보가 없으면, 모델에게 결괏값을 반환하도록 강제하지 마세요.

:::

## 추출기 (The Extractor)

우리가 위에 정의한 스키마를 이용하여 정보 추출기를 생성해 봅시다!

```typescript
import { ChatPromptTemplate } from "@langchain/core/prompts";

//LLM에게 지시 사항과 추가적인 맥락을 제공하는 사용자 정의 프롬프트를 정의하세요
// 1) 추출 품질을 향상하기 위해 예시를 프롬프트 템플릿에 추가할 수 있습니다.
// 2) 추가 매개변수를 도입하여 맥락을 고려합니다. (예시, 텍스트에서 추출된 문서의 메타데이터를 포함하여)

const prompt = ChatPromptTemplate.fromMessages([
  [
    "system",
    `You are an expert extraction algorithm.
Only extract relevant information from the text.
If you do not know the value of an attribute asked to extract,
return null for the attribute's value.`,
  ],
  // 
  // 성능 향상을 위한 방법과 참조 예제들을 참고하세요  
  // ["placeholder", "{examples}"],
  ["human", "{text}"],
]);
```

우리는 함수/도구 호출을 지원하는 모델이 필요합니다.

이 API와 사용할 수 있는 몇 가지 모델 목록은 [문서(함수/도구 호출 ( Function/Tool Calling ))](../../docs/concepts#함수도구-호출--functiontool-calling-)을 참조하세요

```typescript
import { ChatAnthropic } from "@langchain/anthropic";

const llm = new ChatAnthropic({
  model: "claude-3-sonnet-20240229",
  temperature: 0,
});

const runnable = prompt.pipe(llm.withStructuredOutput(personSchema));

const text = "Alan Smith is 6 feet tall and has blond hair.";
await runnable.invoke({ text });
```

```text
{ name: "Alan Smith", hair_color: "blond", height_in_meters: "1.83" }
```

:::중요

추출은 생성형이다 🤯

LLM은 생성형 모델이므로, 피트 단위로 제공된 사람의 키를 미터 단위로 정확히 추출하는 등의 멋진 작업을 할 수 있습니다!


:::

LangSmith의 추적을 확인할 수 있습니다.
[here](https://smith.langchain.com/public/3d44b7e8-e7ca-4e02-951d-3290ccc89d64/r)

비록 우리의 스키마의 변수 이름을 `personSchema`으로 정의했음에도 불구하고, Zod는 이 이름을 추론할 수 없어서 모델에게 전달하지 못합니다. LLM에게
당신이 제공하는 스키마가 무엇을 나타내는지 단서를 주기 위해, `withStructuredOutput()`에 이름을 전달할 수 있습니다.

```typescript
const runnable = prompt.pipe(
  llm.withStructuredOutput(personSchema, { name: "person" })
);

const text = "Alan Smith is 6 feet tall and has blond hair.";

await runnable.invoke({ text });
```

```text
{ name: "Alan Smith", hair_color: "blond", height_in_meters: "1.83" }
```

이것은 다양한 경우에 성능을 향상할 수 있습니다.

## 다중 엔티티 (Multiple Entities)

**대다수의 경우**에, 하나의 엔티티보다는 여러 엔티티의 목록을 추출해야 합니다.  
zod를 사용해서 모델들을 서로 중첩하면 이를 쉽게 달성할 수 있습니다

```typescript
import { z } from "zod";

const personSchema = z.object({
  name: z.string().nullish().describe("The name of the person"),
  hair_color: z
    .string()
    .nullish()
    .describe("The color of the person's hair if known"),
  height_in_meters: z.number().nullish().describe("Height measured in meters"),
});

const dataSchema = z.object({
  people: z.array(personSchema).describe("Extracted data about people"),
});
```

:::중요

여기서 추출은 완벽하지 않을 수 있습니다. 
계속해서 추출 품질을 향상하는 **참조 예제들**의 사용법을 확인하고, **가이드라인** 섹션을 참고하세요

:::

```typescript
const runnable = prompt.pipe(llm.withStructuredOutput(dataSchema));
const text =
  "My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me.";
await runnable.invoke({ text });
```

```text
{
  people: [
    { name: "Jeff", hair_color: "black", height_in_meters: 1.83 },
    { name: "Anna", hair_color: "black", height_in_meters: null }
  ]
}
```

:::팁

스키마가 **여러 엔티티**들의 추출을 지원할 때, 만약 텍스트에 관련 정보가 없으면 빈 목록을 제공함으로써 
**모델이 개체를 추출하지(no entities)** 않게 허용할 수 있습니다.

이건 일반적으로 **좋은 점**입니다! 
이는 모델이 엔티티를 감지하도록 강제하지 않으면서도 **필수 애트리뷰트들**을 명시할 수 있게 합니다.

:::

LangSmith를 이용해 추적을 확인할 수 있습니다.
[here](https://smith.langchain.com/public/272096ab-9ac5-43f9-aa00-3b8443477d17/r)

## Next steps

이제 당신은 랭체인의 기본적인 추출을 이해했습니다. 
나머지 사용 가이드를 진행할 준비가 되었습니다:

- [추가적인 예제들](../../docs/how_to/extraction_examples): 
  **참조 예제** 들의 성능을 향상하는 방법을 배워보세요.
- [긴 텍스트 다루기](../../docs/how_to/extraction_long_text): 
  LLM의 문맥 창에 텍스트가 맞지 않는 경우 어떻게 해야 할까요 ?
- [파싱 접근방식을 사용해 보세요](../../docs/how_to/extraction_parse): 
  함수/도구 호출을 지원하지 않는 모델에서 추출하기 위해 프롬프트에 기반한 접근방식을 사용하세요. 
