---
sidebar_label: OpenAI
---

import CodeBlock from "@theme/CodeBlock";

# ChatOpenAI

You can use OpenAI's chat models as follows:

import OpenAI from "@examples/models/chat/integration_openai.ts";

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/openai
```

import UnifiedModelParamsTooltip from "@mdx_components/unified_model_params_tooltip.mdx";

<UnifiedModelParamsTooltip></UnifiedModelParamsTooltip>

<CodeBlock language="typescript">{OpenAI}</CodeBlock>

If you're part of an organization, you can set `process.env.OPENAI_ORGANIZATION` with your OpenAI organization id, or pass it in as `organization` when
initializing the model.

## Multimodal messages

:::info
This feature is currently in preview. The message schema may change in future releases.
:::

OpenAI supports interleaving images with text in input messages with their `gpt-4-vision-preview`. Here's an example of how this looks:

import OpenAIVision from "@examples/models/chat/integration_openai_vision.ts";

<CodeBlock language="typescript">{OpenAIVision}</CodeBlock>

## Tool calling

:::info
This feature is currently only available for `gpt-3.5-turbo-1106` and `gpt-4-1106-preview` models.
:::

More recent OpenAI chat models support calling multiple functions to get all required data to answer a question.
Here's an example how a conversation turn with this functionality might look:

import OpenAITools from "@examples/models/chat/integration_openai_tool_calls.ts";

<CodeBlock language="typescript">{OpenAITools}</CodeBlock>

### `.withStructuredOutput({ ... })`

:::info
The `.withStructuredOutput` method is in beta. It is actively being worked on, so the API may change.
:::

You can also use the `.withStructuredOutput({ ... })` method to coerce `ChatOpenAI` into returning a structured output.

The method allows for passing in either a Zod object, or a valid JSON schema (like what is returned from [`zodToJsonSchema`](https://www.npmjs.com/package/zod-to-json-schema)).

Using the method is simple. Just define your LLM and call `.withStructuredOutput({ ... })` on it, passing the desired schema.

Here is an example using a Zod schema and the `functionCalling` mode (default mode):

import WSAZodExample from "@examples/models/chat/integration_openai_wsa_zod.ts";

<CodeBlock language="typescript">{WSAZodExample}</CodeBlock>

Additionally, you can pass in an OpenAI function definition or JSON schema directly:

:::info
If using `jsonMode` as the `method` you must include context in your prompt about the structured output you want. This _must_ include the keyword: `JSON`.
:::

import WSAJSONSchemaExample from "@examples/models/chat/integration_openai_wsa_json_schema.ts";

<CodeBlock language="typescript">{WSAJSONSchemaExample}</CodeBlock>

## Custom URLs

You can customize the base URL the SDK sends requests to by passing a `configuration` parameter like this:

import OpenAICustomBase from "@examples/models/chat/integration_openai_custom_base.ts";

<CodeBlock language="typescript">{OpenAICustomBase}</CodeBlock>

You can also pass other `ClientOptions` parameters accepted by the official SDK.

If you are hosting on Azure OpenAI, see the [dedicated page instead](/docs/integrations/chat/azure).

## Calling fine-tuned models

You can call fine-tuned OpenAI models by passing in your corresponding `modelName` parameter.

This generally takes the form of `ft:{OPENAI_MODEL_NAME}:{ORG_NAME}::{MODEL_ID}`. For example:

import OpenAIFineTuned from "@examples/models/chat/integration_openai_fine_tune.ts";

<CodeBlock language="typescript">{OpenAIFineTuned}</CodeBlock>

## Generation metadata

If you need additional information like logprobs or token usage, these will be returned directly in the `.invoke` response.

:::tip
Requires `@langchain/core` version >=0.1.48.
:::

import OpenAIInvokeInfo from "@examples/models/chat/integration_openai_invoke_info.ts";
import OpenAIGenerationInfo from "@examples/models/chat/integration_openai_generation_info.ts";
import OpenAICallbacks from "@examples/models/chat/integration_openai_callbacks.ts";

<CodeBlock language="typescript">{OpenAIInvokeInfo}</CodeBlock>

### With callbacks

You can also use the callbacks system:

<CodeBlock language="typescript">{OpenAICallbacks}</CodeBlock>

### With `.generate()`

<CodeBlock language="typescript">{OpenAIGenerationInfo}</CodeBlock>
