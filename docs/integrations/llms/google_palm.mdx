---
sidebar_label: (Legacy) Google PaLM/VertexAI
sidebar_class_name: hidden
---

import CodeBlock from "@theme/CodeBlock";

# Google PaLM

:::note
This integration does not support `gemini-*` models. Check [Google AI](/docs/integrations/chat/google_generativeai) or [VertexAI](/docs/integrations/llms/google_vertex_ai).
:::

The [Google PaLM API](https://developers.generativeai.google/products/palm) can be integrated by first
installing the required packages:

import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install google-auth-library @google-ai/generativelanguage @langchain/community
```

Create an **API key** from [Google MakerSuite](https://makersuite.google.com/app/apikey). You can then set
the key as `GOOGLE_PALM_API_KEY` environment variable or pass it as `apiKey` parameter while instantiating
the model.

import GooglePaLMExample from "@examples/models/llm/googlepalm.ts";

<CodeBlock language="typescript">{GooglePaLMExample}</CodeBlock>

# GooglePaLM

Langchain.js supports two different authentication methods based on whether
you're running in a Node.js environment or a web environment.

## Setup

### Node.js

To call Vertex AI models in Node, you'll need to install [Google's official auth client](https://www.npmjs.com/package/google-auth-library) as a peer dependency.

You should make sure the Vertex AI API is
enabled for the relevant project and that you've authenticated to
Google Cloud using one of these methods:

- You are logged into an account (using `gcloud auth application-default login`)
  permitted to that project.
- You are running on a machine using a service account that is permitted
  to the project.
- You have downloaded the credentials for a service account that is permitted
  to the project and set the `GOOGLE_APPLICATION_CREDENTIALS` environment
  variable to the path of this file.

```bash npm2yarn
npm install google-auth-library
```

### Web

To call Vertex AI models in web environments (like Edge functions), you'll need to install
the [`web-auth-library`](https://github.com/kriasoft/web-auth-library) pacakge as a peer dependency:

```bash npm2yarn
npm install web-auth-library
```

Then, you'll need to add your service account credentials directly as a `GOOGLE_VERTEX_AI_WEB_CREDENTIALS` environment variable:

```
GOOGLE_VERTEX_AI_WEB_CREDENTIALS={"type":"service_account","project_id":"YOUR_PROJECT-12345",...}
```

You can also pass your credentials directly in code like this:

<IntegrationInstallTooltip></IntegrationInstallTooltip>

```bash npm2yarn
npm install @langchain/community
```

```typescript
import { GoogleVertexAI } from "@langchain/community/llms/googlevertexai";

const model = new GoogleVertexAI({
  authOptions: {
    credentials: {"type":"service_account","project_id":"YOUR_PROJECT-12345",...},
  },
});
```

## Usage

Several models are available and can be specified by the `model` attribute
in the constructor. These include:

- text-bison (default)
- text-bison-32k
- code-gecko
- code-bison

import GoogleVertexAIExample from "@examples/llms/googlevertexai_legacy.ts";

<CodeBlock language="typescript">{GoogleVertexAIExample}</CodeBlock>

Google also has separate models for their "Codey" code generation models.

The "code-gecko" model is useful for code completion:

import GoogleVertexAICodeGeckoExample from "@examples/llms/googlevertexai-code-gecko_legacy.ts";

<CodeBlock language="typescript">{GoogleVertexAICodeGeckoExample}</CodeBlock>

While the "code-bison" model is better at larger code generation based on
a text prompt:

import GoogleVertexAICodeBisonExample from "@examples/llms/googlevertexai-code-bison_legacy.ts";

<CodeBlock language="typescript">{GoogleVertexAICodeBisonExample}</CodeBlock>

### Streaming

Streaming in multiple chunks is supported for faster responses:

import GoogleVertexAIStreaming from "@examples/llms/googlevertexai-streaming_legacy.ts";

<CodeBlock language="typescript">{GoogleVertexAIStreaming}</CodeBlock>
