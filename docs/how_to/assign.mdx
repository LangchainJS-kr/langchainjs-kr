---
sidebar_class_name: hidden
keywords:
  - RunnablePassthrough
  - assign
  - LCEL
title: How to add values to a chain's state
---

:::info Prerequisites

This guide assumes familiarity with the following concepts:

- [LangChain Expression Language
  (LCEL)](../../docs/concepts/#langchain-expression-language)
- [Chaining runnables](../../docs/how_to/sequence/)
- [Calling runnables in parallel](../../docs/how_to/parallel/)
- [Custom functions](../../docs/how_to/functions/)
- [Passing data through](../../docs/how_to/passthrough)

:::

An alternate way of [passing data
through](../../docs/how_to/passthrough) steps of a chain is to leave the
current values of the chain state unchanged while assigning a new value
under a given key. The
[`RunnablePassthrough.assign()`](https://v02.api.js.langchain.com/classes/langchain_core_runnables.RunnablePassthrough.html#assign-2)
static method takes an input value and adds the extra arguments passed
to the assign function.

This is useful in the common [LangChain Expression
Language](../../docs/concepts/#langchain-expression-language) pattern of
additively creating a dictionary to use as input to a later step.

Here’s an example:

```typescript
import {
  RunnableParallel,
  RunnablePassthrough,
} from "@langchain/core/runnables";

const runnable = RunnableParallel.from({
  extra: RunnablePassthrough.assign({
    mult: (input: { num: number }) => input.num * 3,
    modified: (input: { num: number }) => input.num + 1,
  }),
});

await runnable.invoke({ num: 1 });
```

```text
{ extra: { num: 1, mult: 3, modified: 2 } }
```

Let’s break down what’s happening here.

- The input to the chain is `{"num": 1}`. This is passed into a
  `RunnableParallel`, which invokes the runnables it is passed in
  parallel with that input.
- The value under the `extra` key is invoked.
  `RunnablePassthrough.assign()` keeps the original keys in the input
  dict (`{"num": 1}`), and assigns a new key called `mult`. The value
  is `lambda x: x["num"] * 3)`, which is `3`. Thus, the result is
  `{"num": 1, "mult": 3}`.
- `{"num": 1, "mult": 3}` is returned to the `RunnableParallel` call,
  and is set as the value to the key `extra`.
- At the same time, the `modified` key is called. The result is `2`,
  since the lambda extracts a key called `"num"` from its input and
  adds one.

Thus, the result is `{'extra': {'num': 1, 'mult': 3}, 'modified': 2}`.

## Streaming

One convenient feature of this method is that it allows values to pass
through as soon as they are available. To show this off, we’ll use
`RunnablePassthrough.assign()` to immediately return source docs in a
retrieval chain:

```mdx-code-block
import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";
import Npm2Yarn from "@theme/Npm2Yarn";

<IntegrationInstallTooltip></IntegrationInstallTooltip>

<Npm2Yarn>
  @langchain/openai
</Npm2Yarn>
```

```typescript
import { StringOutputParser } from "@langchain/core/output_parsers";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import {
  RunnablePassthrough,
  RunnableSequence,
} from "@langchain/core/runnables";
import { ChatOpenAI, OpenAIEmbeddings } from "@langchain/openai";
import { MemoryVectorStore } from "langchain/vectorstores/memory";

const vectorstore = await MemoryVectorStore.fromDocuments(
  [{ pageContent: "harrison worked at kensho", metadata: {} }],
  new OpenAIEmbeddings()
);

const retriever = vectorstore.asRetriever();

const template = `Answer the question based only on the following context:
{context}

Question: {question}
`;

const prompt = ChatPromptTemplate.fromTemplate(template);

const model = new ChatOpenAI({ model: "gpt-4o" });

const generationChain = prompt.pipe(model).pipe(new StringOutputParser());

const retrievalChain = RunnableSequence.from([
  {
    context: retriever.pipe((docs) => docs[0].pageContent),
    question: new RunnablePassthrough(),
  },
  RunnablePassthrough.assign({ output: generationChain }),
]);

const stream = await retrievalChain.stream("where did harrison work?");

for await (const chunk of stream) {
  console.log(chunk);
}
```

```text
{ question: "where did harrison work?" }
{ context: "harrison worked at kensho" }
{ output: "" }
{ output: "H" }
{ output: "arrison" }
{ output: " worked" }
{ output: " at" }
{ output: " Kens" }
{ output: "ho" }
{ output: "." }
{ output: "" }
```

We can see that the first chunk contains the original `"question"` since
that is immediately available. The second chunk contains `"context"`
since the retriever finishes second. Finally, the output from the
`generation_chain` streams in chunks as soon as it is available.

## Next steps

Now you’ve learned how to pass data through your chains to help to help
format the data flowing through your chains.

To learn more, see the other how-to guides on runnables in this section.
